{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This experiment was done to see how model Model-2 936K behves with kernel_initializer=\"he_uniform\" (It does not converge faster)\n",
    "\n",
    "- 4 Denseblocks with layer [14,14,14,14], growth rate= 12, compression = 0.5, dropout = 0.2 has achived 92.10 (previous test)\n",
    "\n",
    "- It is seen that Model-2 936K params with kernel_initializer=\"he_uniform\"  with Adam() does not result in faster covergence than the model with out intilization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "a0dba4c3-f402-4223-ea89-3be41ca275fe"
   },
   "outputs": [],
   "source": [
    "# https://keras.io/\n",
    "#!pip install -q keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "756bdmamG6f1",
    "outputId": "2f1c4951-b47b-40a0-ab02-1c97fd7c1a95"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhIk-iu4G6f-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBoa2F25G6gE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "#l = 40\n",
    "#num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWRR6JyzG6gT"
   },
   "outputs": [],
   "source": [
    "do_sub_sampling_of_input = False\n",
    "do_data_augmentation = True\n",
    "do_data_append       = False   #2X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "16a221e4-1075-49d1-9d76-8091d240f280"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_hYUAbsG6ge"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "class_name = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "00iNYJLkG6gj",
    "outputId": "4911e408-9a52-4009-eefd-44e5242fb219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6], dtype=uint8), 32, 32, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], img_height, img_width, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS5X5srxG6gp"
   },
   "outputs": [],
   "source": [
    "def draw_img(i, x_train, y_train, class_name):\n",
    "    im = x_train[i]\n",
    "    c = y_train[i]\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Class %d (%s)\" % (int(c), class_name[int(c)]))\n",
    "    plt.axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "mjF2KvIQG6gw",
    "outputId": "6c7a984d-4db5-4d5b-d110-b740edd41a02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_img(7, x_train, y_train, class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to dispaly and analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These helper functions\n",
    "\n",
    "plot_confusion_matrix(): helps us to plot the confusion matrix. \n",
    "It is taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html. \n",
    "The same page has some sample examples on how to use this function \n",
    "cm: Confusion matrix calcualted using confusion_matrix() from sklearn.metrics <br//> classes: a list of labels for the classes we are plotting\n",
    "normalize=False: True means we will plot nomalized values \n",
    "title='Confusion matrix': set the tiltle of the plot \n",
    "cmap : leave it as it is \n",
    "Example Usage:plot_confusion_matrix(cm, classes=Facial_Expressions, normalize=True, title='Test Data - Using Simple Average Ensembling ')\n",
    "\n",
    "plot_histogram(): helps to plot the histogram of a list \n",
    "lst_data: the list whose histogtam we want to plot , \n",
    "class_labels: a list of labels for the classes we are plotting \n",
    "ylabel='None': set the y label of the plot, x label is always frequency \n",
    "title='None': set the tiltle of the plot -lst_data, class_labels, ylabel='None', title='None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm) #to print in text if needed\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_histogram(lst_data, class_labels, ylabel='None', title='None'):\n",
    "    data = pd.Series(lst_data)\n",
    "    distribution = data.value_counts(sort=False)\n",
    "    y_pos = np.arange(len(class_labels))\n",
    "    \n",
    "    plt.bar(y_pos, distribution, align='center', alpha=0.8)\n",
    "    plt.xticks(y_pos, class_labels)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = ['airplane', 'automobile', 'bird','cat', 'deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(list(y_train), y_classes, ylabel='Frequency',title='CIFAR 10 Class Distribution in Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(list(y_test), y_classes, ylabel='Frequency',title='CIFAR 10 Class Distribution in Test Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmdwlu8pG6g3"
   },
   "outputs": [],
   "source": [
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JGd4ezgG6g7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "z_arXgOSG6hA",
    "outputId": "8960acf7-335b-4c96-9ae9-7fe9b9ad56fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59,  62,  63],\n",
       "       [ 43,  46,  45],\n",
       "       [ 50,  48,  43],\n",
       "       [ 68,  54,  42],\n",
       "       [ 98,  73,  52],\n",
       "       [119,  91,  63],\n",
       "       [139, 107,  75],\n",
       "       [145, 110,  80],\n",
       "       [149, 117,  89],\n",
       "       [149, 120,  93],\n",
       "       [131, 103,  77],\n",
       "       [125,  99,  76],\n",
       "       [142, 115,  91],\n",
       "       [144, 112,  86],\n",
       "       [137, 105,  79],\n",
       "       [129,  97,  71],\n",
       "       [137, 106,  79],\n",
       "       [134, 106,  76],\n",
       "       [124,  97,  64],\n",
       "       [139, 113,  78],\n",
       "       [139, 112,  75],\n",
       "       [133, 105,  69],\n",
       "       [136, 105,  74],\n",
       "       [139, 108,  77],\n",
       "       [152, 120,  89],\n",
       "       [163, 131, 100],\n",
       "       [168, 136, 108],\n",
       "       [159, 129, 102],\n",
       "       [158, 130, 104],\n",
       "       [158, 132, 108],\n",
       "       [152, 125, 102],\n",
       "       [148, 124, 103]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_train[0][0:32][0:32][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "jd2usuXDG6hH",
    "outputId": "a0716d82-94e5-4f1b-ba28-39b1cdced01b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 59,  62,  63],\n",
       "        [ 43,  46,  45],\n",
       "        [ 50,  48,  43],\n",
       "        ...,\n",
       "        [158, 132, 108],\n",
       "        [152, 125, 102],\n",
       "        [148, 124, 103]],\n",
       "\n",
       "       [[ 16,  20,  20],\n",
       "        [  0,   0,   0],\n",
       "        [ 18,   8,   0],\n",
       "        ...,\n",
       "        [123,  88,  55],\n",
       "        [119,  83,  50],\n",
       "        [122,  87,  57]],\n",
       "\n",
       "       [[ 25,  24,  21],\n",
       "        [ 16,   7,   0],\n",
       "        [ 49,  27,   8],\n",
       "        ...,\n",
       "        [118,  84,  50],\n",
       "        [120,  84,  50],\n",
       "        [109,  73,  42]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[208, 170,  96],\n",
       "        [201, 153,  34],\n",
       "        [198, 161,  26],\n",
       "        ...,\n",
       "        [160, 133,  70],\n",
       "        [ 56,  31,   7],\n",
       "        [ 53,  34,  20]],\n",
       "\n",
       "       [[180, 139,  96],\n",
       "        [173, 123,  42],\n",
       "        [186, 144,  30],\n",
       "        ...,\n",
       "        [184, 148,  94],\n",
       "        [ 97,  62,  34],\n",
       "        [ 83,  53,  34]],\n",
       "\n",
       "       [[177, 144, 116],\n",
       "        [168, 129,  94],\n",
       "        [179, 142,  87],\n",
       "        ...,\n",
       "        [216, 184, 140],\n",
       "        [151, 118,  84],\n",
       "        [123,  92,  72]]], dtype=uint8)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "T372AU6RG6hN",
    "outputId": "4739d668-5818-4f70-e6d3-3491edcb274c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Mean :  [[[[125.3069  122.95015 113.866  ]]]]\n",
      "Channel Std :  [[[[62.99325  62.088604 66.70501 ]]]]\n",
      "Channel Mean1 :  [[[[126.02428 123.70843 114.85442]]]]\n",
      "Channel Std1 :  [[[[62.896416 61.937508 66.70607 ]]]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "mean  = np.mean(x_train, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "std   = np.std(x_train, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "\n",
    "mean1  = np.mean(x_test, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "std1   = np.std(x_test, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "\n",
    "\n",
    "print(\"Channel Mean : \", mean)\n",
    "print(\"Channel Std : \", std)\n",
    "print(\"Channel Mean1 : \", mean1)\n",
    "print(\"Channel Std1 : \", std1)\n",
    "\n",
    "\n",
    "\n",
    "x_train = (x_train - mean) / (std)\n",
    "x_test  = (x_test - mean1) / (std1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOCMAYM1G6hT"
   },
   "outputs": [],
   "source": [
    "#x_train = (x_train - 127.5)/255.0\n",
    "#x_test  = (x_test  - 127.5)/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZF74U6zcG6hX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0526032e+00, -9.8166406e-01, -7.6255137e-01],\n",
       "        [-1.3065987e+00, -1.2393603e+00, -1.0323962e+00],\n",
       "        [-1.1954757e+00, -1.2071482e+00, -1.0623789e+00],\n",
       "        ...,\n",
       "        [ 5.1899368e-01,  1.4575703e-01, -8.7939382e-02],\n",
       "        [ 4.2374539e-01,  3.3014923e-02, -1.7788765e-01],\n",
       "        [ 3.6024651e-01,  1.6908908e-02, -1.6289628e-01]],\n",
       "\n",
       "       [[-1.7352160e+00, -1.6581167e+00, -1.4071807e+00],\n",
       "        [-1.9892114e+00, -1.9802370e+00, -1.7070082e+00],\n",
       "        [-1.7034665e+00, -1.8513888e+00, -1.7070082e+00],\n",
       "        ...,\n",
       "        [-3.6621384e-02, -5.6290764e-01, -8.8248241e-01],\n",
       "        [-1.0012025e-01, -6.4343774e-01, -9.5743930e-01],\n",
       "        [-5.2496098e-02, -5.7901365e-01, -8.5249966e-01]],\n",
       "\n",
       "       [[-1.5923436e+00, -1.5936927e+00, -1.3921893e+00],\n",
       "        [-1.7352160e+00, -1.8674948e+00, -1.7070082e+00],\n",
       "        [-1.2113504e+00, -1.5453745e+00, -1.5870771e+00],\n",
       "        ...,\n",
       "        [-1.1599497e-01, -6.2733167e-01, -9.5743930e-01],\n",
       "        [-8.4245533e-02, -6.2733167e-01, -9.5743930e-01],\n",
       "        [-2.5886741e-01, -8.0449790e-01, -1.0773703e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.3127295e+00,  7.5778562e-01, -2.6783592e-01],\n",
       "        [ 1.2016065e+00,  4.8398334e-01, -1.1973014e+00],\n",
       "        [ 1.1539823e+00,  6.1283147e-01, -1.3172324e+00],\n",
       "        ...,\n",
       "        [ 5.5074310e-01,  1.6186304e-01, -6.5761173e-01],\n",
       "        [-1.1002274e+00, -1.4809505e+00, -1.6020685e+00],\n",
       "        [-1.1478515e+00, -1.4326324e+00, -1.4071807e+00]],\n",
       "\n",
       "       [[ 8.6823744e-01,  2.5849915e-01, -2.6783592e-01],\n",
       "        [ 7.5711441e-01,  8.0289232e-04, -1.0773703e+00],\n",
       "        [ 9.6348572e-01,  3.3902922e-01, -1.2572669e+00],\n",
       "        ...,\n",
       "        [ 9.3173629e-01,  4.0345326e-01, -2.9781866e-01],\n",
       "        [-4.4936401e-01, -9.8166406e-01, -1.1973014e+00],\n",
       "        [-6.7161006e-01, -1.1266181e+00, -1.1973014e+00]],\n",
       "\n",
       "       [[ 8.2061332e-01,  3.3902922e-01,  3.1991642e-02],\n",
       "        [ 6.7774087e-01,  9.7438984e-02, -2.9781866e-01],\n",
       "        [ 8.5236275e-01,  3.0681717e-01, -4.0275833e-01],\n",
       "        ...,\n",
       "        [ 1.4397272e+00,  9.8326981e-01,  3.9178470e-01],\n",
       "        [ 4.0787068e-01, -7.9727180e-02, -4.4773245e-01],\n",
       "        [-3.6621384e-02, -4.9848357e-01, -6.2762898e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "acEl5EjAG6hd",
    "outputId": "9efce3d3-3074-4f2e-b660-4c6b2f0caf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XuGiXp6rG6hk",
    "outputId": "acc28bb5-470e-48c3-8e6c-354db61c19f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xb0EH5H_G6hq"
   },
   "outputs": [],
   "source": [
    "if do_sub_sampling_of_input:\n",
    "    x_, x_train, x_, y_train    = cross_validation.train_test_split(x_train, y_train, test_size=0.25, random_state=0)\n",
    "    x_, x_test,  y_, y_test    = cross_validation.train_test_split(x_test, y_test, test_size=0.25, random_state=0)\n",
    "    print(\"After SubSampling\")\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jz7L_trG6hv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if do_data_append :\n",
    "    print(\"Doing Data Appending\")\n",
    "    x_train = np.append(x_train, x_train,axis=0)\n",
    "    y_train = np.append(y_train, y_train,axis=0)\n",
    "#print(np.append(x_train, x_train,axis=0).shape)\n",
    "#print(np.append(y_train, y_train,axis=0).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MkHX4hNLG6h0",
    "outputId": "25cf1428-1767-461c-ced2-577e40a2dec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMuvM67DG6h8"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npxonLr5G6h-"
   },
   "outputs": [],
   "source": [
    "keras.utils.Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Tk4q4iYG6iD"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SeparableConv2D\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction densenet -BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock1(input, growth_rate, dropout_rate = 0.2, l = 0, weight_decay= 0.0001):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        #Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        #Conv2D_1_1 = Conv2D(int(num_filter*4*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same',\n",
    "                            kernel_initializer=\"he_uniform\", kernel_regularizer=l2(weight_decay))(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n",
    "        BatchNorm_1_1 = BatchNormalization()(Conv2D_1_1)\n",
    "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
    "        \n",
    "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same',\n",
    "                            kernel_initializer=\"he_uniform\", kernel_regularizer=l2(weight_decay))(relu_1_1)\n",
    "        #Conv2D_3_3 = SeparableConv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu_1_1)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eEu8gikG6iP"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, growth_rate, dropout_rate = 0.2, l = 0, weight_decay= 0.0001):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "        #Conv2D_3_3 = Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        #Conv2D_1_1 = Conv2D(int(num_filter*4*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same',\n",
    "                            kernel_initializer=\"he_uniform\")(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n",
    "        BatchNorm_1_1 = BatchNormalization()(Conv2D_1_1)\n",
    "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
    "        \n",
    "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same',\n",
    "                            kernel_initializer=\"he_uniform\")(relu_1_1)\n",
    "        #Conv2D_3_3 = SeparableConv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu_1_1)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition1(input, dropout_rate = 0.2, weight_decay= 0.0001):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    num_channels = int(input.shape[-1]) #assuming it is tensor\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_channels*compression), (1,1), use_bias=False ,padding='same', \n",
    "                               kernel_initializer=\"he_uniform\", kernel_regularizer=l2(weight_decay))(relu)\n",
    "    \n",
    "    #Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_transition(input, dropout_rate = 0.2, weight_decay= 0.0001):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    num_channels = int(input.shape[-1]) #assuming it is tensor\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_channels*compression), (1,1), use_bias=False ,padding='same', \n",
    "                               kernel_initializer=\"he_uniform\")(relu)\n",
    "    \n",
    "    #Conv2D_BottleNeck = Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer1(input, weight_decay= 0.0001):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    #flat = Dropout(0.25)(flat)\n",
    "    output = Dense(num_classes, activation='softmax', kernel_regularizer=l2(weight_decay))(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbzC-GOZG6ie"
   },
   "outputs": [],
   "source": [
    "def output_layer(input, weight_decay= 0.0001):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    #flat = Dropout(0.25)(flat)\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "#num_filter = 12\n",
    "num_filter = growth_rate = 12\n",
    "\n",
    "dropout_rate = 0.2\n",
    "#compression = 0.751\n",
    "compression = 0.5\n",
    "l = 16\n",
    "dense_l= [8, 16, 20, 12]\n",
    "dense_l= [12, 12, 12, 12]\n",
    "dense_l= [14, 14, 14, 14]\n",
    "\n",
    "weight_decay = 0.0001\n",
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(2*num_filter, (3,3), use_bias=False ,padding='same',\n",
    "                      kernel_initializer=\"he_uniform\", kernel_regularizer=l2(weight_decay))(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, growth_rate, dropout_rate, dense_l[0])\n",
    "First_Transition = add_transition(First_Block, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, growth_rate, dropout_rate, dense_l[1])\n",
    "Second_Transition = add_transition(Second_Block, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, growth_rate, dropout_rate, dense_l[2])\n",
    "Third_Transition = add_transition(Third_Block, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  growth_rate, dropout_rate, dense_l[3])\n",
    "output = output_layer(Last_Block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Printing and Verifying the Densenet-BC configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "p9uA_iR8G6io",
    "outputId": "87a7b724-7e86-416d-e7e9-6526b4bc860b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n",
      "(?, 32, 32, 24)\n",
      "(?, 32, 32, 192) 192\n",
      "(?, 16, 16, 96)\n",
      "(?, 16, 16, 264)\n",
      "(?, 8, 8, 132)\n",
      "(?, 8, 8, 300)\n",
      "(?, 4, 4, 150)\n",
      "(?, 4, 4, 318)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)\n",
    "print(First_Conv2D.shape)\n",
    "print(First_Block.shape, First_Block.shape[-1])\n",
    "print(First_Transition.shape)\n",
    "\n",
    "print(Second_Block.shape)\n",
    "print(Second_Transition.shape)\n",
    "\n",
    "print(Third_Block.shape)\n",
    "print(Third_Transition.shape)\n",
    "\n",
    "print(Last_Block.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 19618
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "7bc989ab-6517-466c-8120-25c63379a4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 48)   5760        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 48)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 48)   192         dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 32, 32, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 32, 32, 12)   5184        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 32, 32, 12)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 132)  0           concatenate_8[0][0]              \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 132)  528         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 32, 32, 132)  0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 32, 32, 48)   6336        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 32, 32, 48)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 48)   192         dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 32, 32, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 32, 32, 12)   5184        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 32, 32, 12)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 32, 32, 144)  0           concatenate_9[0][0]              \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 32, 32, 144)  576         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 32, 32, 144)  0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 32, 32, 48)   6912        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 32, 32, 48)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 32, 32, 48)   192         dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 32, 32, 48)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 32, 32, 12)   5184        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 32, 32, 12)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 32, 32, 156)  0           concatenate_10[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 32, 32, 156)  624         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 32, 32, 156)  0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 48)   7488        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 32, 32, 48)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 48)   192         dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 32, 32, 48)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 12)   5184        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 32, 32, 12)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 32, 32, 168)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 168)  672         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 32, 32, 168)  0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 48)   8064        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 32, 32, 48)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 48)   192         dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 32, 32, 48)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 12)   5184        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 32, 32, 12)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 32, 32, 180)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 32, 32, 180)  720         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 32, 32, 180)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 32, 32, 48)   8640        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 32, 32, 48)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 32, 32, 48)   192         dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 32, 32, 48)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 32, 32, 12)   5184        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 32, 32, 12)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 32, 32, 192)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 32, 32, 192)  768         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 32, 32, 192)  0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 32, 32, 96)   18432       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 32, 32, 96)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 96)   0           dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 96)   384         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 48)   4608        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 16, 16, 48)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 48)   192         dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 12)   5184        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16, 16, 12)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 108)  0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 108)  432         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 108)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 48)   5184        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 16, 16, 48)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 48)   192         dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 48)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 12)   5184        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 16, 16, 12)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 120)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 120)  480         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 120)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 48)   5760        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 12)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 132)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 132)  528         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 132)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 48)   6336        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 12)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 144)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 144)  576         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 144)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 48)   6912        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 12)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 156)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 156)  624         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 156)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 48)   7488        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 12)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 168)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 168)  672         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 168)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 48)   8064        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16, 16, 12)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 180)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 180)  720         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 180)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 48)   8640        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 48)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 12)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 192)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 192)  768         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 192)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 48)   9216        activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 48)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 12)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 204)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 204)  816         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 204)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 48)   9792        activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 48)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 12)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 216)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 216)  864         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 216)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 48)   10368       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 48)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 48)   192         dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 48)   0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 12)   5184        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 12)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 16, 16, 228)  0           concatenate_24[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 228)  912         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 228)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 48)   10944       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 48)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 48)   192         dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 48)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 12)   5184        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 16, 16, 12)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 16, 16, 240)  0           concatenate_25[0][0]             \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 16, 16, 240)  960         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 16, 16, 240)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 16, 16, 48)   11520       activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 16, 16, 48)   0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 16, 16, 48)   192         dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 16, 16, 48)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 16, 16, 12)   5184        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 16, 16, 12)   0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 16, 16, 252)  0           concatenate_26[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 16, 16, 252)  1008        concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 16, 16, 252)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 16, 16, 48)   12096       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 16, 16, 48)   0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 48)   192         dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 48)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 12)   5184        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 16, 16, 12)   0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 16, 16, 264)  0           concatenate_27[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 264)  1056        concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 264)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 132)  34848       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 16, 16, 132)  0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 132)    0           dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 132)    528         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 132)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 48)     6336        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 8, 8, 48)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 48)     192         dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 48)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 12)     5184        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 12)     0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 144)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 144)    576         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 144)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 48)     6912        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 8, 8, 48)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 48)     192         dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 48)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 12)     5184        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 8, 8, 12)     0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 156)    0           concatenate_29[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 156)    624         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 156)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 48)     7488        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 8, 8, 48)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 48)     192         dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 48)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 12)     5184        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 8, 8, 12)     0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 168)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 168)    672         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 168)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 48)     8064        activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 8, 8, 48)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 48)     192         dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 48)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 12)     5184        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 8, 8, 12)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 180)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 180)    720         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 180)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 48)     8640        activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 8, 48)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 12)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 192)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 192)    768         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 48)     9216        activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 8, 8, 48)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 8, 8, 12)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 204)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 204)    816         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 204)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 48)     9792        activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 8, 8, 48)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8, 8, 12)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 216)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 216)    864         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 216)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 48)     10368       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 8, 8, 48)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 228)    0           concatenate_35[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 228)    912         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 228)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 48)     10944       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 8, 8, 48)     0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 8, 8, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 8, 8, 240)    0           concatenate_36[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 240)    960         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 240)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 48)     11520       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 8, 8, 48)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 8, 8, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 8, 8, 252)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 252)    1008        concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 252)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 48)     12096       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 8, 8, 48)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8, 8, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 264)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 264)    1056        concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 264)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 48)     12672       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 48)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 276)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 276)    1104        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 276)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 48)     13248       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 48)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 288)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 288)    1152        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 288)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 48)     13824       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 48)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 300)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 300)    1200        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 300)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 150)    45000       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 150)    0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 150)    0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 4, 4, 150)    600         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 4, 4, 150)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 4, 4, 48)     7200        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 4, 4, 48)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 4, 4, 48)     192         dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 4, 4, 48)     0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 4, 4, 12)     5184        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 4, 4, 12)     0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 4, 4, 162)    0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 4, 4, 162)    648         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 4, 4, 162)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 4, 4, 48)     7776        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 4, 4, 48)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 4, 4, 48)     192         dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 4, 4, 48)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 4, 4, 12)     5184        activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 4, 4, 12)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 4, 4, 174)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 174)    696         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 174)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 48)     8352        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 4, 4, 48)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 48)     192         dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 48)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 12)     5184        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 4, 4, 12)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 186)    0           concatenate_44[0][0]             \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 186)    744         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 186)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 48)     8928        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 4, 4, 48)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 4, 4, 48)     192         dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 48)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 12)     5184        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 4, 4, 12)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 198)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 198)    792         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 198)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 48)     9504        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 4, 4, 48)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 48)     192         dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 48)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 12)     5184        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 4, 4, 12)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 210)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 210)    840         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 210)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 48)     10080       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 4, 4, 48)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 48)     192         dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 48)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 4, 12)     5184        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 4, 4, 12)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 4, 4, 222)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 222)    888         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 222)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 48)     10656       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 48)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 48)     192         dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 48)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 12)     5184        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 12)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 4, 4, 234)    0           concatenate_48[0][0]             \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 234)    936         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 234)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 48)     11232       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 48)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 48)     192         dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 48)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 12)     5184        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 12)     0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 4, 4, 246)    0           concatenate_49[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 246)    984         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 246)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 48)     11808       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 48)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 48)     192         dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 48)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 12)     5184        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 4, 4, 12)     0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 4, 4, 258)    0           concatenate_50[0][0]             \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 258)    1032        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 258)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 48)     12384       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 4, 4, 48)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 48)     192         dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 48)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 12)     5184        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 4, 4, 12)     0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 4, 4, 270)    0           concatenate_51[0][0]             \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 270)    1080        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 270)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 48)     12960       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 4, 4, 48)     0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 48)     192         dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 48)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 12)     5184        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 4, 4, 12)     0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 4, 4, 282)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 4, 4, 282)    1128        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 282)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 48)     13536       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 4, 4, 48)     0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 4, 48)     192         dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 48)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 12)     5184        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4, 4, 12)     0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 4, 4, 294)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 4, 294)    1176        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 294)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 48)     14112       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 4, 4, 48)     0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 48)     192         dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 48)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 12)     5184        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4, 12)     0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 4, 4, 306)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 306)    1224        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 306)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 4, 4, 48)     14688       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4, 4, 48)     0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 4, 48)     192         dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 48)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 4, 4, 12)     5184        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 12)     0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 4, 4, 318)    0           concatenate_55[0][0]             \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 4, 318)    1272        concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 318)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 2, 318)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1272)         0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           12730       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 936,802\n",
      "Trainable params: 909,286\n",
      "Non-trainable params: 27,516\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f68LtcYHG6i4"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 90\n",
    "decay = learning_rate/epochs\n",
    "decay = 0.0001\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Oj8RSwyG6i9"
   },
   "outputs": [],
   "source": [
    "#batch_size = 64\n",
    "#clr_triangular = CyclicLR(mode='triangular', base_lr = 0.1, max_lr = 0.2, step_size = (len(x_train)* 2 * 4)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HT7ZwHzG6jG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crhGk7kEhXAz"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcWydmIVhZGr"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 30.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7dl5K84G6jl"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay1(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epoch_drop_01 = 40\n",
    "    epoch_drop_02 = epoch_drop_01 + 40\n",
    "    epoch_drop_03 = epoch_drop_02 + 40\n",
    "    \n",
    "    if (epoch < epoch_drop_01):\n",
    "        lrate = initial_lrate\n",
    "    elif (epoch < epoch_drop_02):\n",
    "        lrate = initial_lrate * drop\n",
    "    else:\n",
    "        lrate = initial_lrate * drop * drop\n",
    "\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDig-b71G6jq"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(self, epoch, logs=None):\n",
    "    print(\"epoch: \", epoch,\"learning rate for\", K.eval(self.model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zjHHVfPG6jw"
   },
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aS6q4X1G6j0"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience= 4, min_delta=0.003, verbose=1, cooldown=0, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJgRsh_2G6j7"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZZuotjhG6kA"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#filepath = file_prefix + r\".best.hdf5\"\n",
    "filepath = \"DNST_CIFAR10_Conv_09_12-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L"
   },
   "outputs": [],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "#model.save_weights(\"densenet_tr_03-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#files.download('DNST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ir_fg-p9G6kO"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6HtNUyQG6kS"
   },
   "outputs": [],
   "source": [
    "class AdamTracker_0(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"start , epoch = \", epoch,\", lr = \", K.eval(optimizer.lr),\", decay = \",K.eval(optimizer.decay),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BtYHxTCG6kV"
   },
   "outputs": [],
   "source": [
    "class AdamTracker_1(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"end, epoch = \", epoch,\", lr = \", K.eval(optimizer.lr),\", decay = \",K.eval(optimizer.decay),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMe9lOY9G6kb"
   },
   "outputs": [],
   "source": [
    "adam_lr_tracker_1 = AdamTracker_1()\n",
    "adam_lr_tracker_0 = AdamTracker_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2iue0UsLDzb"
   },
   "outputs": [],
   "source": [
    "class SGDLearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"epoch = \", epoch,\", lr = \", K.eval(optimizer.lr), \", momentum = \",K.eval(optimizer.momentum),\n",
    "              \", decay = \",K.eval(optimizer.decay), \", Nestrov = \",optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-itoaFDG6kf"
   },
   "outputs": [],
   "source": [
    "sgd_lr_tracker = SGDLearningRateTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, reduce_on_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki7pVU60G6ko"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [adam_lr_tracker_0, adam_lr_tracker_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBTjYaJ4G6kv"
   },
   "outputs": [],
   "source": [
    "#callbacks_list = [checkpoint, adam_lr_tracker_0, adam_lr_tracker_1, clr_triangular]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhuPjscpK0mm"
   },
   "outputs": [],
   "source": [
    "#callbacks_list = [checkpoint, sgd_lr_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bTKPS9HG6kx"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "#model = load_model('densenet_tr_03-46-0.71.hdf5')\n",
    "#score = model.evaluate(x_test, y_test, verbose=1)\n",
    "#print('Test loss:', score[0])\n",
    "#print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OfdusR7aG6k1",
    "outputId": "f23665c5-6112-4dcc-d452-fae080e5ab70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-LiiCB9G6k8"
   },
   "source": [
    "## Call the model with the datagen, augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### running  with same setting as Model2_Adam_test.ipynb.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WKzwh45G6k8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZjsbZONG6lJ"
   },
   "outputs": [],
   "source": [
    "load_model_from_back = False\n",
    "\n",
    "if load_model_from_back:\n",
    "    model = load_model('----------------')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4114
    },
    "colab_type": "code",
    "id": "ODPSQd8dG6lM",
    "outputId": "0b061b74-5653-4c53-932e-04eb30c3664e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "start , epoch =  0 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 184s 235ms/step - loss: 1.5734 - acc: 0.4283 - val_loss: 1.3922 - val_acc: 0.5361\n",
      "end, epoch =  0 , lr =  0.001 , decay =  0.0\n",
      "Epoch 2/80\n",
      "start , epoch =  1 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 1.1683 - acc: 0.5845 - val_loss: 1.1952 - val_acc: 0.6215\n",
      "end, epoch =  1 , lr =  0.001 , decay =  0.0\n",
      "Epoch 3/80\n",
      "start , epoch =  2 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 0.9741 - acc: 0.6536 - val_loss: 1.2167 - val_acc: 0.6460\n",
      "end, epoch =  2 , lr =  0.001 , decay =  0.0\n",
      "Epoch 4/80\n",
      "start , epoch =  3 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 144s 184ms/step - loss: 0.8545 - acc: 0.6989 - val_loss: 0.9888 - val_acc: 0.7016\n",
      "end, epoch =  3 , lr =  0.001 , decay =  0.0\n",
      "Epoch 5/80\n",
      "start , epoch =  4 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 0.7713 - acc: 0.7318 - val_loss: 0.8286 - val_acc: 0.7391\n",
      "end, epoch =  4 , lr =  0.001 , decay =  0.0\n",
      "Epoch 6/80\n",
      "start , epoch =  5 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 0.7034 - acc: 0.7538 - val_loss: 0.9899 - val_acc: 0.7211\n",
      "end, epoch =  5 , lr =  0.001 , decay =  0.0\n",
      "Epoch 7/80\n",
      "start , epoch =  6 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.6508 - acc: 0.7755 - val_loss: 0.9016 - val_acc: 0.7412\n",
      "end, epoch =  6 , lr =  0.001 , decay =  0.0\n",
      "Epoch 8/80\n",
      "start , epoch =  7 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 0.6149 - acc: 0.7870 - val_loss: 0.8697 - val_acc: 0.7510\n",
      "end, epoch =  7 , lr =  0.001 , decay =  0.0\n",
      "Epoch 9/80\n",
      "start , epoch =  8 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.5799 - acc: 0.8004 - val_loss: 0.8130 - val_acc: 0.7732\n",
      "end, epoch =  8 , lr =  0.001 , decay =  0.0\n",
      "Epoch 10/80\n",
      "start , epoch =  9 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.5484 - acc: 0.8093 - val_loss: 0.6335 - val_acc: 0.8090\n",
      "end, epoch =  9 , lr =  0.001 , decay =  0.0\n",
      "Epoch 11/80\n",
      "start , epoch =  10 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.5246 - acc: 0.8197 - val_loss: 0.6240 - val_acc: 0.8120\n",
      "end, epoch =  10 , lr =  0.001 , decay =  0.0\n",
      "Epoch 12/80\n",
      "start , epoch =  11 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.5022 - acc: 0.8259 - val_loss: 0.7717 - val_acc: 0.7860\n",
      "end, epoch =  11 , lr =  0.001 , decay =  0.0\n",
      "Epoch 13/80\n",
      "start , epoch =  12 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.4827 - acc: 0.8315 - val_loss: 0.8434 - val_acc: 0.7722\n",
      "end, epoch =  12 , lr =  0.001 , decay =  0.0\n",
      "Epoch 14/80\n",
      "start , epoch =  13 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 146s 186ms/step - loss: 0.4652 - acc: 0.8383 - val_loss: 0.6071 - val_acc: 0.8262\n",
      "end, epoch =  13 , lr =  0.001 , decay =  0.0\n",
      "Epoch 15/80\n",
      "start , epoch =  14 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.4502 - acc: 0.8447 - val_loss: 0.6073 - val_acc: 0.8248\n",
      "end, epoch =  14 , lr =  0.001 , decay =  0.0\n",
      "Epoch 16/80\n",
      "start , epoch =  15 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 0.4341 - acc: 0.8509 - val_loss: 0.5739 - val_acc: 0.8282\n",
      "end, epoch =  15 , lr =  0.001 , decay =  0.0\n",
      "Epoch 17/80\n",
      "start , epoch =  16 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 185ms/step - loss: 0.4187 - acc: 0.8567 - val_loss: 0.6956 - val_acc: 0.8108\n",
      "end, epoch =  16 , lr =  0.001 , decay =  0.0\n",
      "Epoch 18/80\n",
      "start , epoch =  17 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 147s 188ms/step - loss: 0.4086 - acc: 0.8589 - val_loss: 0.6797 - val_acc: 0.8097\n",
      "end, epoch =  17 , lr =  0.001 , decay =  0.0\n",
      "Epoch 19/80\n",
      "start , epoch =  18 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 146s 186ms/step - loss: 0.4022 - acc: 0.8622 - val_loss: 0.5350 - val_acc: 0.8461\n",
      "end, epoch =  18 , lr =  0.001 , decay =  0.0\n",
      "Epoch 20/80\n",
      "start , epoch =  19 , lr =  0.001 , decay =  0.0\n",
      "782/781 [==============================] - 145s 186ms/step - loss: 0.3933 - acc: 0.8646 - val_loss: 0.6179 - val_acc: 0.8349\n",
      "end, epoch =  19 , lr =  0.001 , decay =  0.0\n",
      "Epoch 21/80\n",
      "start , epoch =  20 , lr =  0.001 , decay =  0.0\n",
      "126/781 [===>..........................] - ETA: 1:56 - loss: 0.3690 - acc: 0.8751"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-095345c19fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         callbacks=callbacks_list)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     model.fit(x_train, y_train,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 1.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWYRrcp7G6mv"
   },
   "source": [
    "### Stopped early as it does not seem to converge faster than normal Model-2 with 936K params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DNST_CIFAR10_Conv_09.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
