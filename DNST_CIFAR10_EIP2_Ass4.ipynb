{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assingnement 4\n",
    "\n",
    "### Objective: Obtain an accuracy of 92% using denent trained using SGD under 250 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Result : \n",
    "\n",
    "  - Model-1 **982K params**\n",
    "    - Densenet-BC model with 4 Denseblocks with layers [8,6,20,12], growth rate= 12, , compression = 0.5, dropout = 0.2\n",
    "    \n",
    "    - Achieved 90.15 (given in the log, 132th epoch = 63 + 69)\n",
    "    \n",
    "    - Achieved 90.61  but by this time the connection got disconnected, the model achieved 90.65% with in the give number of ephcs, however I have load the weights and shown the verifcation (226th epoch = 63 + 163)\n",
    "              \n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Apporach:\n",
    "\n",
    "Step 1. exploratory analysis\n",
    "\n",
    "   - check if data distribution fine\t\n",
    "    \n",
    "Step 2. Data preprocessng\n",
    "\n",
    "   - Normalise the data before feeding the network\n",
    "    \n",
    "Step 3. Data Augmentation\n",
    "\n",
    "   - this is complex network so we need more samples for the model to generalize well\n",
    "   \n",
    "   - we applied an intial augmentaion in **ImageDataGenerator()**\n",
    "   \n",
    "       - rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "       - width_shift_range=0.20,  # randomly shift images horizontally (fraction of total width)\n",
    "       - height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "       - horizontal_flip=True,  # randomly flip images\n",
    "\n",
    "\n",
    "  - the above augmentation looked insufficent and later we changed to the following settngs\n",
    "  - also looking at the wrong prediction it was partial images and cats and dogs which got mispredcicted a lot\n",
    "  \n",
    "    - rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    - width_shift_range=0.25,  # randomly shift images horizontally (fraction of total width)\n",
    "    - height_shift_range=0.25,  # randomly shift images vertically (fraction of total height)\n",
    "    - horizontal_flip=True,  # randomly flip images\t\n",
    "\n",
    "#### Getting the right model and fine tuning the architecure\n",
    "\n",
    "Step 5. Correcting the current code (**This was the most tricky part**)\n",
    "\n",
    "   - Checked if given code for the model is correct.\n",
    "   \n",
    "   - referred the densent paper [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993) and checked online densent to verify whether my code is correct or not?\n",
    "   \n",
    "   - there was few corrections needed in the given code\n",
    "   \n",
    "   - Implemented Bottle neck layer, transitin  correctly in the given code\n",
    "\n",
    "Step 6 - Getting the correct architecture\n",
    "\n",
    "- aim was to use all the 1M parameter allowed\n",
    "\n",
    "- I implemented two **Densent-BC** models\n",
    "\n",
    "- Model-1 **982K params**\n",
    "    - 4 Denseblocks with layers [8,6,20,12], growth rate= 12, , compression = 0.5, dropout = 0.2\n",
    "    \n",
    "- Model-2 **936K params**\n",
    "    - 4 Denseblocks with layer  [14,14,14,14], growth rate= 12, compression = 0.5, dropout = 0.2\n",
    "    \n",
    "- 3 Denseblock layer \n",
    "    - it was tried  [16, 16, 16] but performance was not good so dorrpped\n",
    "\n",
    "Step 6. **Check if the chosen models will achive 92% target**\n",
    "\n",
    "-  training with **SGD()** is not going to be easy, so I tested the selected models using **Adam()** , both the models I chose got more than 92 acccurcy\n",
    "       \n",
    "    - logs - Model-1 achieved 92% with Adam()\n",
    "        - Model1_Adam_test.ipynb (in https://github.com/TonyIssacJames/EIP2_Ass4)\n",
    "\n",
    "    - logs - Model-2 achieved 92% with Adam()\n",
    "        -  Model2_Adam_test.ipynb (in https://github.com/TonyIssacJames/EIP2_Ass4)\n",
    "        - this seemed to converge slightly faster than the first one\n",
    "       \n",
    "       \n",
    "Step X. Training\n",
    "\n",
    "   - in the densent paper they trained the network for 300 epohcs\n",
    "      - varying the learning rate (**lr**) in the following way.\n",
    "      - lr = 0.1 for 150 epochs (50% of epochs)\n",
    "      - lr = 0.01 for next 75 epohcs ( 25%)\n",
    "      - lr = 0.001 for last 75 epochs (25%)\n",
    "      \n",
    "  - I treid to follow a similiar distribution among 250 epocs.\n",
    "       anothere thought was perormance improemnt from the last 25% epochs(lr = 0.001) is less in the paper\n",
    "       so 150, 75, 25 to use the same split and train less using (lr = 0.001)\n",
    " \n",
    "Step X. increace batch size instead of reducing leaning rate\n",
    "\n",
    "   - paper \"DONâ€™T DECAY THE LEARNING RATE, INCREASE THE BATCH SIZE\" (https://openreview.net/pdf?id=B1Yy1BxCZ)\n",
    "\n",
    "   - I tried learning rate schdule manulal start and stop to reduce learning rate over time \n",
    "      but that does not seem to be worked.\n",
    "      \n",
    "   - This paper talks about a method of increasing batch size instead of reducint lr.\n",
    "      basically they tell that reducing leaning rate by half is eqivalient to increacing batch size by 2.\n",
    "      \n",
    "   - I tried this technique to get the last push, seemed to be working but could not get pass the 92% mark\n",
    "      \n",
    "Step 9. Other appoaches tried \n",
    "\n",
    "   - tried kernel_initializer='he_normal' did not showed any differnce\n",
    "      - log\n",
    "      \n",
    "   - tried cycling learning rate did not seem to help\n",
    "\n",
    "   - Tried Sperable Convolution so I could increace the capcity,\n",
    "       - the model capacity was increased to \n",
    "       - Model-2 improved, became [16, 16, 18, 16] **957K parmas**\n",
    "     \n",
    "    \n",
    "Step 9. Other appoaches tried \n",
    "   - Model-2 improved, is under training will update the results, early results seems good\n",
    "   - DNST_CIFAR10_Conv_09_10_final_1.ipynb (in https://github.com/TonyIssacJames/EIP2_Ass4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "a0dba4c3-f402-4223-ea89-3be41ca275fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "#!pip install -q keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "756bdmamG6f1",
    "outputId": "2f1c4951-b47b-40a0-ab02-1c97fd7c1a95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhIk-iu4G6f-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBoa2F25G6gE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "#l = 40\n",
    "#num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Training options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWRR6JyzG6gT"
   },
   "outputs": [],
   "source": [
    "do_sub_sampling_of_input = False # for fast training use only 25 % of data\n",
    "do_data_augmentation = True    # data augmentaion\n",
    "do_data_append       = False   # data becomes 2X sized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "16a221e4-1075-49d1-9d76-8091d240f280"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_hYUAbsG6ge"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "class_name = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "00iNYJLkG6gj",
    "outputId": "4911e408-9a52-4009-eefd-44e5242fb219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6], dtype=uint8), 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], img_height, img_width, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS5X5srxG6gp"
   },
   "outputs": [],
   "source": [
    "def draw_img(i, x_train, y_train, class_name):\n",
    "    im = x_train[i]\n",
    "    c = y_train[i]\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Class %d (%s)\" % (int(c), class_name[int(c)]))\n",
    "    plt.axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "mjF2KvIQG6gw",
    "outputId": "6c7a984d-4db5-4d5b-d110-b740edd41a02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_img(7, x_train, y_train, class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to dispaly and analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These helper functions\n",
    "\n",
    "plot_confusion_matrix(): helps us to plot the confusion matrix. \n",
    "It is taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html. \n",
    "The same page has some sample examples on how to use this function \n",
    "cm: Confusion matrix calcualted using confusion_matrix() from sklearn.metrics <br//> classes: a list of labels for the classes we are plotting\n",
    "normalize=False: True means we will plot nomalized values \n",
    "title='Confusion matrix': set the tiltle of the plot \n",
    "cmap : leave it as it is \n",
    "Example Usage:plot_confusion_matrix(cm, classes=Facial_Expressions, normalize=True, title='Test Data - Using Simple Average Ensembling ')\n",
    "\n",
    "plot_histogram(): helps to plot the histogram of a list \n",
    "lst_data: the list whose histogtam we want to plot , \n",
    "class_labels: a list of labels for the classes we are plotting \n",
    "ylabel='None': set the y label of the plot, x label is always frequency \n",
    "title='None': set the tiltle of the plot -lst_data, class_labels, ylabel='None', title='None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm) #to print in text if needed\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_histogram(lst_data, class_labels, ylabel='None', title='None'):\n",
    "    data = pd.Series(lst_data)\n",
    "    distribution = data.value_counts(sort=False)\n",
    "    y_pos = np.arange(len(class_labels))\n",
    "    \n",
    "    plt.bar(y_pos, distribution, align='center', alpha=0.8)\n",
    "    plt.xticks(y_pos, class_labels)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = ['airplane', 'automobile', 'bird','cat', 'deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulalising the data, check for class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(list(y_train), y_classes, ylabel='Frequency',title='CIFAR 10 Class Distribution in Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(list(y_test), y_classes, ylabel='Frequency',title='CIFAR 10 Class Distribution in Test Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmdwlu8pG6g3"
   },
   "outputs": [],
   "source": [
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JGd4ezgG6g7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "z_arXgOSG6hA",
    "outputId": "8960acf7-335b-4c96-9ae9-7fe9b9ad56fc"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "jd2usuXDG6hH",
    "outputId": "a0716d82-94e5-4f1b-ba28-39b1cdced01b"
   },
   "source": [
    "##  Normalising the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "T372AU6RG6hN",
    "outputId": "4739d668-5818-4f70-e6d3-3491edcb274c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Mean :  [[[[125.3069  122.95015 113.866  ]]]]\n",
      "Channel Std :  [[[[62.99325  62.088604 66.70501 ]]]]\n",
      "Channel Mean1 :  [[[[126.02428 123.70843 114.85442]]]]\n",
      "Channel Std1 :  [[[[62.896416 61.937508 66.70607 ]]]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "mean  = np.mean(x_train, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "std   = np.std(x_train, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "\n",
    "mean1  = np.mean(x_test, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "std1   = np.std(x_test, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "\n",
    "\n",
    "print(\"Channel Mean : \", mean)\n",
    "print(\"Channel Std : \", std)\n",
    "print(\"Channel Mean1 : \", mean1)\n",
    "print(\"Channel Std1 : \", std1)\n",
    "\n",
    "\n",
    "\n",
    "x_train = (x_train - mean) / (std)\n",
    "x_test  = (x_test - mean1) / (std1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOCMAYM1G6hT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After normalisation input looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZF74U6zcG6hX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0526032e+00, -9.8166406e-01, -7.6255137e-01],\n",
       "        [-1.3065987e+00, -1.2393603e+00, -1.0323962e+00],\n",
       "        [-1.1954757e+00, -1.2071482e+00, -1.0623789e+00],\n",
       "        ...,\n",
       "        [ 5.1899368e-01,  1.4575703e-01, -8.7939382e-02],\n",
       "        [ 4.2374539e-01,  3.3014923e-02, -1.7788765e-01],\n",
       "        [ 3.6024651e-01,  1.6908908e-02, -1.6289628e-01]],\n",
       "\n",
       "       [[-1.7352160e+00, -1.6581167e+00, -1.4071807e+00],\n",
       "        [-1.9892114e+00, -1.9802370e+00, -1.7070082e+00],\n",
       "        [-1.7034665e+00, -1.8513888e+00, -1.7070082e+00],\n",
       "        ...,\n",
       "        [-3.6621384e-02, -5.6290764e-01, -8.8248241e-01],\n",
       "        [-1.0012025e-01, -6.4343774e-01, -9.5743930e-01],\n",
       "        [-5.2496098e-02, -5.7901365e-01, -8.5249966e-01]],\n",
       "\n",
       "       [[-1.5923436e+00, -1.5936927e+00, -1.3921893e+00],\n",
       "        [-1.7352160e+00, -1.8674948e+00, -1.7070082e+00],\n",
       "        [-1.2113504e+00, -1.5453745e+00, -1.5870771e+00],\n",
       "        ...,\n",
       "        [-1.1599497e-01, -6.2733167e-01, -9.5743930e-01],\n",
       "        [-8.4245533e-02, -6.2733167e-01, -9.5743930e-01],\n",
       "        [-2.5886741e-01, -8.0449790e-01, -1.0773703e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.3127295e+00,  7.5778562e-01, -2.6783592e-01],\n",
       "        [ 1.2016065e+00,  4.8398334e-01, -1.1973014e+00],\n",
       "        [ 1.1539823e+00,  6.1283147e-01, -1.3172324e+00],\n",
       "        ...,\n",
       "        [ 5.5074310e-01,  1.6186304e-01, -6.5761173e-01],\n",
       "        [-1.1002274e+00, -1.4809505e+00, -1.6020685e+00],\n",
       "        [-1.1478515e+00, -1.4326324e+00, -1.4071807e+00]],\n",
       "\n",
       "       [[ 8.6823744e-01,  2.5849915e-01, -2.6783592e-01],\n",
       "        [ 7.5711441e-01,  8.0289232e-04, -1.0773703e+00],\n",
       "        [ 9.6348572e-01,  3.3902922e-01, -1.2572669e+00],\n",
       "        ...,\n",
       "        [ 9.3173629e-01,  4.0345326e-01, -2.9781866e-01],\n",
       "        [-4.4936401e-01, -9.8166406e-01, -1.1973014e+00],\n",
       "        [-6.7161006e-01, -1.1266181e+00, -1.1973014e+00]],\n",
       "\n",
       "       [[ 8.2061332e-01,  3.3902922e-01,  3.1991642e-02],\n",
       "        [ 6.7774087e-01,  9.7438984e-02, -2.9781866e-01],\n",
       "        [ 8.5236275e-01,  3.0681717e-01, -4.0275833e-01],\n",
       "        ...,\n",
       "        [ 1.4397272e+00,  9.8326981e-01,  3.9178470e-01],\n",
       "        [ 4.0787068e-01, -7.9727180e-02, -4.4773245e-01],\n",
       "        [-3.6621384e-02, -4.9848357e-01, -6.2762898e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "acEl5EjAG6hd",
    "outputId": "9efce3d3-3074-4f2e-b660-4c6b2f0caf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XuGiXp6rG6hk",
    "outputId": "acc28bb5-470e-48c3-8e6c-354db61c19f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xb0EH5H_G6hq"
   },
   "outputs": [],
   "source": [
    "if do_sub_sampling_of_input:\n",
    "    x_, x_train, x_, y_train    = cross_validation.train_test_split(x_train, y_train, test_size=0.25, random_state=0)\n",
    "    x_, x_test,  y_, y_test    = cross_validation.train_test_split(x_test, y_test, test_size=0.25, random_state=0)\n",
    "    print(\"After SubSampling\")\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jz7L_trG6hv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if do_data_append :\n",
    "    print(\"Doing Data Appending\")\n",
    "    x_train = np.append(x_train, x_train,axis=0)\n",
    "    y_train = np.append(y_train, y_train,axis=0)\n",
    "#print(np.append(x_train, x_train,axis=0).shape)\n",
    "#print(np.append(y_train, y_train,axis=0).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MkHX4hNLG6h0",
    "outputId": "25cf1428-1767-461c-ced2-577e40a2dec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMuvM67DG6h8"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npxonLr5G6h-"
   },
   "outputs": [],
   "source": [
    "keras.utils.Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Tk4q4iYG6iD"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SeparableConv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction densenet -BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, growth_rate, dropout_rate = 0.2, l = 0):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "\n",
    "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n",
    "        BatchNorm_1_1 = BatchNormalization()(Conv2D_1_1)\n",
    "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
    "        \n",
    "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same')(relu_1_1)\n",
    "        #Conv2D_3_3 = SeparableConv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu_1_1) # later tried this\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eEu8gikG6iP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    num_channels = int(input.shape[-1]) #assuming it is tensor\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_channels*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    \n",
    "\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    #flat = Dropout(0.25)(flat) # tried this, did not help\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbzC-GOZG6ie"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "num_filter = growth_rate = 12\n",
    "dropout_rate = 0.2\n",
    "compression = 0.5\n",
    "dense_l= [8, 16, 20, 12]\n",
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(2*num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, growth_rate, dropout_rate, dense_l[0])\n",
    "First_Transition = add_transition(First_Block, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, growth_rate, dropout_rate, dense_l[1])\n",
    "Second_Transition = add_transition(Second_Block, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate, dense_l[2])\n",
    "Third_Transition = add_transition(Third_Block, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  growth_rate, dropout_rate, dense_l[3])\n",
    "output = output_layer(Last_Block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing and Verifying the Densenet-BC configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "p9uA_iR8G6io",
    "outputId": "87a7b724-7e86-416d-e7e9-6526b4bc860b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n",
      "(?, 32, 32, 24)\n",
      "(?, 32, 32, 120) 120\n",
      "(?, 16, 16, 60)\n",
      "(?, 16, 16, 252)\n",
      "(?, 8, 8, 126)\n",
      "(?, 8, 8, 366)\n",
      "(?, 4, 4, 183)\n",
      "(?, 4, 4, 327)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)\n",
    "print(First_Conv2D.shape)\n",
    "print(First_Block.shape, First_Block.shape[-1])\n",
    "print(First_Transition.shape)\n",
    "\n",
    "print(Second_Block.shape)\n",
    "print(Second_Transition.shape)\n",
    "\n",
    "print(Third_Block.shape)\n",
    "print(Third_Transition.shape)\n",
    "\n",
    "print(Last_Block.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 19618
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "7bc989ab-6517-466c-8120-25c63379a4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 60)   7200        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 60)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 60)   0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 60)   240         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 60)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 48)   2880        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 48)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 48)   192         dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 48)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 12)   5184        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 12)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 72)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 72)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 48)   3456        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 48)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 48)   192         dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 12)   5184        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 12)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 84)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 84)   336         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 84)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 48)   4032        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 48)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 48)   192         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 12)   5184        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 12)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 96)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   384         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 48)   4608        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 48)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 48)   192         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 48)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 12)   5184        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 12)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 108)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 108)  432         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 108)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 48)   5184        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 16, 16, 48)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 48)   192         dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 48)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 12)   5184        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16, 16, 12)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 120)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 120)  480         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 120)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 48)   5760        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 16, 16, 48)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 48)   192         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 12)   5184        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 16, 16, 12)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 132)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 132)  528         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 132)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 48)   6336        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 16, 16, 48)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 48)   192         dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 12)   5184        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16, 16, 12)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 144)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 144)  576         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 144)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 48)   6912        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 16, 16, 48)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 48)   192         dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 48)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 12)   5184        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 16, 16, 12)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 156)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 156)  624         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 156)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 48)   7488        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 12)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 168)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 168)  672         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 168)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 48)   8064        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 12)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 180)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 180)  720         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 180)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 48)   8640        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 12)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 192)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 192)  768         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 48)   9216        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 12)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 204)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 204)  816         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 204)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 48)   9792        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16, 16, 12)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 216)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 216)  864         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 216)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 48)   10368       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 48)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 12)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 228)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 228)  912         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 228)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 48)   10944       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 48)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 12)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 240)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 240)  960         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 240)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 48)   11520       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 48)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 12)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 252)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 252)  1008        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 252)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 126)  31752       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 126)  0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 126)    0           dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 126)    504         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 126)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 48)     6048        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 8, 8, 48)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 48)     192         dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 48)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 12)     5184        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 8, 8, 12)     0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 138)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 138)    552         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 138)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 48)     6624        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 8, 8, 48)     0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 48)     192         dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 48)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 12)     5184        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8, 8, 12)     0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 150)    0           concatenate_25[0][0]             \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 150)    600         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 150)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 48)     7200        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8, 8, 48)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 48)     192         dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 48)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 12)     5184        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 8, 8, 12)     0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 162)    0           concatenate_26[0][0]             \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 162)    648         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 162)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 48)     7776        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 8, 8, 48)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 48)     192         dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 48)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 12)     5184        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 8, 8, 12)     0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 174)    0           concatenate_27[0][0]             \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 174)    696         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 174)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 48)     8352        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 8, 8, 48)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 48)     192         dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 48)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 12)     5184        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 12)     0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 186)    0           concatenate_28[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 186)    744         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 186)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 48)     8928        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 8, 8, 48)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 48)     192         dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 48)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 12)     5184        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 8, 8, 12)     0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 198)    0           concatenate_29[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 198)    792         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 198)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 48)     9504        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 8, 8, 48)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 48)     192         dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 48)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 12)     5184        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 8, 8, 12)     0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 210)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 210)    840         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 210)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 48)     10080       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 8, 8, 48)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 48)     192         dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 48)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 12)     5184        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 8, 8, 12)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 222)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 222)    888         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 222)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 48)     10656       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 8, 48)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 12)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 234)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 234)    936         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 234)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 48)     11232       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 8, 8, 48)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 8, 8, 12)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 246)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 246)    984         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 246)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 48)     11808       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 8, 8, 48)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8, 8, 12)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 258)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 258)    1032        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 258)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 48)     12384       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 8, 8, 48)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 270)    0           concatenate_35[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 270)    1080        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 270)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 48)     12960       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 8, 8, 48)     0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 8, 8, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 8, 8, 282)    0           concatenate_36[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 282)    1128        concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 282)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 48)     13536       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 8, 8, 48)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 8, 8, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 8, 8, 294)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 294)    1176        concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 294)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 48)     14112       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 8, 8, 48)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8, 8, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 306)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 306)    1224        concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 306)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 48)     14688       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 48)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 318)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 318)    1272        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 318)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 48)     15264       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 48)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 330)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 330)    1320        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 330)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 48)     15840       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 48)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 342)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 342)    1368        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 342)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 48)     16416       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 48)     0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 48)     192         dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 48)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 12)     5184        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 12)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 354)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 354)    1416        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 354)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 48)     16992       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 48)     0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 48)     192         dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 48)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 12)     5184        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 12)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 366)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 366)    1464        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 366)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 183)    66978       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 183)    0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 183)    0           dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 183)    732         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 183)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 48)     8784        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 4, 4, 48)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 48)     192         dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 48)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 12)     5184        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 4, 4, 12)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 195)    0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 195)    780         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 195)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 48)     9360        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 4, 4, 48)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_95 (BatchNo (None, 4, 4, 48)     192         dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 48)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 12)     5184        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 4, 4, 12)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 207)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 207)    828         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 207)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 48)     9936        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 4, 4, 48)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 48)     192         dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 48)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 12)     5184        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 4, 4, 12)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 219)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 219)    876         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 219)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 48)     10512       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 4, 4, 48)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 48)     192         dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 48)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 4, 12)     5184        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 4, 4, 12)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 4, 4, 231)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 231)    924         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 231)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 48)     11088       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 48)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 48)     192         dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 48)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 12)     5184        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 12)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 4, 4, 243)    0           concatenate_48[0][0]             \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 243)    972         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 243)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 48)     11664       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 48)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 48)     192         dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 48)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 12)     5184        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 12)     0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 4, 4, 255)    0           concatenate_49[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 255)    1020        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 255)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 48)     12240       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 48)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 48)     192         dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 48)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 12)     5184        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 4, 4, 12)     0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 4, 4, 267)    0           concatenate_50[0][0]             \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 267)    1068        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 267)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 48)     12816       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 4, 4, 48)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 48)     192         dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 48)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 12)     5184        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 4, 4, 12)     0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 4, 4, 279)    0           concatenate_51[0][0]             \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 279)    1116        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 279)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 48)     13392       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 4, 4, 48)     0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 48)     192         dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 48)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 12)     5184        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 4, 4, 12)     0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 4, 4, 291)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 4, 4, 291)    1164        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 291)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 48)     13968       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 4, 4, 48)     0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 4, 48)     192         dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 48)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 12)     5184        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4, 4, 12)     0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 4, 4, 303)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 4, 303)    1212        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 303)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 48)     14544       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 4, 4, 48)     0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 48)     192         dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 48)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 12)     5184        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4, 12)     0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 4, 4, 315)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 315)    1260        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 315)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 4, 4, 48)     15120       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4, 4, 48)     0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 4, 48)     192         dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 48)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 4, 4, 12)     5184        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 12)     0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 4, 4, 327)    0           concatenate_55[0][0]             \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 4, 327)    1308        concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 327)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 2, 327)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1308)         0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           13090       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 982,216\n",
      "Trainable params: 953,278\n",
      "Non-trainable params: 28,938\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settinng the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f68LtcYHG6i4"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 90\n",
    "decay = learning_rate/epochs\n",
    "decay = 0.0001\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Oj8RSwyG6i9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HT7ZwHzG6jG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crhGk7kEhXAz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to adjust learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycling learning rate was enabled before\n",
    "#batch_size = 64\n",
    "#clr_triangular = CyclicLR(mode='triangular', base_lr = 0.1, max_lr = 0.2, step_size = (len(x_train)* 2 * 4)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcWydmIVhZGr"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 30.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7dl5K84G6jl"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay1(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epoch_drop_01 = 40\n",
    "    epoch_drop_02 = epoch_drop_01 + 40\n",
    "    epoch_drop_03 = epoch_drop_02 + 40\n",
    "    \n",
    "    if (epoch < epoch_drop_01):\n",
    "        lrate = initial_lrate\n",
    "    elif (epoch < epoch_drop_02):\n",
    "        lrate = initial_lrate * drop\n",
    "    else:\n",
    "        lrate = initial_lrate * drop * drop\n",
    "\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDig-b71G6jq"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(self, epoch, logs=None):\n",
    "    print(\"epoch: \", epoch,\"learning rate for\", K.eval(self.model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zjHHVfPG6jw"
   },
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aS6q4X1G6j0"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience= 4, min_delta=0.003, verbose=1, cooldown=0, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJgRsh_2G6j7"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZZuotjhG6kA"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#filepath = file_prefix + r\".best.hdf5\"\n",
    "filepath = \"DNST_CIFAR10_Conv_09_09_final_tr2-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L"
   },
   "outputs": [],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "#model.save_weights(\"densenet_tr_03-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#files.download('DNST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ir_fg-p9G6kO"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6HtNUyQG6kS"
   },
   "outputs": [],
   "source": [
    "class AdamTracker_0(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"start , epoch = \", epoch,\", lr = \", K.eval(optimizer.lr),\", decay = \",K.eval(optimizer.decay),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BtYHxTCG6kV"
   },
   "outputs": [],
   "source": [
    "class AdamTracker_1(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"end, epoch = \", epoch,\", lr = \", K.eval(optimizer.lr),\", decay = \",K.eval(optimizer.decay),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMe9lOY9G6kb"
   },
   "outputs": [],
   "source": [
    "adam_lr_tracker_1 = AdamTracker_1()\n",
    "adam_lr_tracker_0 = AdamTracker_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2iue0UsLDzb"
   },
   "outputs": [],
   "source": [
    "class SGDLearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"epoch = \", epoch,\", lr = \", K.eval(optimizer.lr), \", momentum = \",K.eval(optimizer.momentum),\n",
    "              \", decay = \",K.eval(optimizer.decay), \", Nestrov = \",optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting call backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-itoaFDG6kf"
   },
   "outputs": [],
   "source": [
    "sgd_lr_tracker = SGDLearningRateTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, reduce_on_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki7pVU60G6ko"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [adam_lr_tracker_0, adam_lr_tracker_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBTjYaJ4G6kv"
   },
   "outputs": [],
   "source": [
    "#callbacks_list = [checkpoint, adam_lr_tracker_0, adam_lr_tracker_1, clr_triangular]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhuPjscpK0mm"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, sgd_lr_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bTKPS9HG6kx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OfdusR7aG6k1",
    "outputId": "f23665c5-6112-4dcc-d452-fae080e5ab70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-LiiCB9G6k8"
   },
   "source": [
    "## Train the model with the datagen, augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WKzwh45G6k8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZjsbZONG6lJ"
   },
   "outputs": [],
   "source": [
    "load_model_from_back = False\n",
    "\n",
    "if load_model_from_back:\n",
    "    model = load_model('--------------')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.9\n",
      "1e-04\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "k.set_value(model.optimizer.lr, 0.1)\n",
    "k.set_value(model.optimizer.momentum, 0.9)\n",
    "\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print(K.eval(model.optimizer.momentum))\n",
    "print(K.eval(model.optimizer.decay))\n",
    "print(model.optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train the model for 120 epochs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4114
    },
    "colab_type": "code",
    "id": "ODPSQd8dG6lM",
    "outputId": "0b061b74-5653-4c53-932e-04eb30c3664e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "391/390 [==============================] - 111s 283ms/step - loss: 2.1374 - acc: 0.2882 - val_loss: 1.7219 - val_acc: 0.3712\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.11190 to 0.37120, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-01-0.3712.hdf5\n",
      "epoch =  0 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 2/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 1.6473 - acc: 0.3983 - val_loss: 1.5223 - val_acc: 0.4480\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37120 to 0.44800, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-02-0.4480.hdf5\n",
      "epoch =  1 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 3/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 1.4703 - acc: 0.4662 - val_loss: 1.3615 - val_acc: 0.5148\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.44800 to 0.51480, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-03-0.5148.hdf5\n",
      "epoch =  2 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 4/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 1.3287 - acc: 0.5221 - val_loss: 1.3106 - val_acc: 0.5371\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.51480 to 0.53710, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-04-0.5371.hdf5\n",
      "epoch =  3 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 5/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 1.1919 - acc: 0.5722 - val_loss: 1.2037 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.53710 to 0.59250, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-05-0.5925.hdf5\n",
      "epoch =  4 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 6/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 1.0717 - acc: 0.6198 - val_loss: 1.2001 - val_acc: 0.6185\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.59250 to 0.61850, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-06-0.6185.hdf5\n",
      "epoch =  5 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 7/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.9899 - acc: 0.6492 - val_loss: 0.9722 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61850 to 0.67840, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-07-0.6784.hdf5\n",
      "epoch =  6 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 8/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.9201 - acc: 0.6752 - val_loss: 1.2207 - val_acc: 0.6340\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.67840\n",
      "epoch =  7 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 9/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.8728 - acc: 0.6880 - val_loss: 0.9466 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.67840 to 0.69030, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-09-0.6903.hdf5\n",
      "epoch =  8 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 10/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.8273 - acc: 0.7057 - val_loss: 0.9207 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.69030 to 0.70770, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-10-0.7077.hdf5\n",
      "epoch =  9 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 11/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.7909 - acc: 0.7195 - val_loss: 0.8792 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.70770 to 0.72840, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-11-0.7284.hdf5\n",
      "epoch =  10 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 12/120\n",
      "391/390 [==============================] - 78s 198ms/step - loss: 0.7524 - acc: 0.7353 - val_loss: 1.0241 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72840\n",
      "epoch =  11 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 13/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.7297 - acc: 0.7410 - val_loss: 0.7647 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.72840 to 0.75720, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-13-0.7572.hdf5\n",
      "epoch =  12 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 14/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.7019 - acc: 0.7499 - val_loss: 0.7821 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75720\n",
      "epoch =  13 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 15/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.6750 - acc: 0.7590 - val_loss: 0.8414 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75720\n",
      "epoch =  14 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 16/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.6543 - acc: 0.7680 - val_loss: 0.8598 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75720\n",
      "epoch =  15 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 17/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.6286 - acc: 0.7800 - val_loss: 0.7463 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.75720 to 0.77480, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-17-0.7748.hdf5\n",
      "epoch =  16 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 18/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.6083 - acc: 0.7860 - val_loss: 0.8252 - val_acc: 0.7553\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77480\n",
      "epoch =  17 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 19/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5939 - acc: 0.7915 - val_loss: 0.6309 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.77480 to 0.80040, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-19-0.8004.hdf5\n",
      "epoch =  18 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 20/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5698 - acc: 0.7988 - val_loss: 0.6121 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.80040 to 0.80680, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-20-0.8068.hdf5\n",
      "epoch =  19 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 21/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.5551 - acc: 0.8054 - val_loss: 0.6963 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80680\n",
      "epoch =  20 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 22/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5427 - acc: 0.8085 - val_loss: 0.7184 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80680\n",
      "epoch =  21 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 23/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.5272 - acc: 0.8140 - val_loss: 0.6207 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.80680 to 0.81190, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-23-0.8119.hdf5\n",
      "epoch =  22 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 24/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5093 - acc: 0.8211 - val_loss: 0.7517 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.81190\n",
      "epoch =  23 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 25/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4940 - acc: 0.8283 - val_loss: 0.6703 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.81190\n",
      "epoch =  24 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 26/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4873 - acc: 0.8304 - val_loss: 0.6151 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.81190 to 0.81570, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-26-0.8157.hdf5\n",
      "epoch =  25 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 27/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4723 - acc: 0.8328 - val_loss: 0.6205 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.81570\n",
      "epoch =  26 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 28/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 77s 197ms/step - loss: 0.4670 - acc: 0.8364 - val_loss: 0.6365 - val_acc: 0.8114\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.81570\n",
      "epoch =  27 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 29/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.4545 - acc: 0.8403 - val_loss: 0.6620 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.81570\n",
      "epoch =  28 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 30/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.4431 - acc: 0.8430 - val_loss: 0.5758 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.81570 to 0.82640, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-30-0.8264.hdf5\n",
      "epoch =  29 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 31/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4358 - acc: 0.8453 - val_loss: 0.6433 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82640\n",
      "epoch =  30 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 32/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.4305 - acc: 0.8488 - val_loss: 0.6561 - val_acc: 0.8143\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82640\n",
      "epoch =  31 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 33/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.4190 - acc: 0.8527 - val_loss: 0.6595 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.82640\n",
      "epoch =  32 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 34/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4118 - acc: 0.8553 - val_loss: 0.6319 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82640\n",
      "epoch =  33 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 35/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.4075 - acc: 0.8563 - val_loss: 0.5588 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.82640 to 0.83440, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-35-0.8344.hdf5\n",
      "epoch =  34 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 36/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.3981 - acc: 0.8594 - val_loss: 0.5768 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83440\n",
      "epoch =  35 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 37/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.3922 - acc: 0.8626 - val_loss: 0.6024 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83440\n",
      "epoch =  36 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 38/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.3829 - acc: 0.8667 - val_loss: 0.6592 - val_acc: 0.8139\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83440\n",
      "epoch =  37 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 39/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.3775 - acc: 0.8662 - val_loss: 0.6390 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83440\n",
      "epoch =  38 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 40/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3711 - acc: 0.8685 - val_loss: 0.5389 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.83440 to 0.83930, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-40-0.8393.hdf5\n",
      "epoch =  39 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 41/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.3666 - acc: 0.8716 - val_loss: 0.6641 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83930\n",
      "epoch =  40 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 42/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3573 - acc: 0.8724 - val_loss: 0.6178 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.83930\n",
      "epoch =  41 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 43/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3592 - acc: 0.8724 - val_loss: 0.5660 - val_acc: 0.8408\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.83930 to 0.84080, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-43-0.8408.hdf5\n",
      "epoch =  42 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 44/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3474 - acc: 0.8768 - val_loss: 0.6962 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.84080\n",
      "epoch =  43 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 45/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3448 - acc: 0.8779 - val_loss: 0.4875 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.84080 to 0.86160, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-45-0.8616.hdf5\n",
      "epoch =  44 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 46/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3412 - acc: 0.8791 - val_loss: 0.6132 - val_acc: 0.8373\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86160\n",
      "epoch =  45 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 47/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3391 - acc: 0.8799 - val_loss: 0.5136 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.86160\n",
      "epoch =  46 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 48/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3360 - acc: 0.8810 - val_loss: 0.6503 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86160\n",
      "epoch =  47 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 49/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.3241 - acc: 0.8856 - val_loss: 0.4680 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.86160 to 0.86690, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-49-0.8669.hdf5\n",
      "epoch =  48 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 50/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3196 - acc: 0.8883 - val_loss: 0.6621 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.86690\n",
      "epoch =  49 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 51/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3193 - acc: 0.8880 - val_loss: 0.5627 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86690\n",
      "epoch =  50 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 52/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.3164 - acc: 0.8893 - val_loss: 0.6544 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.86690\n",
      "epoch =  51 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 53/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.3116 - acc: 0.8894 - val_loss: 0.5317 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.86690\n",
      "epoch =  52 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 54/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3053 - acc: 0.8922 - val_loss: 0.7326 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.86690\n",
      "epoch =  53 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 55/120\n",
      "391/390 [==============================] - 76s 194ms/step - loss: 0.3030 - acc: 0.8919 - val_loss: 0.6372 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.86690\n",
      "epoch =  54 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 56/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2985 - acc: 0.8949 - val_loss: 0.5222 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.86690\n",
      "epoch =  55 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 57/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2976 - acc: 0.8958 - val_loss: 0.5692 - val_acc: 0.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_acc did not improve from 0.86690\n",
      "epoch =  56 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 58/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2894 - acc: 0.8969 - val_loss: 0.4678 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.86690 to 0.87010, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-58-0.8701.hdf5\n",
      "epoch =  57 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 59/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2884 - acc: 0.8975 - val_loss: 0.5209 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.87010\n",
      "epoch =  58 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 60/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2832 - acc: 0.9010 - val_loss: 0.5154 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.87010\n",
      "epoch =  59 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 61/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.2789 - acc: 0.9003 - val_loss: 0.5257 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.87010\n",
      "epoch =  60 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 62/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2781 - acc: 0.9012 - val_loss: 0.5619 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.87010\n",
      "epoch =  61 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 63/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2725 - acc: 0.9043 - val_loss: 0.4431 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87010 to 0.87620, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-63-0.8762.hdf5\n",
      "epoch =  62 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 64/120\n",
      "391/390 [==============================] - 78s 198ms/step - loss: 0.2702 - acc: 0.9047 - val_loss: 0.4808 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.87620\n",
      "epoch =  63 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 65/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.2661 - acc: 0.9049 - val_loss: 0.6164 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.87620\n",
      "epoch =  64 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 66/120\n",
      "391/390 [==============================] - 79s 201ms/step - loss: 0.2694 - acc: 0.9042 - val_loss: 0.5669 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.87620\n",
      "epoch =  65 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 67/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2655 - acc: 0.9049 - val_loss: 0.5897 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.87620\n",
      "epoch =  66 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 68/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2624 - acc: 0.9067 - val_loss: 0.5805 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.87620\n",
      "epoch =  67 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 69/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2603 - acc: 0.9083 - val_loss: 0.4804 - val_acc: 0.8769\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.87620 to 0.87690, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-69-0.8769.hdf5\n",
      "epoch =  68 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 70/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2552 - acc: 0.9103 - val_loss: 0.6979 - val_acc: 0.8334\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.87690\n",
      "epoch =  69 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 71/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2567 - acc: 0.9090 - val_loss: 0.5271 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.87690\n",
      "epoch =  70 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 72/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2506 - acc: 0.9110 - val_loss: 0.5508 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.87690\n",
      "epoch =  71 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 73/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2463 - acc: 0.9132 - val_loss: 0.4703 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.87690 to 0.87760, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-73-0.8776.hdf5\n",
      "epoch =  72 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 74/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2434 - acc: 0.9121 - val_loss: 0.6018 - val_acc: 0.8541\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.87760\n",
      "epoch =  73 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 75/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2434 - acc: 0.9132 - val_loss: 0.4740 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.87760\n",
      "epoch =  74 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 76/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2377 - acc: 0.9141 - val_loss: 0.4626 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.87760\n",
      "epoch =  75 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 77/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2430 - acc: 0.9134 - val_loss: 0.5190 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.87760\n",
      "epoch =  76 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 78/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.2389 - acc: 0.9155 - val_loss: 0.4794 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.87760 to 0.87890, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-78-0.8789.hdf5\n",
      "epoch =  77 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 79/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2341 - acc: 0.9155 - val_loss: 0.4816 - val_acc: 0.8786\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.87890\n",
      "epoch =  78 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 80/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2348 - acc: 0.9155 - val_loss: 0.4521 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.87890 to 0.88360, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-80-0.8836.hdf5\n",
      "epoch =  79 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 81/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2298 - acc: 0.9185 - val_loss: 0.4698 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88360\n",
      "epoch =  80 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 82/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2274 - acc: 0.9178 - val_loss: 0.4972 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.88360\n",
      "epoch =  81 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 83/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2265 - acc: 0.9204 - val_loss: 0.5292 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.88360\n",
      "epoch =  82 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 84/120\n",
      "391/390 [==============================] - 76s 194ms/step - loss: 0.2242 - acc: 0.9200 - val_loss: 0.5326 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.88360\n",
      "epoch =  83 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 85/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2218 - acc: 0.9208 - val_loss: 0.5213 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.88360\n",
      "epoch =  84 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 86/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2250 - acc: 0.9196 - val_loss: 0.5303 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.88360\n",
      "epoch =  85 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 87/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2230 - acc: 0.9195 - val_loss: 0.4940 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.88360\n",
      "epoch =  86 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 88/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2136 - acc: 0.9246 - val_loss: 0.5173 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.88360\n",
      "epoch =  87 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 89/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.2161 - acc: 0.9228 - val_loss: 0.5355 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.88360\n",
      "epoch =  88 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 90/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2177 - acc: 0.9209 - val_loss: 0.4809 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.88360\n",
      "epoch =  89 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 91/120\n",
      "391/390 [==============================] - 76s 196ms/step - loss: 0.2139 - acc: 0.9232 - val_loss: 0.5337 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.88360\n",
      "epoch =  90 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 92/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2092 - acc: 0.9255 - val_loss: 0.4986 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.88360\n",
      "epoch =  91 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 93/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2071 - acc: 0.9248 - val_loss: 0.5099 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.88360\n",
      "epoch =  92 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 94/120\n",
      "391/390 [==============================] - 76s 194ms/step - loss: 0.2080 - acc: 0.9256 - val_loss: 0.5051 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.88360\n",
      "epoch =  93 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 95/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2023 - acc: 0.9274 - val_loss: 0.4664 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.88360\n",
      "epoch =  94 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 96/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2046 - acc: 0.9283 - val_loss: 0.4822 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.88360\n",
      "epoch =  95 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 97/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.2019 - acc: 0.9279 - val_loss: 0.5259 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.88360\n",
      "epoch =  96 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 98/120\n",
      "391/390 [==============================] - 75s 193ms/step - loss: 0.2017 - acc: 0.9281 - val_loss: 0.5036 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.88360\n",
      "epoch =  97 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 99/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2006 - acc: 0.9288 - val_loss: 0.4515 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.88360 to 0.88910, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-99-0.8891.hdf5\n",
      "epoch =  98 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 100/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1964 - acc: 0.9288 - val_loss: 0.5585 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.88910\n",
      "epoch =  99 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 101/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1978 - acc: 0.9289 - val_loss: 0.4816 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.88910\n",
      "epoch =  100 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 102/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1975 - acc: 0.9293 - val_loss: 0.4714 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.88910 to 0.89020, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-102-0.8902.hdf5\n",
      "epoch =  101 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 103/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1976 - acc: 0.9290 - val_loss: 0.5416 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.89020\n",
      "epoch =  102 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 104/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1935 - acc: 0.9301 - val_loss: 0.5016 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.89020\n",
      "epoch =  103 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 105/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1915 - acc: 0.9320 - val_loss: 0.5007 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.89020\n",
      "epoch =  104 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 106/120\n",
      "391/390 [==============================] - 76s 193ms/step - loss: 0.1851 - acc: 0.9336 - val_loss: 0.4809 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.89020\n",
      "epoch =  105 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 107/120\n",
      "391/390 [==============================] - 76s 193ms/step - loss: 0.1912 - acc: 0.9312 - val_loss: 0.4683 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.89020\n",
      "epoch =  106 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 108/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1890 - acc: 0.9317 - val_loss: 0.5575 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.89020\n",
      "epoch =  107 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 109/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.1866 - acc: 0.9340 - val_loss: 0.4596 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.89020\n",
      "epoch =  108 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 110/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1841 - acc: 0.9328 - val_loss: 0.4790 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.89020\n",
      "epoch =  109 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 111/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1821 - acc: 0.9343 - val_loss: 0.5025 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.89020\n",
      "epoch =  110 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 112/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.1763 - acc: 0.9362 - val_loss: 0.4676 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.89020 to 0.89160, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-112-0.8916.hdf5\n",
      "epoch =  111 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 113/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.1834 - acc: 0.9353 - val_loss: 0.5352 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.89160\n",
      "epoch =  112 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 114/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.1850 - acc: 0.9351 - val_loss: 0.5277 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.89160\n",
      "epoch =  113 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 115/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.1795 - acc: 0.9348 - val_loss: 0.4590 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.89160\n",
      "epoch =  114 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 116/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.1776 - acc: 0.9374 - val_loss: 0.4960 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.89160\n",
      "epoch =  115 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 79s 201ms/step - loss: 0.1753 - acc: 0.9382 - val_loss: 0.4770 - val_acc: 0.8922\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.89160 to 0.89220, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-117-0.8922.hdf5\n",
      "epoch =  116 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 118/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.1733 - acc: 0.9375 - val_loss: 0.4928 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.89220\n",
      "epoch =  117 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 119/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.1737 - acc: 0.9381 - val_loss: 0.5319 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.89220\n",
      "epoch =  118 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 120/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.1735 - acc: 0.9380 - val_loss: 0.5974 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.89220\n",
      "epoch =  119 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 120\n",
    "\n",
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 1.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations -1 \n",
    "\n",
    "- We can see that the model did not converge well after 65 th epochs (Test accuracy of  0.8762)\n",
    "\n",
    "- divergent between testing and traing accuracy\n",
    "   - now to pull up testing accuracy by 2.8 % traing accuracy have to rach 96.6 around (estimate, whics is tough)\n",
    "   \n",
    "- Treid differnt methods here to achievd  but none worked \n",
    "\n",
    "- We might not reach 92% from this point\n",
    "\n",
    "- So let's start retrain the model from  63rd epch (just assumed it will be good spot to start re-train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations - 2\n",
    "\n",
    "- Tesiting, traing accracies have diverged, so let's use more augmentatin\n",
    "\n",
    "-  It also seems like there is some saddle point aroung 89% (other people were also reporting it, so try bigger batach size) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Re compile the model, to make sure there is no learing left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_filter = 12\n",
    "num_filter = 12\n",
    "growth_rate = 12\n",
    "dropout_rate = 0.2\n",
    "#compression = 0.751\n",
    "compression = 0.5\n",
    "l = 16\n",
    "dense_l= [8, 16, 20, 12]\n",
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(2*num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, growth_rate, dropout_rate, dense_l[0])\n",
    "First_Transition = add_transition(First_Block, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, growth_rate, dropout_rate, dense_l[1])\n",
    "Second_Transition = add_transition(Second_Block, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate, dense_l[2])\n",
    "Third_Transition = add_transition(Third_Block, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  growth_rate, dropout_rate, dense_l[3])\n",
    "output = output_layer(Last_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 90\n",
    "decay = learning_rate/epochs\n",
    "decay = 0.0001\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the model weight at 63rd epoch and verify (test accurcy verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 14s 1ms/step\n",
      "Test loss: 0.4431272914737463\n",
      "Test accuracy: 0.8762\n",
      "50000/50000 [==============================] - 73s 1ms/step\n",
      "Train loss: 0.22539759956479072\n",
      "Train accuracy: 0.92494\n"
     ]
    }
   ],
   "source": [
    "load_model_from_back = True\n",
    "\n",
    "if load_model_from_back:\n",
    "    model.load_weights('DNST_CIFAR10_Conv_09_09_final_tr2-63-0.8762.hdf5')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    score = model.evaluate(x_train, y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to visualise the wrong predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data old as one got normalised\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_correct = (Y_pred == Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "mis_predict = []\n",
    "for i, val in enumerate(Y_correct):\n",
    "    if not val:\n",
    "        count += 1\n",
    "        #draw_img(i, X_train, Y_train, class_name)\n",
    "        mis_predict.append(i)\n",
    "        #print(\"count = \", count)\n",
    "        if count == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 35, 42, 57, 58, 59, 61, 68, 78, 85]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CIFAR_classes        = list(class_name.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CIFAR_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] [4]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = mis_predict[0]\n",
    "draw_img(index, X_test, Y_test, class_name)\n",
    "print(Y_test[index], Y_pred[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2] [8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = mis_predict[1]\n",
    "draw_img(index, X_test, Y_test, class_name)\n",
    "print(Y_test[index], Y_pred[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5] [3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXuUXXd13z/7PuY9I2n0sixZlizLGAO2cRXzMgnvGrfE0KZZEBaha9GatpiUQtK4NE3crD4gLVDWSkKXKG5MSniERyApNBCXYF61EcbIsiVsSYwsjR6j0Whm7jzue/ePc8Qaj3/7N1fzuCNx9metWXPvb9/fOb/7u2ffc87ve/feoqo4jpM9cqs9AMdxVgd3fsfJKO78jpNR3PkdJ6O48ztORnHnd5yM4s5/GSAi94rI/1rtcViIyN8Vkb+I2P9WRP7JMuzn3SLywaVux0lw579EEJFfE5F9IjIlIqdE5GsictsqjWVIRGbTsUyJyNcX6PIfgQ+0YWgfB94qIpvasK+fe9z5LwFE5L3AfwP+E7AZ2A78MXDnKg7rDaral/69znqRiPwCsEZV/99KD0hVy8DXgF9f6X1lAXf+VUZE1gC/D7xLVb+oqtOqWlPVv1TV3zL6/LmInBaRCRF5UESeN8d2h4g8ISIlERkWkd9M2zeIyF+JyLiIjInIt0VkOT7/1wPfmje+14rIoXR8fwjIHFtORH5HRI6JyIiIfDKdgwv2X09t50Tk36VXIa+Zs/m/Bf7eMow787jzrz4vAbqAL11En68Bu4FNwCPAp+bYPgG8U1X7gecD/zdtfx9wAthIcnXxfiD22+5PichZEfm6iNwUed0LgJ9ceCIiG4AvAr8DbACOAC+b8/p/nP69ErgG6AP+MO17A8kVz1uBLcAaYOu8/R0EYuNxWsSdf/VZD4yqar3VDqp6n6qWVLUC3AvcNOfsWQNuEJEBVT2vqo/Mad8CXJ1eWXxb7cCOtwI7gKuBbwJ/LSJrjdeuBUpznt8BPK6qn1fVGsntzOl52/6wqh5V1Sng3wBvFpEC8CvAX6rqd1S1Cvwuz/6CKpF8KThLxJ1/9TkHbEgP/gURkbyIfEBEjojIJDCUmjak//8hiQMeE5FvichL0vb/AhwGvi4iR0XkHmsfqvpdVZ1V1RlV/c/AOPBy4+Xngf45z68Ejs/Zls59ntqPzXl+DCiQXI3M7ztDMj9z6QcmrLE7rePOv/p8H6gAb2zx9b9GshD4GpIz4I60XQBU9QeqeifJLcFfAJ9L20uq+j5VvQb4ZeC9IvLqFvepzLlvn8d+4Lo5z08BV114IiIy9zlwkuSK4gLbgTpwJu27bU7fbpIro7k8F/hxi+N2IrjzrzKqOkFyeftHIvJGEekRkaKIvF5E/iDQpZ/ky+Ic0EOiEAAgIh0i8lYRWZNeck8CzdT290Xk2tQZJ4DGBdtcRGS7iLws3VaXiPwWyVXFd4238FXgl+Y8/9/A80TkH6RXM78BXDHH/mngX4nIThHpS8f/2fS25/PAG0TkpSLSQXJLM/9L55dI1jycJeLOfwmgqh8C3kuySHaW5NL3bpIz93w+SXKpPAw8AcyX2N4GDKW3BP+M5B4bkgXCvwGmSK42/lhVvxnYfj/wMZLL+WHgduD1qjr/8vvC2B8BJkTkRenzUeAfkej+59L9zv3iuA/4U+BB4KdAGXh32vfx9PFnSK4CpoARki87RKSL5Jbm/tBYnItDPJmHs1RE5HXAv1DVVm9dWt1uH8l6w25V/amIvBu4SlX/9XLuJ6u48zuXFCLyBuABksv9DwEvAm6JKBPOIvHLfudS406SRcGTJLcMb3bHXxn8zO84GcXP/I6TUVr6Ycly0dfXp+vXz5dtL2BfgTSbYVsuZ393xa5oYracWHI2NI1+EukjkQur6Dhy9jYX994iY4yMf6Cr37SVZ8uRbYbH0dmwP7NG3X5fVWqmrWhaoJkPv7d6/lkq58+Yrk2btnJ11rR1d/aatr6OAdOmxmfTjB08xrF/dnSEUmnS/kDnsCTnF5HbgY8CeeB/qGo0rHP9+vX89m9bPyyzf906O1sJtnd325Otan+4tUrVtHUU7EOpWg2Po1C0++Qin1+jZr/nrg57m/WaPf5GM/y+mxEH78x1mrbXXvcq03bo0EHTViiE52rXmP1lMjlmO9YxOWvarlD7vVXWhefxzBrbwR86YQcoPnXiCdN2485bTdtLt7/GtFVz4THO5MJzCJDr7Q62v//e1oWQRV/2i0ge+COSqK4bgLekgRmO41wGLOWe/1bgcBqgUSX5YcZqxp87jnMRLMX5t/LMgI0TPDv8EhG5K81Qs29qamoJu3McZzlZ8dV+Vd2rqntUdU9fX99K785xnBZZivMP88xorW1pm+M4lwFLWe3/AbBbRHaSOP2bScJNTVSVZrMRtOUNSSYhbIssYKOGPLhQP4ktz1sKgrHCDqCRlehaNTwXAIVIhq1KzV4FrpTDklhv3r7q6qjY+5o8esLe16T9XS994dXoetGWvCq5GdNWbdgKR3Xano/zhqJypmArC1u3Puvu9WccOXPMtA2dsOfqed1nTNuVV+4MtnfVbXlzdNpIadBsOSfM4p1fVesicjfw1yRS331pVJbjOJcBS9L5VfWrJPHcjuNcZvjPex0no7jzO05Gced3nIzizu84GaWtUX0iYkbiFQr291AuF5Y8ypVI4ENEz2tE5JBoegMJS3oa2V4s8jCft6W+WCBO7FPr7QpLbNd0XGn2uarftuUK9oQMT0VkQCPi7/HJfWafiRk7I/dgrz3G2aI9Vx3lfLD99NBTZp9j+adN284+O3xlZ+fVpm1dJEJPpibDfXq7zD496zcE22OBafPxM7/jZBR3fsfJKO78jpNR3PkdJ6O48ztORmnraj9APhdefQ1UjvoZVo65JJlQGCvlFkDOWLUHqNftABJLCijk7XFo0w7O0KYdyKKRYBupRuZKwym5GlP2+9p13Q7T9tDxB03bA/u+Y9qKG8KFdLXDzvvX02evbk/XwioGwGivPR8vH9webB88agf2nOi1V8x3FDfZtoJdPLh8KljwCIDN+fA2e3rs7dVmOoLt+UiOxPn4md9xMoo7v+NkFHd+x8ko7vyOk1Hc+R0no7jzO05GabPUpzRy4SCYSsUOclHCtli+PZVINZw++2036rb81lEMyytrB8PtAOVIdaB+teWrgbr9vTx13JYxx2th2Su3yZaNZgbtij09DTuf3UtfYZdpOD4Rzlk3Pn3U7LMeuwJTU+y5qg7Yx86h+vFge3PArhz02lt+2bTlHrel2w2zdp7Enq6Npm3tTHj+S0/aVYqqhiyqldZz+PmZ33Eyiju/42QUd37HySju/I6TUdz5HSejuPM7TkZpq9RX6MyzeWdYzpkYDecxAyiyzrDY310zs9Om7YY91vbg7FlbXpmZCEcXXrvHjvQ6/gP7fTUP2pFl+Uik4Plz9jaPToQrIW+96UX2OG4ZNG0v6Hq5abty8oWm7c8+9/lg+/ST580+5ydKpq3MuGlrRD7rIQnnGWwWbXnw+WdtWW5DIZw7D+D6SFTfhjX2HDMVlg+LY3ZOw7ohmcdKx81nSc4vIkNACWgAdVXds5TtOY7TPpbjzP9KVR1dhu04jtNG/J7fcTLKUp1fga+LyA9F5K7QC0TkLhHZJyL7JiP3dI7jtJelXvbfpqrDIrIJ+IaIHFLVZ+R9UtW9wF6AXdftjJXEcBynjSzpzK+qw+n/EeBLwK3LMSjHcVaeRZ/5RaQXyKlqKX38OuD3Y306u/Ls3B2W2c4NhCUqgLET4e+o7rwtyczO2IkiBzZHEmBGkiYe3h8eY7HLjurrKtlRVucftddJj4odPfbA0BOmbWg0nCjy4OSY2af7yrWm7YU332zaJiNlyp48+tNg+9Ghk2afTf12VF9nRPrMl+1z2HQhfIgfnTpi9mlGEok+Z/BG0/btki1jvrjD7rfdiPjrG7CPxd6+sK2Qb92ll3LZvxn4UppZtwD8mar+nyVsz3GcNrJo51fVo8BNyzgWx3HaiEt9jpNR3PkdJ6O48ztORnHnd5yM0taovlqtzslTI0FbJ3YSycmJcBRbzaz7Byq2dHj8uC2j5SKSUiMfjrI6cchOqFnN2bYz22yp7Ps/etK0/eS0LZfNVsL7+/73vmX2Wfc/bamvePdvmLZy2R5/vjNc7274VDixJ8D0ObtG3p6dN5i2dWon4xyfHgi2j/WE2wFGSuFjFKCptsx6sGQnfx2ZtaNFd9V2BttnR+1fxK4tXxFsn6raY5iPn/kdJ6O48ztORnHnd5yM4s7vOBnFnd9xMkp7y3WpoM3wqv7JE3Zeug3rwiubJ4fDpZgAdjzfztPXqNrfeaMn7ZX0nc8Pr4ofP3LM7DNuL/bzo7L9ng+ePGXaysaKPoDWw0qG1O2yYY8/+ohpe+qQvbq96Yotpm3rls3B9kbdzp13atwOPhrutFf0u3tttaKvIxws1FcPjw9g9Jy9yl6atgPGOoq2+vHY1GHTdrB0Otg+PWKPY3AmfHyPV1vPmeFnfsfJKO78jpNR3PkdJ6O48ztORnHnd5yM4s7vOBmlrVJfsaPAlq1hiWL48JDZr6MZlnIaEi6fBaB5O1Hw4IAdQDJ50A7suXrmmmD76Lgtoz3wnUdN26GDT5u2qRm7lFelYctNNMJSWr1hy1Cj5+ygk2NPHjJta3rsYKzyVLi81kzJljdnZ22Z6tFhO9BpZutVpm2tUUJrfDqS92/cnqu+9ZH8j532cVDutPvliz3B9tluswtHRoeC7ZV6RFueh5/5HSejuPM7TkZx53ecjOLO7zgZxZ3fcTKKO7/jZJS2Sn2Vcpmf/iQs2XQP2FLI2Fi4rFWjYUsrpUjOtDWzO0zbi+Xlpq3v4fAYTx+wpbeRYVvamhyxxzg1Y/erNyNyUzMscdo9YHIinJsQYHhoyLRdu+Nq03Zu5ESwfXrKfl9gR/ydn7FzMh4ds3Pu7eoPRwPmCoNmn+6iLSE3y7aUNjVt26Q/LOcBDGwIy98To3b5r2kjsrOhrdfCXfDMLyL3iciIiByY0zYoIt8QkafS/3b8rOM4lyStXPb/CXD7vLZ7gAdUdTfwQPrccZzLiAWdX1UfBOZnWbgTuD99fD/wxmUel+M4K8xiF/w2q+qFVDOnSSr2BhGRu0Rkn4jsm5yYXuTuHMdZbpa82q+qCpirDKq6V1X3qOqegTV2/XXHcdrLYp3/jIhsAUj/28utjuNckixW6vsK8HbgA+n/L7fSqd5ocn48fOm/+YpdZr8uDUsvs3VbCtl4RZdpKx62I/fWnbcj1R57+vFg+6HTdrLN0alzEZs9/mpEzsvHdDvjGkwiEZANI+knwPkxW46cnLATbp4cHjL2ZcthHZ323Fcr9hinxmz5sLY2LBEODm40+/Ru2m7aOsSO+BPsOZ6oReTgp8PHz/nT9jm1q8M4vu0hPItWpL5PA98HniMiJ0TkHSRO/1oReQp4TfrccZzLiAXP/Kr6FsP06mUei+M4bcR/3us4GcWd33Eyiju/42QUd37HyShtjeoTgXxXWGabPGVH6G2vhmvCFbrCyRkBin22JDMybtdNmzlhy2/fHQ0n3DxRDSerBDg/bm9vtmrLXs28rdkUYnqOEdUVU4AakeSep8/YtQsPHQpLnwCHj/wk2N7RaR9yHZ0dpq0SqU9YnbVltJmJcFLQXuwkrpVpexz1nG3bfc3zTNtgwf51a7kWliOrJfs9d28zahdGJN35+JnfcTKKO7/jZBR3fsfJKO78jpNR3PkdJ6O48ztORmmr1JcToTMf3uVGO2iLjSfDssyxcTua7genHzJt/Tk7mWKDGdN2qBZOJFqLRKrVp+zEk4VIdJ5GJJt8zv7OzuftiEWLjg5b9hoZsSPLHn74YdNWrYal29i+GkadQTAVTACaEXWrruFJ7uztM/uUG/bnOVuxIxll2JY+h8dOm7ZcIewTuzddZ/YZ3BqOSjzzZPgYDe635Vc6jvNzhTu/42QUd37HySju/I6TUdz5HSejtHW1v1kXKufCq9F9aq++qpFjbqpqr7ye+NER09Z95VbTVp41TcxWjQCSWmS1v2kHzcQKK0k9IgV02N/ZaiyL9/bamZN37txh2o4fO2baJidsJWPXrt3B9mND9vZOnbJXxJuR2arnbNt4JazenDxvr4rPYgeZFbptNUUm7QCv0lm7JNpr/s6rgu2v3P0LZp9KM5y38MD3HjP7zMfP/I6TUdz5HSejuPM7TkZx53ecjOLO7zgZxZ3fcTJKW6W+2myd4SfCOe12b3iO2a9iyGUTnXaZpo2Dtpw3Pttt28Zs+apoRJCcm7Hzs1XVDlapRSSqot0tGgDT2RUu43T9c59r9nnB8280bbWqva/RUVsu2779mmB7vWa/51Onz5g2ydnRO2IExgBM18Oy3dkZW5bbtdMuHTfQY+eN3NK9wbTVe+xj9fVX3xpsv7Jk5wssTYXnsSMyv/NppVzXfSIyIiIH5rTdKyLDIvJo+ndHy3t0HOeSoJXL/j8Bbg+0f0RVb07/vrq8w3IcZ6VZ0PlV9UHA/imd4ziXJUtZ8LtbRPantwXrrBeJyF0isk9E9k3P2okyHMdpL4t1/o8Bu4CbgVPAh6wXqupeVd2jqnt6u+0MOo7jtJdFOb+qnlHVhqo2gY8D4eVKx3EuWRYl9YnIFlW9kEDvTcCB2Osv0Gw0mR0Ll0/q7rCjpXKVsHzx5MnjZp/i9s2mTUcjEWLlc7atGZaNJqdtebAZic6LKH00xJbYBvrsCL3bbrst2H7jC242+4yN2SXFypEyWfWI5NhoGtGF/UaZKUBy9jGQjyTxi5Uvq9XCn1nZyO0HsDaS43Fn3xWmrRKRRa+/4nrTtr4UHv+pU0+Yfc41wn5UNaTNEAs6v4h8GngFsEFETgC/B7xCRG4miUodAt7Z8h4dx7kkWND5VfUtgeZPrMBYHMdpI/7zXsfJKO78jpNR3PkdJ6O48ztORmlrVF9Dm0xWw7/yG6rZpbfGxs4G2588bSd83LF+k2mbmbHlq2rNSNIJzFTCkt5kyU7OGKszlYtIVI1Iv+5uOypx27ZwNOOaNbbEdiySpHPdurWRfW0zbV1d4Yi0WPkvK/koQLNpS3NWaTAAKy6uft7+zMqjttxb7RwwbY8fPmzarn+O3W+6dDLYPlMPy3kA0xLONNsgkvh1Hn7md5yM4s7vOBnFnd9xMoo7v+NkFHd+x8ko7vyOk1HaW6tPlZlmuO7e90YeNfsdPzscbC+sHTT7VGfs77WZaTvh5tSUndjx3HhYppos2VFxYqt50Vp9RGTAmOxVqYSlylok2mvnzu2m7aptV5o2EXuO9+/fH2wfGjpq9mk2I1lLI8Tmw7LVCR+HAKMlW+rrORH5QCdt+fDsZPgYBjhWMaIZm7bsXOwKu24sUvRZr239pY7j/Dzhzu84GcWd33Eyiju/42QUd37HyShtXe1XlLqR2+34lB2kM2nUrto+aK9El2fs1dyxcXs1d7JklygYOx8OMFINlxMDyOXs71eN5JHr6bHz9F13nV3abMuWLcH2zk77o+7utoNORO28eidPhgNSAA4cCK/2T03ZwSpN49iAeNBPLqI6WHkGa5EyakfO2cdij31YsSnymR04Zwf9lDRcYm130S4N1tPsDBsiczgfP/M7TkZx53ecjOLO7zgZxZ3fcTKKO7/jZBR3fsfJKK1U7LkK+CSwmSQWZa+qflREBoHPAjtIqvb8qqraES6AIOQN6ahYMKQLYHPfhmB7vmkPf7psD2V2ZtK0zczaQT/VajhvWrHDHkclkl8uJl/19Nglo2K583K5cOBJ1ShbBVAuh98XQF+3nftvYMC23XTTjcH2fH5x0mGlYo9fItFTagX9NO3z3hT2vkYjpdnUkKQBjo6PmrbuzbuC7dfaxa9pFozshLFIsnm0cuavA+9T1RuAFwPvEpEbgHuAB1R1N/BA+txxnMuEBZ1fVU+p6iPp4xJwENgK3Ancn77sfuCNKzVIx3GWn4u65xeRHcALgYeAzXMq9Z4muS1wHOcyoWXnF5E+4AvAe1T1GTfNmty8Bm9gReQuEdknIvvKZTs5geM47aUl5xeRIonjf0pVv5g2nxGRLal9CxBMc6Oqe1V1j6ru6eoK/4bZcZz2s6DzS7KU+gngoKp+eI7pK8Db08dvB768/MNzHGelaCWq72XA24DHRORCor33Ax8APici7wCOAb+60IYUaBq56XJGZBNAXzFcMqpWtstulSLRebPlWA4/O+osnzfypkUi9xp1W/6JSVTr1toyT1+fHYVn5axrGtFtAOVZ+3ZMNBYNaMuR1+y6Nry9iNRnzS/ES4rVanaonSWnSiSikrodpTlWt4+dcs7uNxuxPTYVljhHp+1jcdO6jcH2yabtE/NZ0PlV9TvY2SRf3fKeHMe5pPBf+DlORnHnd5yM4s7vOBnFnd9xMoo7v+NklLYm8BSEXCG8S1EjSgmwVJnpiBRSmrTLbs3Mzpg2ich2HcWwHBmLBGxEJLZYhFtff19kHPbHVjCivbq77eSSqvZ7trYH8bmyPufOTlvS7eyyIzuLxaJpq0YiJy0UW+rTSKm0iZp97EzFymt12p/10Gw4AvVp7OjT3nI4SrBUa/1XtH7md5yM4s7vOBnFnd9xMoo7v+NkFHd+x8ko7vyOk1HaK/WJUCwack6kJtyMIelNRuS80kwk0WI47wgAhaI9jtlyWOaJRZXFiEUDFgq2LRL8hpUzoavLlg5FbDkvn7dlr5jEVjSkvlhi0q6IDBiLgIzZFkPs+Kg1bem2nrPlw0bN7pczPutmzh5HqR6O3mtEksI+a78tv9JxnJ8r3PkdJ6O48ztORnHnd5yM4s7vOBmlrav9itA0gkgakRXzqdJEsD0WUNNUe3W1GcnfFitrVauHx2jlzVvIFgvsiZXyyuXsfsWisXIfCd7p7IisskdWsGOr/QVjtX/NwBqzz5q1ti02HzEW088qeQbYCe0Amva+YqNQQ1FpRDrFlKJW8TO/42QUd37HySju/I6TUdz5HSejuPM7TkZx53ecjLKg1CciVwGfJCnBrcBeVf2oiNwL/FPgbPrS96vqV2PbUlVqRvmq6ZKdr6w8Gw7SqdXtfGX1pl0eKSoDiq2vNAzZLpanb9FBJxFpLp+zpbl8ziopFtlXZIixElqxHH6dneEArthcdXRE8jhGJLu4nBd+cxr7WCLvqyuSP3Hj2nBZOYAzY2dNmxrHSE7scUik2lirtKLz14H3qeojItIP/FBEvpHaPqKq/3Xpw3Acp920UqvvFHAqfVwSkYPA1pUemOM4K8tF3fOLyA7ghcBDadPdIrJfRO4TEbusrOM4lxwtO7+I9AFfAN6jqpPAx4BdwM0kVwYfMvrdJSL7RGRfpTK7DEN2HGc5aMn5RaRI4vifUtUvAqjqGVVtqGoT+Dhwa6ivqu5V1T2quqezs3u5xu04zhJZ0PklWa7+BHBQVT88p33LnJe9CTiw/MNzHGelaGW1/2XA24DHROTRtO39wFtE5GYS+W8IeOeCWxJBDfmibkiAABjSXL1uR5XFJKUYdSNyD6BhyIeLzS8XK0GVL9i2XC5mM6S+SC6+mAwYG38u+t7C47By+wE0I5KdJbNCvPSWWBF6MRktMo6eTluO3H31DtNWr4Rz7gGcs0psxfTIujHGiwhibGW1/zuExdKopu84zqWN/8LPcTKKO7/jZBR3fsfJKO78jpNR3PkdJ6O0NYFnPpen30jgOD0ZLskFUJkOl+WqVu2ovmpEBiyX7V8a1ip2PzGkl1jkWz5vf792dEQku4iMFivlhSF7xYILY4lEGxEJViKJUPNmpJo9kNmyLYfFojQNdROA3v7wD8vqllQGSNmWe3NFe/wDxr4AXn3Ti0zbgwcfD7YPT5wz+xTMJK6tR5H6md9xMoo7v+NkFHd+x8ko7vyOk1Hc+R0no7jzO05Gaa/UV8izdjCc8Of08EmzX6USll5qkfp+tUgduUokwioWxWYlmLTq0i1ErOaeGY0GNJu2/FZvhOdEJJxQE4BIFFszEh25mKSasbFXS3btxXwkYWVsHjusyMlcZA7rtqwYi8SkZm9zc5+d3HNtISwRnowl6bSiNC8iX6yf+R0no7jzO05Gced3nIzizu84GcWd33Eyiju/42SUtkp9ilLXsBTV0dNj9pNCWGLTiK4Rk6GakWi0np5e09bbGx6jVZcO4olEc5HMmVYCTIjXKGwa0W+LrSdYjUimMUmsuZi6hhF5s39tOBoUoDRjR4TOTIfnqtARicTsspN0TkfkyNq4/blMluwIvepEuBZlMZJktGEd3heRwNPP/I6TUdz5HSejuPM7TkZx53ecjOLO7zgZZcHVfhHpAh4EOtPXf15Vf09EdgKfAdYDPwTepqr20jDJ6nZXb1fQtnnLlmA7wNjpU8H2yIJ+tOxWpxGgA7B58ybT1t/fH2zv6+uLjMNeEY8FBA0M2NvM5SJKhhE4Y62+JzZ7e7HgqUbkvVlJA2OfWf96O/jliupW09Z8+rhp6zJy9fX12+rSaMVWDzpmTBNrCuHjA6AnHz7uAbry4WAhQxi7YI0ZW6KVM38FeJWq3kRSjvt2EXkx8EHgI6p6LXAeeMeSR+M4TttY0Pk14YIQWUz/FHgV8Pm0/X7gjSsyQsdxVoSW7vlFJJ9W6B0BvgEcAcZV9cJ13wnAvi5zHOeSoyXnV9WGqt4MbANuBa5vdQcicpeI7BORfTPT4V8yOY7Tfi5qtV9Vx4FvAi8B1orIhRWrbcCw0Wevqu5R1T09vfYiluM47WVB5xeRjSKyNn3cDbwWOEjyJfAr6cveDnx5pQbpOM7y00pgzxbgfhHJk3xZfE5V/0pEngA+IyL/AfgR8ImFNlTsKLJ1+7agrVYOXjgkGPWYCh12QM2AURYMYM0aW5LZdpW9dNHTE8611ttrBwOVy3awRywfXFckuKRYtHPW5Y1SXrlI0Ew0CComEUb6FYwSYGZOPeCKDbbM2oyU0FoTkd+uyIclvWqnrUqPDNlBODu27DJtVw5uNm3Fqj1XPf3hK+JGedTsc1HJ+gwWdH5V3Q+8MNB+lOT+33GcyxD/hZ/jZBR3fsdr2UF8AAADMklEQVTJKO78jpNR3PkdJ6O48ztORpGYzLPsOxM5CxxLn24AYlpGu/BxPBMfxzO53MZxtapubGWDbXX+Z+xYZJ+q7lmVnfs4fBw+Dr/sd5ys4s7vOBllNZ1/7yruey4+jmfi43gmP7fjWLV7fsdxVhe/7HecjOLO7zgZZVWcX0RuF5GfiMhhEblnNcaQjmNIRB4TkUdFZF8b93ufiIyIyIE5bYMi8g0ReSr9v26VxnGviAync/KoiNzRhnFcJSLfFJEnRORxEfmXaXtb5yQyjrbOiYh0icjDIvLjdBz/Pm3fKSIPpX7zWRGx475bQVXb+gfkSXIAXgN0AD8Gbmj3ONKxDAEbVmG/vwjcAhyY0/YHwD3p43uAD67SOO4FfrPN87EFuCV93A88CdzQ7jmJjKOtc0ISrN+XPi4CDwEvBj4HvDlt/+/AP1/KflbjzH8rcFhVj2qS5/8zwJ2rMI5VQ1UfBMbmNd9JkgUZ2pQN2RhH21HVU6r6SPq4RJIpaittnpPIONqKJqx4xuzVcP6twNwqC6uZ+VeBr4vID0XkrlUawwU2q+qF6iSnATstzMpzt4jsT28LVvz2Yy4isoMkecxDrOKczBsHtHlO2pExO+sLfrep6i3A64F3icgvrvaAIPnmZzlKsiyOjwG7SAq0nAI+1K4di0gf8AXgPao6OdfWzjkJjKPtc6JLyJjdKqvh/MPAVXOem5l/VxpVHU7/jwBfYnXTkp0RkS0A6f+R1RiEqp5JD7wm8HHaNCciUiRxuE+p6hfT5rbPSWgcqzUn6b4vOmN2q6yG8/8A2J2uXHYAbwa+0u5BiEiviPRfeAy8DjgQ77WifIUkCzKsYjbkC86W8ibaMCciIiQJYA+q6ofnmNo6J9Y42j0nbcuY3a4VzHmrmXeQrKQeAf7tKo3hGhKl4cfA4+0cB/BpksvHGsm92ztICp4+ADwF/A0wuErj+FPgMWA/ifNtacM4biO5pN8PPJr+3dHuOYmMo61zAtxIkhF7P8kXze/OOWYfBg4Dfw50LmU//vNex8koWV/wc5zM4s7vOBnFnd9xMoo7v+NkFHd+x8ko7vyOk1Hc+R0no/x/cVRLuRPqmkoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = mis_predict[2]\n",
    "draw_img(index, X_test, Y_test, class_name)\n",
    "print(Y_test[index], Y_pred[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm) #to print in text if needed\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnf_matrix_train     = confusion_matrix(y_true_train, y_pred_train)\n",
    "#cnf_matrix_val       = confusion_matrix(y_true_val, y_pred_val)\n",
    "cnf_matrix_test      = confusion_matrix(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cnf_matrix_test, classes=CIFAR_classes, normalize=True,\n",
    "                      title='Normalized confusion matrix for Testing Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Observation \n",
    "- cat and dog are the major classes got mis classified\n",
    "- maybe more data agumentaitn (rotation) might help\n",
    "- partial images are getting wrongly predicted (how to fix it may be increasing more widht shift might help?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  This time more augmentation to genralize will"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the leaning rate and sgd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.9\n",
      "1e-04\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import keras.backend as K\n",
    "k.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print(K.eval(model.optimizer.momentum))\n",
    "print(K.eval(model.optimizer.decay))\n",
    "print(model.optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain -  starts at 13:56 30 october 30, more agumentaion, 2x steps per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "391/390 [==============================] - 137s 352ms/step - loss: 0.3197 - acc: 0.8874 - val_loss: 0.5486 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.89750\n",
      "epoch =  0 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 2/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.3092 - acc: 0.8902 - val_loss: 0.5944 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89750\n",
      "epoch =  1 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 3/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2999 - acc: 0.8939 - val_loss: 0.4826 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89750\n",
      "epoch =  2 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 4/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2916 - acc: 0.8967 - val_loss: 0.6128 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89750\n",
      "epoch =  3 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 5/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2838 - acc: 0.8988 - val_loss: 0.5307 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89750\n",
      "epoch =  4 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 6/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2774 - acc: 0.9012 - val_loss: 0.4476 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89750\n",
      "epoch =  5 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 7/175\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.2680 - acc: 0.9052 - val_loss: 0.5446 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89750\n",
      "epoch =  6 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 8/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2617 - acc: 0.9061 - val_loss: 0.4766 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89750\n",
      "epoch =  7 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 9/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2587 - acc: 0.9072 - val_loss: 0.5685 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89750\n",
      "epoch =  8 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 10/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2488 - acc: 0.9113 - val_loss: 0.7172 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89750\n",
      "epoch =  9 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 11/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2445 - acc: 0.9124 - val_loss: 0.5497 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89750\n",
      "epoch =  10 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 12/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2382 - acc: 0.9143 - val_loss: 0.5224 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89750\n",
      "epoch =  11 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 13/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2343 - acc: 0.9160 - val_loss: 0.5752 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.89750\n",
      "epoch =  12 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 14/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2267 - acc: 0.9190 - val_loss: 0.6288 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.89750\n",
      "epoch =  13 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 15/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2237 - acc: 0.9201 - val_loss: 0.5366 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.89750\n",
      "epoch =  14 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 16/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2215 - acc: 0.9202 - val_loss: 0.5667 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.89750\n",
      "epoch =  15 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 17/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2139 - acc: 0.9239 - val_loss: 0.5296 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.89750\n",
      "epoch =  16 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 18/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2126 - acc: 0.9247 - val_loss: 0.6340 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.89750\n",
      "epoch =  17 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 19/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2068 - acc: 0.9260 - val_loss: 0.5778 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.89750\n",
      "epoch =  18 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 20/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2040 - acc: 0.9272 - val_loss: 0.5039 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.89750\n",
      "epoch =  19 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 21/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1981 - acc: 0.9285 - val_loss: 0.5175 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.89750\n",
      "epoch =  20 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 22/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1941 - acc: 0.9316 - val_loss: 0.5003 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.89750\n",
      "epoch =  21 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 23/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1912 - acc: 0.9326 - val_loss: 0.5548 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.89750\n",
      "epoch =  22 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 24/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1899 - acc: 0.9320 - val_loss: 0.5593 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89750\n",
      "epoch =  23 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 25/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1857 - acc: 0.9338 - val_loss: 0.5013 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89750\n",
      "epoch =  24 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 26/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1853 - acc: 0.9339 - val_loss: 0.5114 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.89750\n",
      "epoch =  25 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 27/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1821 - acc: 0.9343 - val_loss: 0.5117 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.89750\n",
      "epoch =  26 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 28/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1775 - acc: 0.9355 - val_loss: 0.4992 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.89750\n",
      "epoch =  27 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 29/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1753 - acc: 0.9374 - val_loss: 0.5130 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.89750\n",
      "epoch =  28 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 30/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1707 - acc: 0.9382 - val_loss: 0.6864 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.89750\n",
      "epoch =  29 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 31/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1676 - acc: 0.9398 - val_loss: 0.5165 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89750\n",
      "epoch =  30 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 32/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1652 - acc: 0.9412 - val_loss: 0.5018 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89750\n",
      "epoch =  31 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 33/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1641 - acc: 0.9411 - val_loss: 0.5301 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89750\n",
      "epoch =  32 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 34/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1631 - acc: 0.9410 - val_loss: 0.5457 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89750\n",
      "epoch =  33 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 35/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1594 - acc: 0.9431 - val_loss: 0.4999 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89750\n",
      "epoch =  34 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 36/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1617 - acc: 0.9419 - val_loss: 0.5197 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89750\n",
      "epoch =  35 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 37/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1579 - acc: 0.9432 - val_loss: 0.5218 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89750\n",
      "epoch =  36 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 38/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1505 - acc: 0.9456 - val_loss: 0.5389 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89750\n",
      "epoch =  37 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 39/175\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.1489 - acc: 0.9462 - val_loss: 0.6001 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89750\n",
      "epoch =  38 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 40/175\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.1514 - acc: 0.9453 - val_loss: 0.5448 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89750\n",
      "epoch =  39 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 41/175\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.1468 - acc: 0.9483 - val_loss: 0.4847 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.89750 to 0.89930, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-41-0.8993.hdf5\n",
      "epoch =  40 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 42/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1462 - acc: 0.9475 - val_loss: 0.5111 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89930\n",
      "epoch =  41 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 43/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1474 - acc: 0.9469 - val_loss: 0.5054 - val_acc: 0.8933\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89930\n",
      "epoch =  42 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 44/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1423 - acc: 0.9494 - val_loss: 0.4917 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89930\n",
      "epoch =  43 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 45/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1404 - acc: 0.9500 - val_loss: 0.5533 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89930\n",
      "epoch =  44 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 46/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1385 - acc: 0.9499 - val_loss: 0.5887 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.89930\n",
      "epoch =  45 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 47/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1394 - acc: 0.9502 - val_loss: 0.5527 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.89930\n",
      "epoch =  46 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 48/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1399 - acc: 0.9496 - val_loss: 0.5475 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.89930\n",
      "epoch =  47 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 49/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1355 - acc: 0.9517 - val_loss: 0.5417 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.89930\n",
      "epoch =  48 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 50/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1350 - acc: 0.9517 - val_loss: 0.5362 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.89930\n",
      "epoch =  49 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 51/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1314 - acc: 0.9528 - val_loss: 0.5322 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.89930\n",
      "epoch =  50 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 52/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1295 - acc: 0.9535 - val_loss: 0.5730 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.89930\n",
      "epoch =  51 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 53/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1300 - acc: 0.9537 - val_loss: 0.5744 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.89930\n",
      "epoch =  52 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 54/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1259 - acc: 0.9555 - val_loss: 0.5798 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.89930\n",
      "epoch =  53 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 55/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1280 - acc: 0.9537 - val_loss: 0.5794 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.89930\n",
      "epoch =  54 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 56/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1238 - acc: 0.9552 - val_loss: 0.5578 - val_acc: 0.8922\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.89930\n",
      "epoch =  55 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 57/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1239 - acc: 0.9553 - val_loss: 0.5799 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.89930\n",
      "epoch =  56 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 58/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1245 - acc: 0.9546 - val_loss: 0.5433 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.89930\n",
      "epoch =  57 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 59/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1208 - acc: 0.9560 - val_loss: 0.5478 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.89930\n",
      "epoch =  58 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 60/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1218 - acc: 0.9561 - val_loss: 0.5529 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.89930\n",
      "epoch =  59 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 61/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1180 - acc: 0.9568 - val_loss: 0.5960 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.89930\n",
      "epoch =  60 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 62/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1156 - acc: 0.9587 - val_loss: 0.5511 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.89930\n",
      "epoch =  61 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 63/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1184 - acc: 0.9573 - val_loss: 0.5770 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.89930\n",
      "epoch =  62 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 64/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1192 - acc: 0.9575 - val_loss: 0.5461 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.89930\n",
      "epoch =  63 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 65/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1132 - acc: 0.9589 - val_loss: 0.5862 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.89930\n",
      "epoch =  64 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 66/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1142 - acc: 0.9591 - val_loss: 0.5858 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.89930\n",
      "epoch =  65 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 67/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1110 - acc: 0.9603 - val_loss: 0.5446 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.89930\n",
      "epoch =  66 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 68/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1108 - acc: 0.9609 - val_loss: 0.5775 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.89930\n",
      "epoch =  67 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 69/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1092 - acc: 0.9603 - val_loss: 0.5453 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.89930 to 0.90150, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-69-0.9015.hdf5\n",
      "epoch =  68 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 70/175\n",
      "391/390 [==============================] - 100s 255ms/step - loss: 0.1101 - acc: 0.9609 - val_loss: 0.6052 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.90150\n",
      "epoch =  69 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 71/175\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.1088 - acc: 0.9611 - val_loss: 0.5936 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.90150\n",
      "epoch =  70 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 72/175\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9603"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 175\n",
    "\n",
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 2.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  We can see that model achieved 90.15% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 15s 1ms/step\n",
      "Test loss: 0.5452964616169688\n",
      "Test accuracy: 0.9015\n",
      "50000/50000 [==============================] - 72s 1ms/step\n",
      "Train loss: 0.09000801703142672\n",
      "Train accuracy: 0.97348\n"
     ]
    }
   ],
   "source": [
    "load_model_from_back = True\n",
    "\n",
    "if load_model_from_back:\n",
    "    model.load_weights('DNST_CIFAR10_Conv_09_09_final_tr2-69-0.9015.hdf5')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    score = model.evaluate(x_train, y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Just showing the maximum accuracy got - unfortunately not in the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 15s 1ms/step\n",
      "Test loss: 0.5823950641511939\n",
      "Test accuracy: 0.9061\n",
      "50000/50000 [==============================] - 73s 1ms/step\n",
      "Train loss: 0.04425766106435287\n",
      "Train accuracy: 0.98686\n"
     ]
    }
   ],
   "source": [
    "load_model_from_back = True\n",
    "\n",
    "if load_model_from_back:\n",
    "    model.load_weights('DNST_CIFAR10_Conv_09_09_final_tr2-163-0.9061.hdf5')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    score = model.evaluate(x_train, y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One more try, 19:29 30 october 30, more agumentaion, 2x steps per epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 654us/step\n",
      "Test loss: 0.4431272743701935\n",
      "Test accuracy: 0.8762\n",
      "50000/50000 [==============================] - 32s 649us/step\n",
      "Train loss: 0.22539761049449444\n",
      "Train accuracy: 0.92494\n"
     ]
    }
   ],
   "source": [
    "load_model_from_back = True\n",
    "\n",
    "if load_model_from_back:\n",
    "    model.load_weights('DNST_CIFAR10_Conv_09_09_final_tr2-63-0.8762.hdf5')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    score = model.evaluate(x_train, y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.25,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.25,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.9\n",
      "1e-04\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import keras.backend as K\n",
    "k.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print(K.eval(model.optimizer.momentum))\n",
    "print(K.eval(model.optimizer.decay))\n",
    "print(model.optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/187\n",
      "586/585 [==============================] - 142s 243ms/step - loss: 0.4413 - acc: 0.8467 - val_loss: 0.4100 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.90610\n",
      "epoch =  0 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 2/187\n",
      "586/585 [==============================] - 141s 241ms/step - loss: 0.4101 - acc: 0.8570 - val_loss: 0.4392 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90610\n",
      "epoch =  1 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 3/187\n",
      "586/585 [==============================] - 141s 240ms/step - loss: 0.3970 - acc: 0.8610 - val_loss: 0.4301 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90610\n",
      "epoch =  2 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 4/187\n",
      "586/585 [==============================] - 141s 241ms/step - loss: 0.3864 - acc: 0.8645 - val_loss: 0.4272 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90610\n",
      "epoch =  3 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 5/187\n",
      "586/585 [==============================] - 140s 240ms/step - loss: 0.3783 - acc: 0.8679 - val_loss: 0.4379 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90610\n",
      "epoch =  4 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 6/187\n",
      "586/585 [==============================] - 140s 240ms/step - loss: 0.3756 - acc: 0.8689 - val_loss: 0.4388 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90610\n",
      "epoch =  5 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 7/187\n",
      "586/585 [==============================] - 140s 238ms/step - loss: 0.3713 - acc: 0.8704 - val_loss: 0.4447 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90610\n",
      "epoch =  6 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 8/187\n",
      "586/585 [==============================] - 139s 238ms/step - loss: 0.3644 - acc: 0.8722 - val_loss: 0.4506 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90610\n",
      "epoch =  7 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 9/187\n",
      "586/585 [==============================] - 139s 238ms/step - loss: 0.3602 - acc: 0.8743 - val_loss: 0.4423 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90610\n",
      "epoch =  8 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 10/187\n",
      "586/585 [==============================] - 139s 238ms/step - loss: 0.3554 - acc: 0.8748 - val_loss: 0.4780 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90610\n",
      "epoch =  9 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 11/187\n",
      "585/585 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8757"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 250- 63\n",
    "\n",
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 3.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This trial did not help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1781
    },
    "colab_type": "code",
    "id": "KbD-T7m0G6lP",
    "outputId": "198b9368-e44a-461d-a822-15e6901dc520"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imdB9nUyoCn0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "eEgYnYbSoDJg",
    "outputId": "bdc7ee86-c7dd-4905-ed02-b91d18c0424f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1373
    },
    "colab_type": "code",
    "id": "LLcxWH2hoDXw",
    "outputId": "5143ffbd-b989-4dc5-c1fc-3ee16dfe0d5d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rpig1ugEsLfe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H0PIL3pysLxt",
    "outputId": "f4855f05-c410-49f0-839b-c1c62e169196"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wn3m4_EjsMGE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4PzRvhLvHsK",
    "outputId": "01b9cc7a-df0a-41c5-e312-eab3b46fb24a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ethaY4Y2wi4I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0yrzJxXw0rM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "A5uOHjlkw045",
    "outputId": "db583ad7-967e-416f-f212-7b83f77f3c6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "EpyFvpU0w1GY",
    "outputId": "8e3f9817-ef81-4709-f332-689ab3a7eba6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x5ZsYV6yw1DV",
    "outputId": "b98facfe-1bd6-40bb-8f47-bd6027867392"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWzP6Edpw0_x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_HMxDUvWZ0F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "eadO_adxWaFe",
    "outputId": "c8909100-25c9-4a0b-f79d-e0fece23c4f6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_32NGkhiprV7",
    "outputId": "df92c9ac-63ea-4d1a-912f-d7562598d5ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMEISrvNprzz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "U3PICoCgw01Z",
    "outputId": "e6e8a94b-cfd8-4ce8-9bab-b1e0081a759d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p916JhoWHz6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlZmM-_zG6lS",
    "outputId": "9977e1ed-3f85-4f39-f9f7-4baa702e2e76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6zvEjTAoBM4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qq-HWYiln_b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmvoF8QVG6lU",
    "outputId": "9e7ac435-50e3-4a84-f347-7e78bf01d9de"
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zix_gEdBG6lX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAFfDq18G6lZ",
    "outputId": "b7ac644b-f46b-4fc6-95e1-2437e58f3898"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcMp-CA3G6lc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUMfE3mfG6ld",
    "outputId": "b12040ea-6043-46c5-9c5c-87f1d12873b6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP9uPg9GG6lh",
    "outputId": "cf1ac1cb-8982-4136-ded1-0f7cbcc5e729"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZVtRNGtG6ll",
    "outputId": "17891475-5760-497c-9e8b-795465f9d46b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iq_aLgxuG6lp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jQ3lM8zG6lv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpU6cQarG6lx",
    "outputId": "6d08876d-c10d-4b68-9f6c-0b4240ecf71d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCE9_64ZG6l2",
    "outputId": "3cc5efd4-7104-4da9-8997-894249ee5562"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gS6ODLgHG6l5",
    "outputId": "8b30c208-9fe2-4ceb-e3a6-d66d9ffac8d3"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m6Mgwh1G6l8",
    "outputId": "bc3aee71-5d64-4ecd-fcf4-c2b368ec89f8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSMOqu70G6l_",
    "outputId": "f1f97535-70c4-4e98-9dcc-a156368420e9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEQ6qu5BG6mC",
    "outputId": "d3d5b175-fbc8-4624-a476-6ff6ae9ec189"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTi7d5RDG6mM",
    "outputId": "f92692b1-e390-4c5c-bbb4-8664132c1ecf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2UeD_6KG6mR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onvf93F-G6mU",
    "outputId": "ba633c58-eb7c-4c1d-e296-f44a15990493"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeR7qi_iG6mX",
    "outputId": "e12e99a9-c267-4c81-fe24-6d4c4809681a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_W4l0s3G6ma",
    "outputId": "e3460c04-8738-45f1-8ac4-1bae56fa04fe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4A_Ktx95G6mh",
    "outputId": "863c7823-cf52-4383-b546-fb73b8033e56"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAnw_xNlG6mj",
    "outputId": "f679acb4-169a-4d23-acd0-b1b540596108"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwOoDMefG6mm",
    "outputId": "002e30cf-7bb5-420c-bc7c-86bb1c1d8d7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cU0meEE3G6mr",
    "outputId": "f6793d3d-6c44-4eb8-fcb1-1112b3c540a0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWYRrcp7G6mv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DNST_CIFAR10_Conv_09.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
