{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assingnement 4\n",
    "\n",
    "### Objective: Obtain an accuracy of 92% using denent trained using SGD under 250 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Result : \n",
    "\n",
    "  - Model-1 **982K params**\n",
    "    - 4 Denseblocks with layers [8,6,20,12], growth rate= 12, , compression = 0.5, dropout = 0.2\n",
    "    \n",
    "    Achieved 90.15 (given in the log) *\n",
    "    \n",
    "    \n",
    "    * by this time the connection got disconnected, the model achieved 90.65% which \n",
    "              \n",
    "                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apporach:\n",
    "\n",
    "Step 1. exploratory analysis\n",
    "\n",
    "   - check if data distribution fine\t\n",
    "    \n",
    "Step 2. Data preprocessng\n",
    "\n",
    "   - Normalise the data before feeding the network\n",
    "    \n",
    "Step 3. Data Augmentation\n",
    "\n",
    "   - this is complex network so we need more samples for the model to generalize well\n",
    "   \n",
    "   - we applied an intial augmentaion in **ImageDataGenerator()**\n",
    "   \n",
    "       - rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "       - width_shift_range=0.20,  # randomly shift images horizontally (fraction of total width)\n",
    "       - height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "       - horizontal_flip=True,  # randomly flip images\n",
    "\t\t\n",
    "  - the above augmentation looked insufficent and later we changed to the following settngs\n",
    "  \n",
    "    - rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    - width_shift_range=0.25,  # randomly shift images horizontally (fraction of total width)\n",
    "    - height_shift_range=0.25,  # randomly shift images vertically (fraction of total height)\n",
    "    - horizontal_flip=True,  # randomly flip images\t\n",
    "\n",
    "### Getting the right model and fine tuning the architecure\n",
    "\n",
    "Step 5. Correcting the current code (**This was the most tricky part**)\n",
    "\n",
    "   - Checked if given code for the model is correct.\n",
    "   \n",
    "   - referred the densent paper [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993) and checked online densent to verify whether my code is correct or not?\n",
    "   \n",
    "   - there was few corrections needed in the given code\n",
    "   \n",
    "   - Implemented Bottle neck layer, transitin  correctly in the given code\n",
    "\n",
    "Step 6 - Getting the correct architecture\n",
    "\n",
    "- aim was to use all the 1M parameter allowed\n",
    "\n",
    "- I implemented two **Densent-BC** models\n",
    "\n",
    "- Model-1 **982K params**\n",
    "    - 4 Denseblocks with layers [8,6,20,12], growth rate= 12, , compression = 0.5, dropout = 0.2\n",
    "    \n",
    "- Model-2 **936K params**\n",
    "    - 4 Denseblocks with layer  [14,14,14,14], growth rate= 12, compression = 0.5, dropout = 0.2\n",
    "    \n",
    "- 3 Denseblock layer \n",
    "    - it was tried  [16, 16, 16] but performance was not good so dorrpped\n",
    "\n",
    "Step 6. Check if the chosen models will achive 92% target\n",
    "\n",
    "-  training with **SGD()** is not going to be easy, so I tested the selected models using **Adam()** ,\n",
    "       both the models I chose got more than 92 acccurcy\n",
    "       \n",
    "    - logs - Model-1 achieved 92% with Adam()\n",
    "        - \n",
    "    - logs - Model-2 achieved 92% with Adam()\n",
    "       - this seemed to converge slig\n",
    "       \n",
    "       \n",
    "Step X. Training\n",
    "\n",
    "   - in the densent paper they trained the network for 300 epohcs\n",
    "      - varying the learning rate (**lr**) in the following way.\n",
    "      - lr = 0.1 for 150 epochs (50% of epochs)\n",
    "      - lr = 0.01 for next 75 epohcs ( 25%)\n",
    "      - lr = 0.001 for last 75 epochs (25%)\n",
    "      \n",
    "  - I treid to follow a similiar distribution among 250 epocs.\n",
    "       anothere thought was perormance improemnt from the last 25% epochs(lr = 0.001) is less in the paper\n",
    "       so 150, 75, 25 to use the same split and train less using (lr = 0.001)\n",
    " \n",
    "Step X. increace batch size instead of reducing leaning rate\n",
    "\n",
    "   - DONâ€™T DECAY THE LEARNING RATE, INCREASE THE BATCH SIZE (https://openreview.net/pdf?id=B1Yy1BxCZ)\n",
    "\n",
    "   - I tried learning rate schdule manulal start and stop to reduce learning rate over time \n",
    "      but that does not seem to be worked.\n",
    "      \n",
    "   - This paper talks about a method of increasing batch size instead of reducint lr.\n",
    "      basically they tell that reducing leaning rate by half is eqivalient to increacing batch size by 2.\n",
    "      \n",
    "   - I tried this technique to get the last push, seemed to be working but could not get pass the 92% mark\n",
    "      \n",
    "Step 9. Other appoaches tried \n",
    "\n",
    "   - tried kernel_initializer='he_normal' did not showed any differnce\n",
    "      - log\n",
    "      \n",
    "   - tried cycling learning rate did not seem to help\n",
    "\n",
    "   - Tried Sperable Convolution so I could increace the capcity, the model capacity was increased to \n",
    "       - Model-2 improved, became [16, 16, 18, 16] **957K parmas**\n",
    "     \n",
    "    \n",
    "Step 9. Other appoaches tried \n",
    "   - Model-2 improved, is under training will update the results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "K70hAckqg0EA",
    "outputId": "a0dba4c3-f402-4223-ea89-3be41ca275fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# https://keras.io/\n",
    "#!pip install -q keras\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVIx_KIigxPV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.layers import Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "756bdmamG6f1",
    "outputId": "2f1c4951-b47b-40a0-ab02-1c97fd7c1a95"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight \n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhIk-iu4G6f-"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time, pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XBoa2F25G6gE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNHw6luQg3gc"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf\n",
    "from keras import backend as k\n",
    "\n",
    "# Don't pre-allocate memory; allocate as-needed\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# Create a session with the above options specified.\n",
    "k.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dsO_yGxcg5D8"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "#l = 40\n",
    "#num_filter = 12\n",
    "compression = 0.5\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Traing options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iWRR6JyzG6gT"
   },
   "outputs": [],
   "source": [
    "do_sub_sampling_of_input = False # for fast training use only 25 % of data\n",
    "do_data_augmentation = True    # data augmentaion\n",
    "do_data_append       = False   # data becomes 2X sized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "mB7o3zu1g6eT",
    "outputId": "16a221e4-1075-49d1-9d76-8091d240f280"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "img_height, img_width, channel = x_train.shape[1],x_train.shape[2],x_train.shape[3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G_hYUAbsG6ge"
   },
   "outputs": [],
   "source": [
    "nb_classes = 10\n",
    "class_name = {\n",
    "    0: 'airplane',\n",
    "    1: 'automobile',\n",
    "    2: 'bird',\n",
    "    3: 'cat',\n",
    "    4: 'deer',\n",
    "    5: 'dog',\n",
    "    6: 'frog',\n",
    "    7: 'horse',\n",
    "    8: 'ship',\n",
    "    9: 'truck',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "00iNYJLkG6gj",
    "outputId": "4911e408-9a52-4009-eefd-44e5242fb219"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6], dtype=uint8), 32, 32, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0], img_height, img_width, channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OS5X5srxG6gp"
   },
   "outputs": [],
   "source": [
    "def draw_img(i, x_train, y_train, class_name):\n",
    "    im = x_train[i]\n",
    "    c = y_train[i]\n",
    "    plt.imshow(im)\n",
    "    plt.title(\"Class %d (%s)\" % (int(c), class_name[int(c)]))\n",
    "    plt.axis('on')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "mjF2KvIQG6gw",
    "outputId": "6c7a984d-4db5-4d5b-d110-b740edd41a02"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_img(7, x_train, y_train, class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions to dispaly and analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These helper functions\n",
    "\n",
    "plot_confusion_matrix(): helps us to plot the confusion matrix. \n",
    "It is taken from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html. \n",
    "The same page has some sample examples on how to use this function \n",
    "cm: Confusion matrix calcualted using confusion_matrix() from sklearn.metrics <br//> classes: a list of labels for the classes we are plotting\n",
    "normalize=False: True means we will plot nomalized values \n",
    "title='Confusion matrix': set the tiltle of the plot \n",
    "cmap : leave it as it is \n",
    "Example Usage:plot_confusion_matrix(cm, classes=Facial_Expressions, normalize=True, title='Test Data - Using Simple Average Ensembling ')\n",
    "\n",
    "plot_histogram(): helps to plot the histogram of a list \n",
    "lst_data: the list whose histogtam we want to plot , \n",
    "class_labels: a list of labels for the classes we are plotting \n",
    "ylabel='None': set the y label of the plot, x label is always frequency \n",
    "title='None': set the tiltle of the plot -lst_data, class_labels, ylabel='None', title='None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm) #to print in text if needed\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "def plot_histogram(lst_data, class_labels, ylabel='None', title='None'):\n",
    "    data = pd.Series(lst_data)\n",
    "    distribution = data.value_counts(sort=False)\n",
    "    y_pos = np.arange(len(class_labels))\n",
    "    \n",
    "    plt.bar(y_pos, distribution, align='center', alpha=0.8)\n",
    "    plt.xticks(y_pos, class_labels)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_classes = ['airplane', 'automobile', 'bird','cat', 'deer','dog','frog','horse','ship','truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visulalising the data, check for class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(list(y_train), y_classes, ylabel='Frequency',title='CIFAR 10 Class Distribution in Training Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_histogram(list(y_test), y_classes, ylabel='Frequency',title='CIFAR 10 Class Distribution in Test Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmdwlu8pG6g3"
   },
   "outputs": [],
   "source": [
    "# convert to one hot encoing \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9JGd4ezgG6g7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "z_arXgOSG6hA",
    "outputId": "8960acf7-335b-4c96-9ae9-7fe9b9ad56fc"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "colab_type": "code",
    "id": "jd2usuXDG6hH",
    "outputId": "a0716d82-94e5-4f1b-ba28-39b1cdced01b"
   },
   "source": [
    "##  Normalising the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "T372AU6RG6hN",
    "outputId": "4739d668-5818-4f70-e6d3-3491edcb274c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel Mean :  [[[[125.3069  122.95015 113.866  ]]]]\n",
      "Channel Std :  [[[[62.99325  62.088604 66.70501 ]]]]\n",
      "Channel Mean1 :  [[[[126.02428 123.70843 114.85442]]]]\n",
      "Channel Std1 :  [[[[62.896416 61.937508 66.70607 ]]]]\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test  = x_test.astype('float32')\n",
    "\n",
    "mean  = np.mean(x_train, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "std   = np.std(x_train, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "\n",
    "mean1  = np.mean(x_test, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "std1   = np.std(x_test, axis=(0, 1, 2), keepdims=True).astype('float32')\n",
    "\n",
    "\n",
    "print(\"Channel Mean : \", mean)\n",
    "print(\"Channel Std : \", std)\n",
    "print(\"Channel Mean1 : \", mean1)\n",
    "print(\"Channel Std1 : \", std1)\n",
    "\n",
    "\n",
    "\n",
    "x_train = (x_train - mean) / (std)\n",
    "x_test  = (x_test - mean1) / (std1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yOCMAYM1G6hT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After normalisation input looks like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZF74U6zcG6hX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.0526032e+00, -9.8166406e-01, -7.6255137e-01],\n",
       "        [-1.3065987e+00, -1.2393603e+00, -1.0323962e+00],\n",
       "        [-1.1954757e+00, -1.2071482e+00, -1.0623789e+00],\n",
       "        ...,\n",
       "        [ 5.1899368e-01,  1.4575703e-01, -8.7939382e-02],\n",
       "        [ 4.2374539e-01,  3.3014923e-02, -1.7788765e-01],\n",
       "        [ 3.6024651e-01,  1.6908908e-02, -1.6289628e-01]],\n",
       "\n",
       "       [[-1.7352160e+00, -1.6581167e+00, -1.4071807e+00],\n",
       "        [-1.9892114e+00, -1.9802370e+00, -1.7070082e+00],\n",
       "        [-1.7034665e+00, -1.8513888e+00, -1.7070082e+00],\n",
       "        ...,\n",
       "        [-3.6621384e-02, -5.6290764e-01, -8.8248241e-01],\n",
       "        [-1.0012025e-01, -6.4343774e-01, -9.5743930e-01],\n",
       "        [-5.2496098e-02, -5.7901365e-01, -8.5249966e-01]],\n",
       "\n",
       "       [[-1.5923436e+00, -1.5936927e+00, -1.3921893e+00],\n",
       "        [-1.7352160e+00, -1.8674948e+00, -1.7070082e+00],\n",
       "        [-1.2113504e+00, -1.5453745e+00, -1.5870771e+00],\n",
       "        ...,\n",
       "        [-1.1599497e-01, -6.2733167e-01, -9.5743930e-01],\n",
       "        [-8.4245533e-02, -6.2733167e-01, -9.5743930e-01],\n",
       "        [-2.5886741e-01, -8.0449790e-01, -1.0773703e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 1.3127295e+00,  7.5778562e-01, -2.6783592e-01],\n",
       "        [ 1.2016065e+00,  4.8398334e-01, -1.1973014e+00],\n",
       "        [ 1.1539823e+00,  6.1283147e-01, -1.3172324e+00],\n",
       "        ...,\n",
       "        [ 5.5074310e-01,  1.6186304e-01, -6.5761173e-01],\n",
       "        [-1.1002274e+00, -1.4809505e+00, -1.6020685e+00],\n",
       "        [-1.1478515e+00, -1.4326324e+00, -1.4071807e+00]],\n",
       "\n",
       "       [[ 8.6823744e-01,  2.5849915e-01, -2.6783592e-01],\n",
       "        [ 7.5711441e-01,  8.0289232e-04, -1.0773703e+00],\n",
       "        [ 9.6348572e-01,  3.3902922e-01, -1.2572669e+00],\n",
       "        ...,\n",
       "        [ 9.3173629e-01,  4.0345326e-01, -2.9781866e-01],\n",
       "        [-4.4936401e-01, -9.8166406e-01, -1.1973014e+00],\n",
       "        [-6.7161006e-01, -1.1266181e+00, -1.1973014e+00]],\n",
       "\n",
       "       [[ 8.2061332e-01,  3.3902922e-01,  3.1991642e-02],\n",
       "        [ 6.7774087e-01,  9.7438984e-02, -2.9781866e-01],\n",
       "        [ 8.5236275e-01,  3.0681717e-01, -4.0275833e-01],\n",
       "        ...,\n",
       "        [ 1.4397272e+00,  9.8326981e-01,  3.9178470e-01],\n",
       "        [ 4.0787068e-01, -7.9727180e-02, -4.4773245e-01],\n",
       "        [-3.6621384e-02, -4.9848357e-01, -6.2762898e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "acEl5EjAG6hd",
    "outputId": "9efce3d3-3074-4f2e-b660-4c6b2f0caf20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XuGiXp6rG6hk",
    "outputId": "acc28bb5-470e-48c3-8e6c-354db61c19f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xb0EH5H_G6hq"
   },
   "outputs": [],
   "source": [
    "if do_sub_sampling_of_input:\n",
    "    x_, x_train, x_, y_train    = cross_validation.train_test_split(x_train, y_train, test_size=0.25, random_state=0)\n",
    "    x_, x_test,  y_, y_test    = cross_validation.train_test_split(x_test, y_test, test_size=0.25, random_state=0)\n",
    "    print(\"After SubSampling\")\n",
    "    print(x_train.shape, x_test.shape)\n",
    "    print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7jz7L_trG6hv"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "if do_data_append :\n",
    "    print(\"Doing Data Appending\")\n",
    "    x_train = np.append(x_train, x_train,axis=0)\n",
    "    y_train = np.append(y_train, y_train,axis=0)\n",
    "#print(np.append(x_train, x_train,axis=0).shape)\n",
    "#print(np.append(y_train, y_train,axis=0).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "MkHX4hNLG6h0",
    "outputId": "25cf1428-1767-461c-ced2-577e40a2dec3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GMuvM67DG6h8"
   },
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npxonLr5G6h-"
   },
   "outputs": [],
   "source": [
    "keras.utils.Sequence\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Tk4q4iYG6iD"
   },
   "outputs": [],
   "source": [
    "from keras.layers import SeparableConv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction densenet -BC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee-sge5Kg7vr"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def add_denseblock(input, growth_rate, dropout_rate = 0.2, l = 0):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l):\n",
    "        BatchNorm = BatchNormalization()(temp)\n",
    "        relu = Activation('relu')(BatchNorm)\n",
    "\n",
    "        Conv2D_1_1 = Conv2D(int(growth_rate*4), (1,1), use_bias=False ,padding='same')(relu)\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_1_1 = Dropout(dropout_rate)(Conv2D_1_1)\n",
    "        BatchNorm_1_1 = BatchNormalization()(Conv2D_1_1)\n",
    "        relu_1_1 = Activation('relu')(BatchNorm_1_1)\n",
    "        \n",
    "        Conv2D_3_3 = Conv2D(int(growth_rate), (3,3), use_bias=False ,padding='same')(relu_1_1)\n",
    "        #Conv2D_3_3 = SeparableConv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu_1_1) # later tried this\n",
    "        if dropout_rate>0:\n",
    "            Conv2D_3_3 = Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8eEu8gikG6iP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OOP6IPsGhBwb"
   },
   "outputs": [],
   "source": [
    "def add_transition(input, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    num_channels = int(input.shape[-1]) #assuming it is tensor\n",
    "    Conv2D_BottleNeck = Conv2D(int(num_channels*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    \n",
    "\n",
    "    if dropout_rate>0:\n",
    "      Conv2D_BottleNeck = Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0RaKFpubhDIC"
   },
   "outputs": [],
   "source": [
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = BatchNormalization()(input)\n",
    "    relu = Activation('relu')(BatchNorm)\n",
    "    AvgPooling = AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = Flatten()(AvgPooling)\n",
    "    #flat = Dropout(0.25)(flat) # tried this, did not help\n",
    "    output = Dense(num_classes, activation='softmax')(flat)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbzC-GOZG6ie"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "anPCpQWhhGb7"
   },
   "outputs": [],
   "source": [
    "num_filter = growth_rate = 12\n",
    "dropout_rate = 0.2\n",
    "compression = 0.5\n",
    "dense_l= [8, 16, 20, 12]\n",
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(2*num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, growth_rate, dropout_rate, dense_l[0])\n",
    "First_Transition = add_transition(First_Block, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, growth_rate, dropout_rate, dense_l[1])\n",
    "Second_Transition = add_transition(Second_Block, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate, dense_l[2])\n",
    "Third_Transition = add_transition(Third_Block, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  growth_rate, dropout_rate, dense_l[3])\n",
    "output = output_layer(Last_Block)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing and Verifying the Densenet-BC configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "p9uA_iR8G6io",
    "outputId": "87a7b724-7e86-416d-e7e9-6526b4bc860b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 3)\n",
      "(?, 32, 32, 24)\n",
      "(?, 32, 32, 120) 120\n",
      "(?, 16, 16, 60)\n",
      "(?, 16, 16, 252)\n",
      "(?, 8, 8, 126)\n",
      "(?, 8, 8, 366)\n",
      "(?, 4, 4, 183)\n",
      "(?, 4, 4, 327)\n"
     ]
    }
   ],
   "source": [
    "print(input.shape)\n",
    "print(First_Conv2D.shape)\n",
    "print(First_Block.shape, First_Block.shape[-1])\n",
    "print(First_Transition.shape)\n",
    "\n",
    "print(Second_Block.shape)\n",
    "print(Second_Transition.shape)\n",
    "\n",
    "print(Third_Block.shape)\n",
    "print(Third_Transition.shape)\n",
    "\n",
    "print(Last_Block.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 19618
    },
    "colab_type": "code",
    "id": "1kFh7pdxhNtT",
    "outputId": "7bc989ab-6517-466c-8120-25c63379a4e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 24)   648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 24)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 24)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 48)   1152        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 48)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 48)   192         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 48)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 12)   5184        activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 12)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 36)   0           conv2d_1[0][0]                   \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 36)   144         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 36)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 48)   1728        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 48)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 48)   192         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 48)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 12)   5184        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 12)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 48)   0           concatenate_1[0][0]              \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 48)   192         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 48)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 48)   2304        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 48)   0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 48)   192         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 12)   5184        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 12)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 60)   0           concatenate_2[0][0]              \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 60)   240         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 60)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 48)   2880        activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 48)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 48)   192         dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 48)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 12)   5184        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 12)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 72)   0           concatenate_3[0][0]              \n",
      "                                                                 dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 72)   288         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 72)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 48)   3456        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32, 32, 48)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 48)   192         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 48)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 32, 32, 12)   5184        activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 32, 32, 12)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 84)   0           concatenate_4[0][0]              \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 84)   336         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 32, 32, 84)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 48)   4032        activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 32, 32, 48)   0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 48)   192         dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 32, 32, 48)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 12)   5184        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 12)   0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 96)   0           concatenate_5[0][0]              \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 96)   384         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 32, 32, 96)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 48)   4608        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 48)   0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 32, 32, 48)   192         dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 32, 32, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 12)   5184        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 32, 32, 12)   0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 108)  0           concatenate_6[0][0]              \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 32, 32, 108)  432         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 32, 32, 108)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 48)   5184        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 32, 32, 48)   0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 48)   192         dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 48)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 12)   5184        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 12)   0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 120)  0           concatenate_7[0][0]              \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 120)  480         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 32, 32, 120)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 32, 32, 60)   7200        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 60)   0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 16, 60)   0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 60)   240         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16, 16, 60)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 48)   2880        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 48)   0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 48)   192         dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 16, 16, 48)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 16, 16, 12)   5184        activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 12)   0           conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 72)   0           average_pooling2d_1[0][0]        \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 16, 16, 72)   288         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 16, 16, 72)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 16, 16, 48)   3456        activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 16, 16, 48)   0           conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 16, 16, 48)   192         dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 16, 16, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 16, 16, 12)   5184        activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 16, 16, 12)   0           conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 84)   0           concatenate_9[0][0]              \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 16, 16, 84)   336         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 16, 16, 84)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 16, 16, 48)   4032        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 16, 16, 48)   0           conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16, 16, 48)   192         dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 16, 16, 48)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 16, 16, 12)   5184        activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 16, 16, 12)   0           conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 96)   0           concatenate_10[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 16, 16, 96)   384         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 16, 16, 48)   4608        activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 16, 16, 48)   0           conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 16, 16, 48)   192         dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16, 16, 48)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 16, 16, 12)   5184        activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 16, 16, 12)   0           conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 108)  0           concatenate_11[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 16, 16, 108)  432         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 16, 16, 108)  0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 16, 16, 48)   5184        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 16, 16, 48)   0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 48)   192         dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 16, 16, 48)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 12)   5184        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 16, 16, 12)   0           conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 120)  0           concatenate_12[0][0]             \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 120)  480         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 16, 16, 120)  0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 48)   5760        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 16, 16, 48)   0           conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 48)   192         dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 16, 16, 48)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 12)   5184        activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 16, 16, 12)   0           conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 132)  0           concatenate_13[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 16, 16, 132)  528         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 16, 16, 132)  0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 48)   6336        activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 16, 16, 48)   0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 16, 16, 48)   192         dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 16, 16, 48)   0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 16, 16, 12)   5184        activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 16, 16, 12)   0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 144)  0           concatenate_14[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 16, 16, 144)  576         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 16, 16, 144)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 16, 16, 48)   6912        activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 16, 16, 48)   0           conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 16, 16, 48)   192         dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16, 16, 48)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 16, 16, 12)   5184        activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 16, 16, 12)   0           conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 16, 16, 156)  0           concatenate_15[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 16, 16, 156)  624         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 16, 16, 156)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 16, 16, 48)   7488        activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 16, 16, 48)   0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 16, 16, 48)   192         dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 16, 16, 48)   0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 16, 16, 12)   5184        activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 16, 16, 12)   0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 16, 16, 168)  0           concatenate_16[0][0]             \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 16, 16, 168)  672         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16, 16, 168)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 16, 16, 48)   8064        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 16, 16, 48)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 16, 16, 48)   192         dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 16, 16, 48)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 16, 16, 12)   5184        activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 16, 16, 12)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 16, 16, 180)  0           concatenate_17[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 16, 16, 180)  720         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 16, 16, 180)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 16, 16, 48)   8640        activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 16, 16, 48)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 16, 16, 48)   192         dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 16, 16, 48)   0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 16, 16, 12)   5184        activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 16, 16, 12)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 16, 16, 192)  0           concatenate_18[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 16, 16, 192)  768         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16, 16, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 16, 16, 48)   9216        activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 16, 16, 48)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 16, 16, 48)   192         dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 16, 16, 48)   0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 16, 16, 12)   5184        activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 16, 16, 12)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 16, 16, 204)  0           concatenate_19[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 16, 16, 204)  816         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 16, 16, 204)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 16, 16, 48)   9792        activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 16, 16, 48)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 16, 16, 48)   192         dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 16, 16, 48)   0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 16, 16, 12)   5184        activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 16, 16, 12)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 16, 16, 216)  0           concatenate_20[0][0]             \n",
      "                                                                 dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 16, 16, 216)  864         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 16, 16, 216)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 16, 16, 48)   10368       activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 48)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 48)   192         dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 48)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 12)   5184        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 12)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 16, 16, 228)  0           concatenate_21[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 228)  912         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 228)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 48)   10944       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 48)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 48)   192         dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 48)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 12)   5184        activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 12)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 16, 16, 240)  0           concatenate_22[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 240)  960         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 240)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 48)   11520       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 48)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 48)   192         dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 48)   0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 12)   5184        activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 12)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 16, 16, 252)  0           concatenate_23[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 252)  1008        concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 252)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 126)  31752       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 126)  0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 8, 126)    0           dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 8, 8, 126)    504         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 8, 8, 126)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 8, 8, 48)     6048        activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 8, 8, 48)     0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 8, 8, 48)     192         dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 8, 8, 48)     0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 8, 8, 12)     5184        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 8, 8, 12)     0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 8, 8, 138)    0           average_pooling2d_2[0][0]        \n",
      "                                                                 dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 8, 8, 138)    552         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 8, 8, 138)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 8, 8, 48)     6624        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 8, 8, 48)     0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 48)     192         dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 48)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 12)     5184        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8, 8, 12)     0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 8, 8, 150)    0           concatenate_25[0][0]             \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 150)    600         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 150)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 48)     7200        activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8, 8, 48)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 48)     192         dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 48)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 12)     5184        activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 8, 8, 12)     0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 8, 8, 162)    0           concatenate_26[0][0]             \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 162)    648         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 162)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 48)     7776        activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 8, 8, 48)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 48)     192         dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 48)     0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 12)     5184        activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 8, 8, 12)     0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 8, 8, 174)    0           concatenate_27[0][0]             \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 174)    696         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 174)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 48)     8352        activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 8, 8, 48)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 48)     192         dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 48)     0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 12)     5184        activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 12)     0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 8, 8, 186)    0           concatenate_28[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 186)    744         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 186)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 48)     8928        activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 8, 8, 48)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 48)     192         dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 48)     0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 12)     5184        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 8, 8, 12)     0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 8, 8, 198)    0           concatenate_29[0][0]             \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 8, 8, 198)    792         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 8, 8, 198)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 8, 8, 48)     9504        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 8, 8, 48)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 8, 8, 48)     192         dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 8, 8, 48)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 8, 8, 12)     5184        activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 8, 8, 12)     0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 8, 8, 210)    0           concatenate_30[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 8, 8, 210)    840         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 8, 8, 210)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 8, 8, 48)     10080       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 8, 8, 48)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 8, 8, 48)     192         dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 8, 8, 48)     0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 8, 8, 12)     5184        activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 8, 8, 12)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 8, 8, 222)    0           concatenate_31[0][0]             \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 8, 8, 222)    888         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 8, 8, 222)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 8, 8, 48)     10656       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 8, 8, 48)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 8, 8, 48)     192         dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 8, 8, 48)     0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 8, 8, 12)     5184        activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 8, 8, 12)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 8, 8, 234)    0           concatenate_32[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 8, 8, 234)    936         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 8, 8, 234)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 8, 8, 48)     11232       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 8, 8, 48)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 8, 8, 48)     192         dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 8, 8, 48)     0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 8, 8, 12)     5184        activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 8, 8, 12)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 8, 8, 246)    0           concatenate_33[0][0]             \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 8, 8, 246)    984         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 8, 8, 246)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 8, 8, 48)     11808       activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 8, 8, 48)     0           conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 8, 8, 48)     192         dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 8, 8, 48)     0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 8, 8, 12)     5184        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 8, 8, 12)     0           conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 8, 8, 258)    0           concatenate_34[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 8, 8, 258)    1032        concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 8, 8, 258)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 8, 8, 48)     12384       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 8, 8, 48)     0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 8, 8, 48)     192         dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 8, 8, 48)     0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 8, 8, 12)     5184        activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 8, 8, 12)     0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 8, 8, 270)    0           concatenate_35[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 8, 8, 270)    1080        concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 8, 8, 270)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 8, 8, 48)     12960       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 8, 8, 48)     0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 8, 8, 48)     192         dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 8, 8, 48)     0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 8, 8, 12)     5184        activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 8, 8, 12)     0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 8, 8, 282)    0           concatenate_36[0][0]             \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 8, 8, 282)    1128        concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 8, 8, 282)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 8, 8, 48)     13536       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 8, 8, 48)     0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 8, 8, 48)     192         dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 8, 8, 48)     0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 8, 8, 12)     5184        activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 8, 8, 12)     0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 8, 8, 294)    0           concatenate_37[0][0]             \n",
      "                                                                 dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 8, 8, 294)    1176        concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 8, 8, 294)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 8, 8, 48)     14112       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 8, 8, 48)     0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 8, 8, 48)     192         dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 8, 8, 48)     0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 8, 8, 12)     5184        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 8, 8, 12)     0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 8, 8, 306)    0           concatenate_38[0][0]             \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 8, 8, 306)    1224        concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 8, 8, 306)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 8, 8, 48)     14688       activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 8, 8, 48)     0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 8, 8, 48)     192         dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 8, 8, 48)     0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 8, 8, 12)     5184        activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 8, 8, 12)     0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 8, 8, 318)    0           concatenate_39[0][0]             \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 8, 8, 318)    1272        concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 8, 8, 318)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 8, 8, 48)     15264       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 8, 8, 48)     0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 8, 8, 48)     192         dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 8, 8, 48)     0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 8, 8, 12)     5184        activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 8, 8, 12)     0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 8, 8, 330)    0           concatenate_40[0][0]             \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 8, 8, 330)    1320        concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 8, 8, 330)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 8, 8, 48)     15840       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 8, 8, 48)     0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 8, 8, 48)     192         dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 8, 8, 48)     0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 8, 8, 12)     5184        activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 8, 8, 12)     0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 8, 8, 342)    0           concatenate_41[0][0]             \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 8, 8, 342)    1368        concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 8, 8, 342)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 8, 8, 48)     16416       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 8, 8, 48)     0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 8, 8, 48)     192         dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 8, 8, 48)     0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 8, 8, 12)     5184        activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 12)     0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 8, 8, 354)    0           concatenate_42[0][0]             \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 8, 8, 354)    1416        concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 8, 8, 354)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 8, 8, 48)     16992       activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 48)     0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 48)     192         dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 48)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 8, 8, 12)     5184        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 12)     0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 8, 8, 366)    0           concatenate_43[0][0]             \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 366)    1464        concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 366)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 183)    66978       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 183)    0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 4, 183)    0           dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 4, 4, 183)    732         average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 4, 4, 183)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 4, 4, 48)     8784        activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 4, 4, 48)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 4, 4, 48)     192         dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 4, 4, 48)     0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 4, 4, 12)     5184        activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 4, 4, 12)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 4, 4, 195)    0           average_pooling2d_3[0][0]        \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 4, 4, 195)    780         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 4, 4, 195)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 4, 4, 48)     9360        activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 4, 4, 48)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_normalization_95 (BatchNo (None, 4, 4, 48)     192         dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 4, 4, 48)     0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 4, 4, 12)     5184        activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 4, 4, 12)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 4, 4, 207)    0           concatenate_45[0][0]             \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 4, 4, 207)    828         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 4, 4, 207)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 4, 4, 48)     9936        activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 4, 4, 48)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 4, 4, 48)     192         dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 4, 4, 48)     0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 4, 4, 12)     5184        activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 4, 4, 12)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 4, 4, 219)    0           concatenate_46[0][0]             \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 4, 4, 219)    876         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 4, 4, 219)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 4, 4, 48)     10512       activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 4, 4, 48)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 48)     192         dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 48)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 4, 4, 12)     5184        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 4, 4, 12)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 4, 4, 231)    0           concatenate_47[0][0]             \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 231)    924         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 231)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 48)     11088       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 48)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 48)     192         dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 48)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 12)     5184        activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 12)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 4, 4, 243)    0           concatenate_48[0][0]             \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 243)    972         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 243)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 48)     11664       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 48)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 48)     192         dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 48)     0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 12)     5184        activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 12)     0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 4, 4, 255)    0           concatenate_49[0][0]             \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 255)    1020        concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 255)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 48)     12240       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 48)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 48)     192         dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 48)     0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 12)     5184        activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 4, 4, 12)     0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 4, 4, 267)    0           concatenate_50[0][0]             \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 267)    1068        concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 267)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 48)     12816       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 4, 4, 48)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 48)     192         dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 48)     0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 12)     5184        activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 4, 4, 12)     0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 4, 4, 279)    0           concatenate_51[0][0]             \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 4, 4, 279)    1116        concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 4, 4, 279)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 4, 4, 48)     13392       activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 4, 4, 48)     0           conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 4, 4, 48)     192         dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 4, 4, 48)     0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 4, 4, 12)     5184        activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 4, 4, 12)     0           conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 4, 4, 291)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 4, 4, 291)    1164        concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 4, 4, 291)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 4, 4, 48)     13968       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 4, 4, 48)     0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 4, 4, 48)     192         dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 4, 4, 48)     0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 4, 4, 12)     5184        activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 4, 4, 12)     0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 4, 4, 303)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 4, 4, 303)    1212        concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 4, 4, 303)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 4, 4, 48)     14544       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 4, 4, 48)     0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 4, 4, 48)     192         dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 4, 4, 48)     0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 4, 4, 12)     5184        activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 4, 4, 12)     0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 4, 4, 315)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 4, 4, 315)    1260        concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 4, 4, 315)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 4, 4, 48)     15120       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 4, 4, 48)     0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 4, 4, 48)     192         dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 4, 4, 48)     0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 4, 4, 12)     5184        activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 4, 4, 12)     0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 4, 4, 327)    0           concatenate_55[0][0]             \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 4, 4, 327)    1308        concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 4, 4, 327)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 2, 327)    0           activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1308)         0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           13090       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 982,216\n",
      "Trainable params: 953,278\n",
      "Non-trainable params: 28,938\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settinng the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f68LtcYHG6i4"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 90\n",
    "decay = learning_rate/epochs\n",
    "decay = 0.0001\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Oj8RSwyG6i9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6HT7ZwHzG6jG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b4XOsW3ahSkL"
   },
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "crhGk7kEhXAz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to adjust learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cycling learning rate was enabled before\n",
    "#batch_size = 64\n",
    "#clr_triangular = CyclicLR(mode='triangular', base_lr = 0.1, max_lr = 0.2, step_size = (len(x_train)* 2 * 4)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcWydmIVhZGr"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epochs_drop = 30.0\n",
    "    lrate = initial_lrate * math.pow(drop, math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T7dl5K84G6jl"
   },
   "outputs": [],
   "source": [
    "# learning rate schedule\n",
    "def step_decay1(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.5\n",
    "    epoch_drop_01 = 40\n",
    "    epoch_drop_02 = epoch_drop_01 + 40\n",
    "    epoch_drop_03 = epoch_drop_02 + 40\n",
    "    \n",
    "    if (epoch < epoch_drop_01):\n",
    "        lrate = initial_lrate\n",
    "    elif (epoch < epoch_drop_02):\n",
    "        lrate = initial_lrate * drop\n",
    "    else:\n",
    "        lrate = initial_lrate * drop * drop\n",
    "\n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JDig-b71G6jq"
   },
   "outputs": [],
   "source": [
    "def on_epoch_end(self, epoch, logs=None):\n",
    "    print(\"epoch: \", epoch,\"learning rate for\", K.eval(self.model.optimizer.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2zjHHVfPG6jw"
   },
   "outputs": [],
   "source": [
    "lrate = LearningRateScheduler(step_decay1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1aS6q4X1G6j0"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_on_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=0, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0.001)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.5, patience= 4, min_delta=0.003, verbose=1, cooldown=0, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YJgRsh_2G6j7"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GZZuotjhG6kA"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#filepath = file_prefix + r\".best.hdf5\"\n",
    "filepath = \"DNST_CIFAR10_Conv_09_09_final_tr2-{epoch:02d}-{val_acc:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', save_weights_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UE3lF6EH1r_L"
   },
   "outputs": [],
   "source": [
    "# Save the trained weights in to .h5 format\n",
    "#model.save_weights(\"densenet_tr_03-{epoch:02d}-{val_acc:.2f}.hdf5\")\n",
    "#print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ai-yZ2ED5AK1"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#files.download('DNST_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ir_fg-p9G6kO"
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6HtNUyQG6kS"
   },
   "outputs": [],
   "source": [
    "class AdamTracker_0(Callback):\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"start , epoch = \", epoch,\", lr = \", K.eval(optimizer.lr),\", decay = \",K.eval(optimizer.decay),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BtYHxTCG6kV"
   },
   "outputs": [],
   "source": [
    "class AdamTracker_1(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"end, epoch = \", epoch,\", lr = \", K.eval(optimizer.lr),\", decay = \",K.eval(optimizer.decay),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMe9lOY9G6kb"
   },
   "outputs": [],
   "source": [
    "adam_lr_tracker_1 = AdamTracker_1()\n",
    "adam_lr_tracker_0 = AdamTracker_0()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n2iue0UsLDzb"
   },
   "outputs": [],
   "source": [
    "class SGDLearningRateTracker(Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        optimizer = self.model.optimizer\n",
    "        #lr = K.eval(optimizer.lr * (1. / (1. + optimizer.decay * optimizer.iterations)))\n",
    "        #print('\\nLR: {:.6f}\\n'.format(lr))\n",
    "        print(\"epoch = \", epoch,\", lr = \", K.eval(optimizer.lr), \", momentum = \",K.eval(optimizer.momentum),\n",
    "              \", decay = \",K.eval(optimizer.decay), \", Nestrov = \",optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting call backs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h-itoaFDG6kf"
   },
   "outputs": [],
   "source": [
    "sgd_lr_tracker = SGDLearningRateTracker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Og56VCRh5j8V"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, reduce_on_plateau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ki7pVU60G6ko"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [adam_lr_tracker_0, adam_lr_tracker_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lBTjYaJ4G6kv"
   },
   "outputs": [],
   "source": [
    "#callbacks_list = [checkpoint, adam_lr_tracker_0, adam_lr_tracker_1, clr_triangular]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EhuPjscpK0mm"
   },
   "outputs": [],
   "source": [
    "callbacks_list = [checkpoint, sgd_lr_tracker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bTKPS9HG6kx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OfdusR7aG6k1",
    "outputId": "f23665c5-6112-4dcc-d452-fae080e5ab70"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u-LiiCB9G6k8"
   },
   "source": [
    "## Train the model with the datagen, augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WKzwh45G6k8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZjsbZONG6lJ"
   },
   "outputs": [],
   "source": [
    "load_model_from_back = False\n",
    "\n",
    "if load_model_from_back:\n",
    "    model = load_model('--------------')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.9\n",
      "1e-04\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "k.set_value(model.optimizer.lr, 0.1)\n",
    "k.set_value(model.optimizer.momentum, 0.9)\n",
    "\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print(K.eval(model.optimizer.momentum))\n",
    "print(K.eval(model.optimizer.decay))\n",
    "print(model.optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train the model for 120 epochs first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 4114
    },
    "colab_type": "code",
    "id": "ODPSQd8dG6lM",
    "outputId": "0b061b74-5653-4c53-932e-04eb30c3664e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "391/390 [==============================] - 111s 283ms/step - loss: 2.1374 - acc: 0.2882 - val_loss: 1.7219 - val_acc: 0.3712\n",
      "\n",
      "Epoch 00001: val_acc improved from 0.11190 to 0.37120, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-01-0.3712.hdf5\n",
      "epoch =  0 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 2/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 1.6473 - acc: 0.3983 - val_loss: 1.5223 - val_acc: 0.4480\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.37120 to 0.44800, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-02-0.4480.hdf5\n",
      "epoch =  1 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 3/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 1.4703 - acc: 0.4662 - val_loss: 1.3615 - val_acc: 0.5148\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.44800 to 0.51480, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-03-0.5148.hdf5\n",
      "epoch =  2 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 4/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 1.3287 - acc: 0.5221 - val_loss: 1.3106 - val_acc: 0.5371\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.51480 to 0.53710, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-04-0.5371.hdf5\n",
      "epoch =  3 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 5/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 1.1919 - acc: 0.5722 - val_loss: 1.2037 - val_acc: 0.5925\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.53710 to 0.59250, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-05-0.5925.hdf5\n",
      "epoch =  4 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 6/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 1.0717 - acc: 0.6198 - val_loss: 1.2001 - val_acc: 0.6185\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.59250 to 0.61850, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-06-0.6185.hdf5\n",
      "epoch =  5 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 7/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.9899 - acc: 0.6492 - val_loss: 0.9722 - val_acc: 0.6784\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.61850 to 0.67840, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-07-0.6784.hdf5\n",
      "epoch =  6 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 8/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.9201 - acc: 0.6752 - val_loss: 1.2207 - val_acc: 0.6340\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.67840\n",
      "epoch =  7 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 9/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.8728 - acc: 0.6880 - val_loss: 0.9466 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.67840 to 0.69030, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-09-0.6903.hdf5\n",
      "epoch =  8 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 10/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.8273 - acc: 0.7057 - val_loss: 0.9207 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.69030 to 0.70770, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-10-0.7077.hdf5\n",
      "epoch =  9 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 11/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.7909 - acc: 0.7195 - val_loss: 0.8792 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.70770 to 0.72840, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-11-0.7284.hdf5\n",
      "epoch =  10 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 12/120\n",
      "391/390 [==============================] - 78s 198ms/step - loss: 0.7524 - acc: 0.7353 - val_loss: 1.0241 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.72840\n",
      "epoch =  11 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 13/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.7297 - acc: 0.7410 - val_loss: 0.7647 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.72840 to 0.75720, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-13-0.7572.hdf5\n",
      "epoch =  12 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 14/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.7019 - acc: 0.7499 - val_loss: 0.7821 - val_acc: 0.7562\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.75720\n",
      "epoch =  13 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 15/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.6750 - acc: 0.7590 - val_loss: 0.8414 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.75720\n",
      "epoch =  14 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 16/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.6543 - acc: 0.7680 - val_loss: 0.8598 - val_acc: 0.7388\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.75720\n",
      "epoch =  15 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 17/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.6286 - acc: 0.7800 - val_loss: 0.7463 - val_acc: 0.7748\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.75720 to 0.77480, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-17-0.7748.hdf5\n",
      "epoch =  16 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 18/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.6083 - acc: 0.7860 - val_loss: 0.8252 - val_acc: 0.7553\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.77480\n",
      "epoch =  17 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 19/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5939 - acc: 0.7915 - val_loss: 0.6309 - val_acc: 0.8004\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.77480 to 0.80040, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-19-0.8004.hdf5\n",
      "epoch =  18 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 20/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5698 - acc: 0.7988 - val_loss: 0.6121 - val_acc: 0.8068\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.80040 to 0.80680, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-20-0.8068.hdf5\n",
      "epoch =  19 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 21/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.5551 - acc: 0.8054 - val_loss: 0.6963 - val_acc: 0.7883\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.80680\n",
      "epoch =  20 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 22/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5427 - acc: 0.8085 - val_loss: 0.7184 - val_acc: 0.7916\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.80680\n",
      "epoch =  21 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 23/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.5272 - acc: 0.8140 - val_loss: 0.6207 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00023: val_acc improved from 0.80680 to 0.81190, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-23-0.8119.hdf5\n",
      "epoch =  22 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 24/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.5093 - acc: 0.8211 - val_loss: 0.7517 - val_acc: 0.7778\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.81190\n",
      "epoch =  23 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 25/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4940 - acc: 0.8283 - val_loss: 0.6703 - val_acc: 0.8007\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.81190\n",
      "epoch =  24 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 26/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4873 - acc: 0.8304 - val_loss: 0.6151 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.81190 to 0.81570, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-26-0.8157.hdf5\n",
      "epoch =  25 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 27/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4723 - acc: 0.8328 - val_loss: 0.6205 - val_acc: 0.8119\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.81570\n",
      "epoch =  26 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 28/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 77s 197ms/step - loss: 0.4670 - acc: 0.8364 - val_loss: 0.6365 - val_acc: 0.8114\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.81570\n",
      "epoch =  27 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 29/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.4545 - acc: 0.8403 - val_loss: 0.6620 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.81570\n",
      "epoch =  28 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 30/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.4431 - acc: 0.8430 - val_loss: 0.5758 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.81570 to 0.82640, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-30-0.8264.hdf5\n",
      "epoch =  29 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 31/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4358 - acc: 0.8453 - val_loss: 0.6433 - val_acc: 0.8066\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.82640\n",
      "epoch =  30 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 32/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.4305 - acc: 0.8488 - val_loss: 0.6561 - val_acc: 0.8143\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.82640\n",
      "epoch =  31 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 33/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.4190 - acc: 0.8527 - val_loss: 0.6595 - val_acc: 0.8145\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.82640\n",
      "epoch =  32 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 34/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.4118 - acc: 0.8553 - val_loss: 0.6319 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.82640\n",
      "epoch =  33 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 35/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.4075 - acc: 0.8563 - val_loss: 0.5588 - val_acc: 0.8344\n",
      "\n",
      "Epoch 00035: val_acc improved from 0.82640 to 0.83440, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-35-0.8344.hdf5\n",
      "epoch =  34 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 36/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.3981 - acc: 0.8594 - val_loss: 0.5768 - val_acc: 0.8301\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.83440\n",
      "epoch =  35 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 37/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.3922 - acc: 0.8626 - val_loss: 0.6024 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.83440\n",
      "epoch =  36 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 38/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.3829 - acc: 0.8667 - val_loss: 0.6592 - val_acc: 0.8139\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.83440\n",
      "epoch =  37 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 39/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.3775 - acc: 0.8662 - val_loss: 0.6390 - val_acc: 0.8257\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.83440\n",
      "epoch =  38 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 40/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3711 - acc: 0.8685 - val_loss: 0.5389 - val_acc: 0.8393\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.83440 to 0.83930, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-40-0.8393.hdf5\n",
      "epoch =  39 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 41/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.3666 - acc: 0.8716 - val_loss: 0.6641 - val_acc: 0.8115\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.83930\n",
      "epoch =  40 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 42/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3573 - acc: 0.8724 - val_loss: 0.6178 - val_acc: 0.8313\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.83930\n",
      "epoch =  41 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 43/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3592 - acc: 0.8724 - val_loss: 0.5660 - val_acc: 0.8408\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.83930 to 0.84080, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-43-0.8408.hdf5\n",
      "epoch =  42 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 44/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3474 - acc: 0.8768 - val_loss: 0.6962 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.84080\n",
      "epoch =  43 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 45/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3448 - acc: 0.8779 - val_loss: 0.4875 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.84080 to 0.86160, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-45-0.8616.hdf5\n",
      "epoch =  44 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 46/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3412 - acc: 0.8791 - val_loss: 0.6132 - val_acc: 0.8373\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.86160\n",
      "epoch =  45 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 47/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3391 - acc: 0.8799 - val_loss: 0.5136 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.86160\n",
      "epoch =  46 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 48/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.3360 - acc: 0.8810 - val_loss: 0.6503 - val_acc: 0.8218\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.86160\n",
      "epoch =  47 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 49/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.3241 - acc: 0.8856 - val_loss: 0.4680 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00049: val_acc improved from 0.86160 to 0.86690, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-49-0.8669.hdf5\n",
      "epoch =  48 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 50/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3196 - acc: 0.8883 - val_loss: 0.6621 - val_acc: 0.8228\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.86690\n",
      "epoch =  49 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 51/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3193 - acc: 0.8880 - val_loss: 0.5627 - val_acc: 0.8457\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.86690\n",
      "epoch =  50 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 52/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.3164 - acc: 0.8893 - val_loss: 0.6544 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.86690\n",
      "epoch =  51 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 53/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.3116 - acc: 0.8894 - val_loss: 0.5317 - val_acc: 0.8549\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.86690\n",
      "epoch =  52 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 54/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.3053 - acc: 0.8922 - val_loss: 0.7326 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.86690\n",
      "epoch =  53 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 55/120\n",
      "391/390 [==============================] - 76s 194ms/step - loss: 0.3030 - acc: 0.8919 - val_loss: 0.6372 - val_acc: 0.8347\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.86690\n",
      "epoch =  54 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 56/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2985 - acc: 0.8949 - val_loss: 0.5222 - val_acc: 0.8579\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.86690\n",
      "epoch =  55 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 57/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2976 - acc: 0.8958 - val_loss: 0.5692 - val_acc: 0.8498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00057: val_acc did not improve from 0.86690\n",
      "epoch =  56 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 58/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2894 - acc: 0.8969 - val_loss: 0.4678 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00058: val_acc improved from 0.86690 to 0.87010, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-58-0.8701.hdf5\n",
      "epoch =  57 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 59/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2884 - acc: 0.8975 - val_loss: 0.5209 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.87010\n",
      "epoch =  58 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 60/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2832 - acc: 0.9010 - val_loss: 0.5154 - val_acc: 0.8598\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.87010\n",
      "epoch =  59 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 61/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.2789 - acc: 0.9003 - val_loss: 0.5257 - val_acc: 0.8559\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.87010\n",
      "epoch =  60 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 62/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2781 - acc: 0.9012 - val_loss: 0.5619 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.87010\n",
      "epoch =  61 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 63/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2725 - acc: 0.9043 - val_loss: 0.4431 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00063: val_acc improved from 0.87010 to 0.87620, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-63-0.8762.hdf5\n",
      "epoch =  62 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 64/120\n",
      "391/390 [==============================] - 78s 198ms/step - loss: 0.2702 - acc: 0.9047 - val_loss: 0.4808 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.87620\n",
      "epoch =  63 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 65/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.2661 - acc: 0.9049 - val_loss: 0.6164 - val_acc: 0.8472\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.87620\n",
      "epoch =  64 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 66/120\n",
      "391/390 [==============================] - 79s 201ms/step - loss: 0.2694 - acc: 0.9042 - val_loss: 0.5669 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.87620\n",
      "epoch =  65 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 67/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2655 - acc: 0.9049 - val_loss: 0.5897 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.87620\n",
      "epoch =  66 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 68/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2624 - acc: 0.9067 - val_loss: 0.5805 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.87620\n",
      "epoch =  67 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 69/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2603 - acc: 0.9083 - val_loss: 0.4804 - val_acc: 0.8769\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.87620 to 0.87690, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-69-0.8769.hdf5\n",
      "epoch =  68 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 70/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2552 - acc: 0.9103 - val_loss: 0.6979 - val_acc: 0.8334\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.87690\n",
      "epoch =  69 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 71/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2567 - acc: 0.9090 - val_loss: 0.5271 - val_acc: 0.8667\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.87690\n",
      "epoch =  70 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 72/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2506 - acc: 0.9110 - val_loss: 0.5508 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.87690\n",
      "epoch =  71 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 73/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2463 - acc: 0.9132 - val_loss: 0.4703 - val_acc: 0.8776\n",
      "\n",
      "Epoch 00073: val_acc improved from 0.87690 to 0.87760, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-73-0.8776.hdf5\n",
      "epoch =  72 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 74/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2434 - acc: 0.9121 - val_loss: 0.6018 - val_acc: 0.8541\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.87760\n",
      "epoch =  73 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 75/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2434 - acc: 0.9132 - val_loss: 0.4740 - val_acc: 0.8762\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.87760\n",
      "epoch =  74 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 76/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2377 - acc: 0.9141 - val_loss: 0.4626 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.87760\n",
      "epoch =  75 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 77/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2430 - acc: 0.9134 - val_loss: 0.5190 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.87760\n",
      "epoch =  76 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 78/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.2389 - acc: 0.9155 - val_loss: 0.4794 - val_acc: 0.8789\n",
      "\n",
      "Epoch 00078: val_acc improved from 0.87760 to 0.87890, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-78-0.8789.hdf5\n",
      "epoch =  77 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 79/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2341 - acc: 0.9155 - val_loss: 0.4816 - val_acc: 0.8786\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.87890\n",
      "epoch =  78 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 80/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2348 - acc: 0.9155 - val_loss: 0.4521 - val_acc: 0.8836\n",
      "\n",
      "Epoch 00080: val_acc improved from 0.87890 to 0.88360, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-80-0.8836.hdf5\n",
      "epoch =  79 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 81/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2298 - acc: 0.9185 - val_loss: 0.4698 - val_acc: 0.8790\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88360\n",
      "epoch =  80 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 82/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2274 - acc: 0.9178 - val_loss: 0.4972 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.88360\n",
      "epoch =  81 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 83/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2265 - acc: 0.9204 - val_loss: 0.5292 - val_acc: 0.8678\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.88360\n",
      "epoch =  82 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 84/120\n",
      "391/390 [==============================] - 76s 194ms/step - loss: 0.2242 - acc: 0.9200 - val_loss: 0.5326 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.88360\n",
      "epoch =  83 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 85/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.2218 - acc: 0.9208 - val_loss: 0.5213 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.88360\n",
      "epoch =  84 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 86/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2250 - acc: 0.9196 - val_loss: 0.5303 - val_acc: 0.8690\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.88360\n",
      "epoch =  85 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 87/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2230 - acc: 0.9195 - val_loss: 0.4940 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.88360\n",
      "epoch =  86 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 88/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2136 - acc: 0.9246 - val_loss: 0.5173 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.88360\n",
      "epoch =  87 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 89/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.2161 - acc: 0.9228 - val_loss: 0.5355 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.88360\n",
      "epoch =  88 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 90/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2177 - acc: 0.9209 - val_loss: 0.4809 - val_acc: 0.8806\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.88360\n",
      "epoch =  89 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 91/120\n",
      "391/390 [==============================] - 76s 196ms/step - loss: 0.2139 - acc: 0.9232 - val_loss: 0.5337 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.88360\n",
      "epoch =  90 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 92/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2092 - acc: 0.9255 - val_loss: 0.4986 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.88360\n",
      "epoch =  91 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 93/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2071 - acc: 0.9248 - val_loss: 0.5099 - val_acc: 0.8747\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.88360\n",
      "epoch =  92 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 94/120\n",
      "391/390 [==============================] - 76s 194ms/step - loss: 0.2080 - acc: 0.9256 - val_loss: 0.5051 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.88360\n",
      "epoch =  93 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 95/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2023 - acc: 0.9274 - val_loss: 0.4664 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.88360\n",
      "epoch =  94 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 96/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.2046 - acc: 0.9283 - val_loss: 0.4822 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.88360\n",
      "epoch =  95 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 97/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.2019 - acc: 0.9279 - val_loss: 0.5259 - val_acc: 0.8749\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.88360\n",
      "epoch =  96 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 98/120\n",
      "391/390 [==============================] - 75s 193ms/step - loss: 0.2017 - acc: 0.9281 - val_loss: 0.5036 - val_acc: 0.8781\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.88360\n",
      "epoch =  97 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 99/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.2006 - acc: 0.9288 - val_loss: 0.4515 - val_acc: 0.8891\n",
      "\n",
      "Epoch 00099: val_acc improved from 0.88360 to 0.88910, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-99-0.8891.hdf5\n",
      "epoch =  98 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 100/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1964 - acc: 0.9288 - val_loss: 0.5585 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.88910\n",
      "epoch =  99 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 101/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1978 - acc: 0.9289 - val_loss: 0.4816 - val_acc: 0.8813\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.88910\n",
      "epoch =  100 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 102/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1975 - acc: 0.9293 - val_loss: 0.4714 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00102: val_acc improved from 0.88910 to 0.89020, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-102-0.8902.hdf5\n",
      "epoch =  101 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 103/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1976 - acc: 0.9290 - val_loss: 0.5416 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.89020\n",
      "epoch =  102 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 104/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1935 - acc: 0.9301 - val_loss: 0.5016 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.89020\n",
      "epoch =  103 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 105/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1915 - acc: 0.9320 - val_loss: 0.5007 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.89020\n",
      "epoch =  104 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 106/120\n",
      "391/390 [==============================] - 76s 193ms/step - loss: 0.1851 - acc: 0.9336 - val_loss: 0.4809 - val_acc: 0.8871\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.89020\n",
      "epoch =  105 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 107/120\n",
      "391/390 [==============================] - 76s 193ms/step - loss: 0.1912 - acc: 0.9312 - val_loss: 0.4683 - val_acc: 0.8881\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.89020\n",
      "epoch =  106 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 108/120\n",
      "391/390 [==============================] - 76s 195ms/step - loss: 0.1890 - acc: 0.9317 - val_loss: 0.5575 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.89020\n",
      "epoch =  107 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 109/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.1866 - acc: 0.9340 - val_loss: 0.4596 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.89020\n",
      "epoch =  108 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 110/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1841 - acc: 0.9328 - val_loss: 0.4790 - val_acc: 0.8893\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.89020\n",
      "epoch =  109 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 111/120\n",
      "391/390 [==============================] - 77s 196ms/step - loss: 0.1821 - acc: 0.9343 - val_loss: 0.5025 - val_acc: 0.8874\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.89020\n",
      "epoch =  110 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 112/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.1763 - acc: 0.9362 - val_loss: 0.4676 - val_acc: 0.8916\n",
      "\n",
      "Epoch 00112: val_acc improved from 0.89020 to 0.89160, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-112-0.8916.hdf5\n",
      "epoch =  111 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 113/120\n",
      "391/390 [==============================] - 77s 197ms/step - loss: 0.1834 - acc: 0.9353 - val_loss: 0.5352 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.89160\n",
      "epoch =  112 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 114/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.1850 - acc: 0.9351 - val_loss: 0.5277 - val_acc: 0.8792\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.89160\n",
      "epoch =  113 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 115/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.1795 - acc: 0.9348 - val_loss: 0.4590 - val_acc: 0.8884\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.89160\n",
      "epoch =  114 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 116/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.1776 - acc: 0.9374 - val_loss: 0.4960 - val_acc: 0.8830\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.89160\n",
      "epoch =  115 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 117/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 79s 201ms/step - loss: 0.1753 - acc: 0.9382 - val_loss: 0.4770 - val_acc: 0.8922\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.89160 to 0.89220, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-117-0.8922.hdf5\n",
      "epoch =  116 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 118/120\n",
      "391/390 [==============================] - 78s 200ms/step - loss: 0.1733 - acc: 0.9375 - val_loss: 0.4928 - val_acc: 0.8852\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.89220\n",
      "epoch =  117 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 119/120\n",
      "391/390 [==============================] - 78s 199ms/step - loss: 0.1737 - acc: 0.9381 - val_loss: 0.5319 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.89220\n",
      "epoch =  118 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 120/120\n",
      "391/390 [==============================] - 77s 198ms/step - loss: 0.1735 - acc: 0.9380 - val_loss: 0.5974 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.89220\n",
      "epoch =  119 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 120\n",
    "\n",
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 1.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_filter = 12\n",
    "num_filter = 12\n",
    "growth_rate = 12\n",
    "dropout_rate = 0.2\n",
    "#compression = 0.751\n",
    "compression = 0.5\n",
    "l = 16\n",
    "dense_l= [8, 16, 20, 12]\n",
    "\n",
    "input = Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = Conv2D(2*num_filter, (3,3), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = add_denseblock(First_Conv2D, growth_rate, dropout_rate, dense_l[0])\n",
    "First_Transition = add_transition(First_Block, dropout_rate)\n",
    "\n",
    "Second_Block = add_denseblock(First_Transition, growth_rate, dropout_rate, dense_l[1])\n",
    "Second_Transition = add_transition(Second_Block, dropout_rate)\n",
    "\n",
    "Third_Block = add_denseblock(Second_Transition, num_filter, dropout_rate, dense_l[2])\n",
    "Third_Transition = add_transition(Third_Block, dropout_rate)\n",
    "\n",
    "Last_Block = add_denseblock(Third_Transition,  growth_rate, dropout_rate, dense_l[3])\n",
    "output = output_layer(Last_Block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[input], outputs=[output])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "epochs = 90\n",
    "decay = learning_rate/epochs\n",
    "decay = 0.0001\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=learning_rate, decay=decay, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine Loss function and Optimizer\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 18s 2ms/step\n",
      "Test loss: 0.4431272743701935\n",
      "Test accuracy: 0.8762\n",
      "50000/50000 [==============================] - 35s 691us/step\n",
      "Train loss: 0.22539761049449444\n",
      "Train accuracy: 0.92494\n"
     ]
    }
   ],
   "source": [
    "load_model_from_back = True\n",
    "\n",
    "if load_model_from_back:\n",
    "    model.load_weights('DNST_CIFAR10_Conv_09_09_final_tr2-63-0.8762.hdf5')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    score = model.evaluate(x_train, y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.9\n",
      "1e-04\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import keras.backend as K\n",
    "k.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print(K.eval(model.optimizer.momentum))\n",
    "print(K.eval(model.optimizer.decay))\n",
    "print(model.optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13:56 30 october, more agumentaion, 2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/175\n",
      "391/390 [==============================] - 137s 352ms/step - loss: 0.3197 - acc: 0.8874 - val_loss: 0.5486 - val_acc: 0.8560\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.89750\n",
      "epoch =  0 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 2/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.3092 - acc: 0.8902 - val_loss: 0.5944 - val_acc: 0.8460\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.89750\n",
      "epoch =  1 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 3/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2999 - acc: 0.8939 - val_loss: 0.4826 - val_acc: 0.8684\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.89750\n",
      "epoch =  2 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 4/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2916 - acc: 0.8967 - val_loss: 0.6128 - val_acc: 0.8455\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.89750\n",
      "epoch =  3 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 5/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2838 - acc: 0.8988 - val_loss: 0.5307 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.89750\n",
      "epoch =  4 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 6/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2774 - acc: 0.9012 - val_loss: 0.4476 - val_acc: 0.8820\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.89750\n",
      "epoch =  5 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 7/175\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.2680 - acc: 0.9052 - val_loss: 0.5446 - val_acc: 0.8601\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.89750\n",
      "epoch =  6 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 8/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2617 - acc: 0.9061 - val_loss: 0.4766 - val_acc: 0.8757\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.89750\n",
      "epoch =  7 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 9/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2587 - acc: 0.9072 - val_loss: 0.5685 - val_acc: 0.8561\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.89750\n",
      "epoch =  8 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 10/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2488 - acc: 0.9113 - val_loss: 0.7172 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.89750\n",
      "epoch =  9 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 11/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2445 - acc: 0.9124 - val_loss: 0.5497 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.89750\n",
      "epoch =  10 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 12/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2382 - acc: 0.9143 - val_loss: 0.5224 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.89750\n",
      "epoch =  11 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 13/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2343 - acc: 0.9160 - val_loss: 0.5752 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.89750\n",
      "epoch =  12 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 14/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2267 - acc: 0.9190 - val_loss: 0.6288 - val_acc: 0.8547\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.89750\n",
      "epoch =  13 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 15/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2237 - acc: 0.9201 - val_loss: 0.5366 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.89750\n",
      "epoch =  14 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 16/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2215 - acc: 0.9202 - val_loss: 0.5667 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.89750\n",
      "epoch =  15 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 17/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.2139 - acc: 0.9239 - val_loss: 0.5296 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.89750\n",
      "epoch =  16 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 18/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2126 - acc: 0.9247 - val_loss: 0.6340 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.89750\n",
      "epoch =  17 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 19/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2068 - acc: 0.9260 - val_loss: 0.5778 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.89750\n",
      "epoch =  18 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 20/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.2040 - acc: 0.9272 - val_loss: 0.5039 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.89750\n",
      "epoch =  19 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 21/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1981 - acc: 0.9285 - val_loss: 0.5175 - val_acc: 0.8785\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.89750\n",
      "epoch =  20 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 22/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1941 - acc: 0.9316 - val_loss: 0.5003 - val_acc: 0.8825\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.89750\n",
      "epoch =  21 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 23/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1912 - acc: 0.9326 - val_loss: 0.5548 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.89750\n",
      "epoch =  22 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 24/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1899 - acc: 0.9320 - val_loss: 0.5593 - val_acc: 0.8801\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.89750\n",
      "epoch =  23 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 25/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1857 - acc: 0.9338 - val_loss: 0.5013 - val_acc: 0.8853\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.89750\n",
      "epoch =  24 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 26/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1853 - acc: 0.9339 - val_loss: 0.5114 - val_acc: 0.8848\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.89750\n",
      "epoch =  25 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 27/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1821 - acc: 0.9343 - val_loss: 0.5117 - val_acc: 0.8850\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.89750\n",
      "epoch =  26 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 28/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1775 - acc: 0.9355 - val_loss: 0.4992 - val_acc: 0.8912\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.89750\n",
      "epoch =  27 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 29/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1753 - acc: 0.9374 - val_loss: 0.5130 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.89750\n",
      "epoch =  28 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 30/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1707 - acc: 0.9382 - val_loss: 0.6864 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.89750\n",
      "epoch =  29 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 31/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1676 - acc: 0.9398 - val_loss: 0.5165 - val_acc: 0.8866\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.89750\n",
      "epoch =  30 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 32/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1652 - acc: 0.9412 - val_loss: 0.5018 - val_acc: 0.8896\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.89750\n",
      "epoch =  31 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 33/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1641 - acc: 0.9411 - val_loss: 0.5301 - val_acc: 0.8902\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.89750\n",
      "epoch =  32 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 34/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1631 - acc: 0.9410 - val_loss: 0.5457 - val_acc: 0.8838\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.89750\n",
      "epoch =  33 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 35/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1594 - acc: 0.9431 - val_loss: 0.4999 - val_acc: 0.8890\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.89750\n",
      "epoch =  34 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 36/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1617 - acc: 0.9419 - val_loss: 0.5197 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.89750\n",
      "epoch =  35 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 37/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1579 - acc: 0.9432 - val_loss: 0.5218 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.89750\n",
      "epoch =  36 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 38/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1505 - acc: 0.9456 - val_loss: 0.5389 - val_acc: 0.8870\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.89750\n",
      "epoch =  37 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 39/175\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.1489 - acc: 0.9462 - val_loss: 0.6001 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.89750\n",
      "epoch =  38 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 40/175\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.1514 - acc: 0.9453 - val_loss: 0.5448 - val_acc: 0.8855\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.89750\n",
      "epoch =  39 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 41/175\n",
      "391/390 [==============================] - 99s 253ms/step - loss: 0.1468 - acc: 0.9483 - val_loss: 0.4847 - val_acc: 0.8993\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.89750 to 0.89930, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-41-0.8993.hdf5\n",
      "epoch =  40 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 42/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1462 - acc: 0.9475 - val_loss: 0.5111 - val_acc: 0.8918\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.89930\n",
      "epoch =  41 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 43/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1474 - acc: 0.9469 - val_loss: 0.5054 - val_acc: 0.8933\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.89930\n",
      "epoch =  42 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 44/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1423 - acc: 0.9494 - val_loss: 0.4917 - val_acc: 0.8969\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.89930\n",
      "epoch =  43 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 45/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1404 - acc: 0.9500 - val_loss: 0.5533 - val_acc: 0.8862\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.89930\n",
      "epoch =  44 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 46/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1385 - acc: 0.9499 - val_loss: 0.5887 - val_acc: 0.8877\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.89930\n",
      "epoch =  45 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 47/175\n",
      "391/390 [==============================] - 99s 252ms/step - loss: 0.1394 - acc: 0.9502 - val_loss: 0.5527 - val_acc: 0.8879\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.89930\n",
      "epoch =  46 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 48/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1399 - acc: 0.9496 - val_loss: 0.5475 - val_acc: 0.8940\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.89930\n",
      "epoch =  47 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 49/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1355 - acc: 0.9517 - val_loss: 0.5417 - val_acc: 0.8913\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.89930\n",
      "epoch =  48 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 50/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1350 - acc: 0.9517 - val_loss: 0.5362 - val_acc: 0.8906\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.89930\n",
      "epoch =  49 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 51/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1314 - acc: 0.9528 - val_loss: 0.5322 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.89930\n",
      "epoch =  50 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 52/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1295 - acc: 0.9535 - val_loss: 0.5730 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.89930\n",
      "epoch =  51 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 53/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1300 - acc: 0.9537 - val_loss: 0.5744 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.89930\n",
      "epoch =  52 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 54/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1259 - acc: 0.9555 - val_loss: 0.5798 - val_acc: 0.8883\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.89930\n",
      "epoch =  53 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 55/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1280 - acc: 0.9537 - val_loss: 0.5794 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.89930\n",
      "epoch =  54 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 56/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1238 - acc: 0.9552 - val_loss: 0.5578 - val_acc: 0.8922\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.89930\n",
      "epoch =  55 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 57/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1239 - acc: 0.9553 - val_loss: 0.5799 - val_acc: 0.8889\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.89930\n",
      "epoch =  56 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 58/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1245 - acc: 0.9546 - val_loss: 0.5433 - val_acc: 0.8941\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.89930\n",
      "epoch =  57 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 59/175\n",
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1208 - acc: 0.9560 - val_loss: 0.5478 - val_acc: 0.8935\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.89930\n",
      "epoch =  58 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 60/175\n",
      "391/390 [==============================] - 98s 252ms/step - loss: 0.1218 - acc: 0.9561 - val_loss: 0.5529 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.89930\n",
      "epoch =  59 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 61/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1180 - acc: 0.9568 - val_loss: 0.5960 - val_acc: 0.8858\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.89930\n",
      "epoch =  60 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 62/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1156 - acc: 0.9587 - val_loss: 0.5511 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.89930\n",
      "epoch =  61 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 63/175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - 98s 251ms/step - loss: 0.1184 - acc: 0.9573 - val_loss: 0.5770 - val_acc: 0.8931\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.89930\n",
      "epoch =  62 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 64/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1192 - acc: 0.9575 - val_loss: 0.5461 - val_acc: 0.8975\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.89930\n",
      "epoch =  63 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 65/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1132 - acc: 0.9589 - val_loss: 0.5862 - val_acc: 0.8909\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.89930\n",
      "epoch =  64 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 66/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1142 - acc: 0.9591 - val_loss: 0.5858 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.89930\n",
      "epoch =  65 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 67/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1110 - acc: 0.9603 - val_loss: 0.5446 - val_acc: 0.8986\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.89930\n",
      "epoch =  66 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 68/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1108 - acc: 0.9609 - val_loss: 0.5775 - val_acc: 0.8930\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.89930\n",
      "epoch =  67 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 69/175\n",
      "391/390 [==============================] - 98s 250ms/step - loss: 0.1092 - acc: 0.9603 - val_loss: 0.5453 - val_acc: 0.9015\n",
      "\n",
      "Epoch 00069: val_acc improved from 0.89930 to 0.90150, saving model to DNST_CIFAR10_Conv_09_09_final_tr2-69-0.9015.hdf5\n",
      "epoch =  68 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 70/175\n",
      "391/390 [==============================] - 100s 255ms/step - loss: 0.1101 - acc: 0.9609 - val_loss: 0.6052 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.90150\n",
      "epoch =  69 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 71/175\n",
      "391/390 [==============================] - 99s 254ms/step - loss: 0.1088 - acc: 0.9611 - val_loss: 0.5936 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.90150\n",
      "epoch =  70 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 72/175\n",
      "390/390 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9603"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 175\n",
    "\n",
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 2.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19:29 30 october, more agumentaion, 2x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 7s 654us/step\n",
      "Test loss: 0.4431272743701935\n",
      "Test accuracy: 0.8762\n",
      "50000/50000 [==============================] - 32s 649us/step\n",
      "Train loss: 0.22539761049449444\n",
      "Train accuracy: 0.92494\n"
     ]
    }
   ],
   "source": [
    "load_model_from_back = True\n",
    "\n",
    "if load_model_from_back:\n",
    "    model.load_weights('DNST_CIFAR10_Conv_09_09_final_tr2-63-0.8762.hdf5')\n",
    "    score = model.evaluate(x_test, y_test, verbose=1)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    score = model.evaluate(x_train, y_train, verbose=1)\n",
    "    print('Train loss:', score[0])\n",
    "    print('Train accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=25,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.25,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.25,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,    # randomly flip images\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n",
      "0.9\n",
      "1e-04\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# import keras.backend as K\n",
    "k.set_value(model.optimizer.lr, 0.1)\n",
    "\n",
    "print(K.eval(model.optimizer.lr))\n",
    "print(K.eval(model.optimizer.momentum))\n",
    "print(K.eval(model.optimizer.decay))\n",
    "print(model.optimizer.nesterov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/187\n",
      "586/585 [==============================] - 142s 243ms/step - loss: 0.4413 - acc: 0.8467 - val_loss: 0.4100 - val_acc: 0.8796\n",
      "\n",
      "Epoch 00001: val_acc did not improve from 0.90610\n",
      "epoch =  0 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 2/187\n",
      "586/585 [==============================] - 141s 241ms/step - loss: 0.4101 - acc: 0.8570 - val_loss: 0.4392 - val_acc: 0.8717\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.90610\n",
      "epoch =  1 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 3/187\n",
      "586/585 [==============================] - 141s 240ms/step - loss: 0.3970 - acc: 0.8610 - val_loss: 0.4301 - val_acc: 0.8778\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.90610\n",
      "epoch =  2 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 4/187\n",
      "586/585 [==============================] - 141s 241ms/step - loss: 0.3864 - acc: 0.8645 - val_loss: 0.4272 - val_acc: 0.8777\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.90610\n",
      "epoch =  3 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 5/187\n",
      "586/585 [==============================] - 140s 240ms/step - loss: 0.3783 - acc: 0.8679 - val_loss: 0.4379 - val_acc: 0.8798\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.90610\n",
      "epoch =  4 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 6/187\n",
      "586/585 [==============================] - 140s 240ms/step - loss: 0.3756 - acc: 0.8689 - val_loss: 0.4388 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.90610\n",
      "epoch =  5 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 7/187\n",
      "586/585 [==============================] - 140s 238ms/step - loss: 0.3713 - acc: 0.8704 - val_loss: 0.4447 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.90610\n",
      "epoch =  6 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 8/187\n",
      "586/585 [==============================] - 139s 238ms/step - loss: 0.3644 - acc: 0.8722 - val_loss: 0.4506 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.90610\n",
      "epoch =  7 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 9/187\n",
      "586/585 [==============================] - 139s 238ms/step - loss: 0.3602 - acc: 0.8743 - val_loss: 0.4423 - val_acc: 0.8788\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.90610\n",
      "epoch =  8 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 10/187\n",
      "586/585 [==============================] - 139s 238ms/step - loss: 0.3554 - acc: 0.8748 - val_loss: 0.4780 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.90610\n",
      "epoch =  9 , lr =  0.1 , momentum =  0.9 , decay =  1e-04 , Nestrov =  True\n",
      "Epoch 11/187\n",
      "585/585 [============================>.] - ETA: 0s - loss: 0.3553 - acc: 0.8757"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "epochs = 250- 63\n",
    "\n",
    "if do_data_augmentation:\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                        batch_size=batch_size),\n",
    "                        steps_per_epoch= (len(x_train)* 3.0)/batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        callbacks=callbacks_list)\n",
    "else:\n",
    "    model.fit(x_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(x_test, y_test),\n",
    "                callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1781
    },
    "colab_type": "code",
    "id": "KbD-T7m0G6lP",
    "outputId": "198b9368-e44a-461d-a822-15e6901dc520"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "imdB9nUyoCn0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "eEgYnYbSoDJg",
    "outputId": "bdc7ee86-c7dd-4905-ed02-b91d18c0424f"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1373
    },
    "colab_type": "code",
    "id": "LLcxWH2hoDXw",
    "outputId": "5143ffbd-b989-4dc5-c1fc-3ee16dfe0d5d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rpig1ugEsLfe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "H0PIL3pysLxt",
    "outputId": "f4855f05-c410-49f0-839b-c1c62e169196"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wn3m4_EjsMGE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Z4PzRvhLvHsK",
    "outputId": "01b9cc7a-df0a-41c5-e312-eab3b46fb24a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ethaY4Y2wi4I"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p0yrzJxXw0rM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 561
    },
    "colab_type": "code",
    "id": "A5uOHjlkw045",
    "outputId": "db583ad7-967e-416f-f212-7b83f77f3c6e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "EpyFvpU0w1GY",
    "outputId": "8e3f9817-ef81-4709-f332-689ab3a7eba6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x5ZsYV6yw1DV",
    "outputId": "b98facfe-1bd6-40bb-8f47-bd6027867392"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lWzP6Edpw0_x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_HMxDUvWZ0F"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "colab_type": "code",
    "id": "eadO_adxWaFe",
    "outputId": "c8909100-25c9-4a0b-f79d-e0fece23c4f6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_32NGkhiprV7",
    "outputId": "df92c9ac-63ea-4d1a-912f-d7562598d5ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMEISrvNprzz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "U3PICoCgw01Z",
    "outputId": "e6e8a94b-cfd8-4ce8-9bab-b1e0081a759d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8p916JhoWHz6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jlZmM-_zG6lS",
    "outputId": "9977e1ed-3f85-4f39-f9f7-4baa702e2e76"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6zvEjTAoBM4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qq-HWYiln_b2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zmvoF8QVG6lU",
    "outputId": "9e7ac435-50e3-4a84-f347-7e78bf01d9de"
   },
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zix_gEdBG6lX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cAFfDq18G6lZ",
    "outputId": "b7ac644b-f46b-4fc6-95e1-2437e58f3898"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dcMp-CA3G6lc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PUMfE3mfG6ld",
    "outputId": "b12040ea-6043-46c5-9c5c-87f1d12873b6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uP9uPg9GG6lh",
    "outputId": "cf1ac1cb-8982-4136-ded1-0f7cbcc5e729"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tZVtRNGtG6ll",
    "outputId": "17891475-5760-497c-9e8b-795465f9d46b"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iq_aLgxuG6lp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jQ3lM8zG6lv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cpU6cQarG6lx",
    "outputId": "6d08876d-c10d-4b68-9f6c-0b4240ecf71d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zCE9_64ZG6l2",
    "outputId": "3cc5efd4-7104-4da9-8997-894249ee5562"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gS6ODLgHG6l5",
    "outputId": "8b30c208-9fe2-4ceb-e3a6-d66d9ffac8d3"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m6Mgwh1G6l8",
    "outputId": "bc3aee71-5d64-4ecd-fcf4-c2b368ec89f8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NSMOqu70G6l_",
    "outputId": "f1f97535-70c4-4e98-9dcc-a156368420e9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nEQ6qu5BG6mC",
    "outputId": "d3d5b175-fbc8-4624-a476-6ff6ae9ec189"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PTi7d5RDG6mM",
    "outputId": "f92692b1-e390-4c5c-bbb4-8664132c1ecf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2UeD_6KG6mR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onvf93F-G6mU",
    "outputId": "ba633c58-eb7c-4c1d-e296-f44a15990493"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeR7qi_iG6mX",
    "outputId": "e12e99a9-c267-4c81-fe24-6d4c4809681a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_W4l0s3G6ma",
    "outputId": "e3460c04-8738-45f1-8ac4-1bae56fa04fe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4A_Ktx95G6mh",
    "outputId": "863c7823-cf52-4383-b546-fb73b8033e56"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kAnw_xNlG6mj",
    "outputId": "f679acb4-169a-4d23-acd0-b1b540596108"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TwOoDMefG6mm",
    "outputId": "002e30cf-7bb5-420c-bc7c-86bb1c1d8d7e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cU0meEE3G6mr",
    "outputId": "f6793d3d-6c44-4eb8-fcb1-1112b3c540a0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWYRrcp7G6mv"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DNST_CIFAR10_Conv_09.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
